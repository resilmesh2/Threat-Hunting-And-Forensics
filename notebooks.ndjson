{"attributes":{"dateModified":"2024-09-02T15:19:39.110Z","paragraphs":[{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-30T11:25:35.445Z","dateModified":"2024-08-30T11:32:16.301Z","id":"paragraph_29d5cbf1-2132-47f9-9b34-2db7a4687fed","input":{"inputText":"%md\nThis notebook is designed based on the ThreatHunter-Playbook as : https://github.com/OTRF/ThreatHunter-Playbook/blob/master/docs/hunts/windows/170105-LSASSMemoryReadAccess/notebook.md\n\nThe purpose of this notebook is to demonstrate whether OpenSearch notebooks, using Piped Processing Language (PPL), are capable of supporting threat hunting activities. ","inputType":"MARKDOWN"},"output":[{"execution_time":"0.087 ms","outputType":"MARKDOWN","result":"This notebook is designed based on the ThreatHunter-Playbook as : https://github.com/OTRF/ThreatHunter-Playbook/blob/master/docs/hunts/windows/170105-LSASSMemoryReadAccess/notebook.md\n\nThe purpose of this notebook is to demonstrate whether OpenSearch notebooks, using Piped Processing Language (PPL), are capable of supporting threat hunting activities. "}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-30T11:32:30.621Z","dateModified":"2024-08-30T14:52:30.752Z","id":"paragraph_e32294f0-27e9-466c-a8fc-2ac5b63bc9e6","input":{"inputText":"%md\n## Hypothesis\n\nAdversaries might retrieve credential data from the process memory of the Local Security Authority Subsystem Service (LSASS).\n\n\n## Technical Context\n\nWhen a user logs on to a system, the Local Security Authority Subsystem Service (LSASS) process in memory generates and stores various types of credentials. These credentials enabling single sign-on (SSO), allowing the user to access multiple resources without needing to re-authenticate each time. The stored credential data can include Kerberos tickets, NTLM password hashes, and LM password hashes. Additionally, LSASS may store clear-text passwords to support legacy authentication protocols like WDigest and Security Support Provider (SSP) authentication.","inputType":"MARKDOWN"},"output":[{"execution_time":"0.037 ms","outputType":"MARKDOWN","result":"## Hypothesis\n\nAdversaries might retrieve credential data from the process memory of the Local Security Authority Subsystem Service (LSASS).\n\n\n## Technical Context\n\nWhen a user logs on to a system, the Local Security Authority Subsystem Service (LSASS) process in memory generates and stores various types of credentials. These credentials enabling single sign-on (SSO), allowing the user to access multiple resources without needing to re-authenticate each time. The stored credential data can include Kerberos tickets, NTLM password hashes, and LM password hashes. Additionally, LSASS may store clear-text passwords to support legacy authentication protocols like WDigest and Security Support Provider (SSP) authentication."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-30T15:03:34.684Z","dateModified":"2024-08-30T15:24:08.255Z","id":"paragraph_89e3ed39-e080-428b-8a25-f071a81db663","input":{"inputText":"%md\n## Pre-Recorded Security Datasets\n\n| **Metadata**   | **Value** |\n|------------|-----------|\n| **docs**   | [Link for document page](https://securitydatasets.com/notebooks/atomic/windows/credential_access/SDWIN-190518202151.html) |\n| **link**   | [Link for download dataset](https://raw.githubusercontent.com/OTRF/Security-Datasets/master/datasets/atomic/windows/credential_access/host/empire_mimikatz_logonpasswords.zip) |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.012 ms","outputType":"MARKDOWN","result":"## Pre-Recorded Security Datasets\n\n| **Metadata**   | **Value** |\n|------------|-----------|\n| **docs**   | [Link for document page](https://securitydatasets.com/notebooks/atomic/windows/credential_access/SDWIN-190518202151.html) |\n| **link**   | [Link for download dataset](https://raw.githubusercontent.com/OTRF/Security-Datasets/master/datasets/atomic/windows/credential_access/host/empire_mimikatz_logonpasswords.zip) |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T10:48:41.545Z","dateModified":"2024-09-02T12:55:43.651Z","id":"paragraph_5e6f6c77-bc3b-409e-bf82-286aaaf92afd","input":{"inputText":"%md\n*** Analytic I ***\n\nMonitor for non-system accounts that gain access to and interact with LSASS. While many attackers might inject their malicious code into a system process to avoid detection, there are instances where they do not escalate privileges to the System level. Instead, they use an account with administrative rights, as this is sufficient to access LSASS. Detecting such behavior can help identify potential threats that don’t follow more sophisticated methods.\n\n| Data source | Event Provider                        | Relationship               | Event |\n|-------------|---------------------------------------|----------------------------|-------|\n| Process     | Microsoft-Windows-Security-Auditing   | Process accessed Process    | 4663  |\n| Process     | Microsoft-Windows-Security-Auditing   | Process requested_access Process | 4656  |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.013 ms","outputType":"MARKDOWN","result":"*** Analytic I ***\n\nMonitor for non-system accounts that gain access to and interact with LSASS. While many attackers might inject their malicious code into a system process to avoid detection, there are instances where they do not escalate privileges to the System level. Instead, they use an account with administrative rights, as this is sufficient to access LSASS. Detecting such behavior can help identify potential threats that don’t follow more sophisticated methods.\n\n| Data source | Event Provider                        | Relationship               | Event |\n|-------------|---------------------------------------|----------------------------|-------|\n| Process     | Microsoft-Windows-Security-Auditing   | Process accessed Process    | 4663  |\n| Process     | Microsoft-Windows-Security-Auditing   | Process requested_access Process | 4656  |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T14:03:51.903Z","dateModified":"2024-08-28T14:07:22.075Z","id":"paragraph_ebd3110f-7949-47e2-b75a-e794a4566497","input":{"inputText":"%ppl\nsource = lsass-memory* | where match(Channel, 'Security') | where EventID = '4663' OR EventID = '4656' | where query_string(['ObjectName'], '*lsass.exe') | where not query_string(['SubjectUserName'], '*$') | fields @timestamp , Hostname, SubjectUserName, ProcessName, ObjectName, AccessMask, EventID\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.015 ms","outputType":"QUERY","result":"{\"schema\":[{\"name\":\"@timestamp\",\"type\":\"timestamp\"},{\"name\":\"Hostname\",\"type\":\"string\"},{\"name\":\"SubjectUserName\",\"type\":\"string\"},{\"name\":\"ProcessName\",\"type\":\"string\"},{\"name\":\"ObjectName\",\"type\":\"string\"},{\"name\":\"AccessMask\",\"type\":\"string\"},{\"name\":\"EventID\",\"type\":\"string\"}],\"datarows\":[[\"2020-08-07 14:32:57.592\",\"WORKSTATION5.theshire.local\",\"pgustavo\",\"C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\",\"\\\\Device\\\\HarddiskVolume2\\\\Windows\\\\System32\\\\lsass.exe\",\"0x1010\",\"4656\"],[\"2020-08-07 14:32:57.592\",\"WORKSTATION5.theshire.local\",\"pgustavo\",\"C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\",\"\\\\Device\\\\HarddiskVolume2\\\\Windows\\\\System32\\\\lsass.exe\",\"0x10\",\"4663\"]],\"total\":2,\"size\":2}"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T11:20:12.423Z","dateModified":"2024-09-02T12:55:58.890Z","id":"paragraph_0b6c67ab-ab11-4438-b06e-8f5477e01555","input":{"inputText":"%md\n*** Analytic II ***\n\n Look for processes that open handles and access Lsass, especially those with unknown entries in the CallTrace. An UNKNOWN in CallTrace could indicate that the process is using non-standard or obfuscated code to interact with Lsass, potentially in an attempt to evade detection while accessing sensitive security information.","inputType":"MARKDOWN"},"output":[{"execution_time":"0.017 ms","outputType":"MARKDOWN","result":"*** Analytic II ***\n\n Look for processes that open handles and access Lsass, especially those with unknown entries in the CallTrace. An UNKNOWN in CallTrace could indicate that the process is using non-standard or obfuscated code to interact with Lsass, potentially in an attempt to evade detection while accessing sensitive security information."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T14:07:50.449Z","dateModified":"2024-08-28T14:09:26.025Z","id":"paragraph_b9efb881-3493-44b5-bafc-f03fc1689ccf","input":{"inputText":"%ppl\nsource = lsass-memory* | where Channel =\"Microsoft-Windows-Sysmon/Operational\" | where EventID = '10' | where query_string(['TargetImage'], '*lsass.exe') | where query_string(['CallTrace'], '*UNKNOWN*') | fields @timestamp,Hostname,SourceImage,TargetImage,GrantedAccess,SourceProcessGUID,CallTrace\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.023 ms","outputType":"QUERY","result":"{\"schema\":[{\"name\":\"@timestamp\",\"type\":\"timestamp\"},{\"name\":\"Hostname\",\"type\":\"string\"},{\"name\":\"SourceImage\",\"type\":\"string\"},{\"name\":\"TargetImage\",\"type\":\"string\"},{\"name\":\"GrantedAccess\",\"type\":\"string\"},{\"name\":\"SourceProcessGUID\",\"type\":\"string\"},{\"name\":\"CallTrace\",\"type\":\"string\"}],\"datarows\":[[\"2020-08-07 14:32:57.589\",\"WORKSTATION5.theshire.local\",\"C:\\\\windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\",\"C:\\\\windows\\\\system32\\\\lsass.exe\",\"0x1010\",\"{297bc33e-65d0-5f2d-8207-000000000400}\",\"C:\\\\windows\\\\SYSTEM32\\\\ntdll.dll+9c534|C:\\\\windows\\\\System32\\\\KERNELBASE.dll+2726e|UNKNOWN(000002EE319439BF)\"]],\"total\":1,\"size\":1}"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T11:41:06.519Z","dateModified":"2024-09-02T12:56:24.488Z","id":"paragraph_d28dad48-110f-4e4d-b91a-f6d5bef49cb0","input":{"inputText":"%md \n*** Analytic III ***\n\nLooking for processes loading several known DLLs loaded by tools like Mimikatz to interact with credentials.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | --Process Loaded Dll--    | 7     |\n\n\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.024 ms","outputType":"MARKDOWN","result":"\n*** Analytic III ***\n\nLooking for processes loading several known DLLs loaded by tools like Mimikatz to interact with credentials.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | --Process Loaded Dll--    | 7     |\n\n\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T14:09:44.844Z","dateModified":"2024-08-28T14:40:56.833Z","id":"paragraph_4a323e05-cce7-480e-b99a-6082b32f8875","input":{"inputText":"%ppl\nsource = lsass-memory* | where Channel =\"Microsoft-Windows-Sysmon/Operational\" | where EventID = '7' | where query_string(['ImageLoaded'], '*samlib.dll') OR query_string(['ImageLoaded'], '*vaultcli.dll') OR query_string(['ImageLoaded'], '*hid.dll') OR  query_string(['ImageLoaded'], '*winscard.dll') OR  query_string(['ImageLoaded'], '*cryptdll.dll')| where @timestamp >= '2020-08-01 00:00:00.000' and @timestamp <= '2020-10-20 00:00:00.000'| stats count() as count by ProcessGuid, Image | fields ProcessGuid, Image, count\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.011 ms","outputType":"QUERY","result":"{\"schema\":[{\"name\":\"ProcessGuid\",\"type\":\"string\"},{\"name\":\"Image\",\"type\":\"string\"},{\"name\":\"count\",\"type\":\"integer\"}],\"datarows\":[[\"{297bc33e-65d0-5f2d-8207-000000000400}\",\"C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\",5]],\"total\":1,\"size\":1}"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T12:09:18.531Z","dateModified":"2024-09-02T12:57:54.078Z","id":"paragraph_a6a80fe0-96a2-4427-bd72-31ea952122a6","input":{"inputText":"%md\n\n*** Analytic IV ***\n\nJoin processes opening a handle and accessing LSASS with potential DLLs loaded in memory and processes loading a few known DLLs.","inputType":"MARKDOWN"},"output":[{"execution_time":"0.017 ms","outputType":"MARKDOWN","result":"\n*** Analytic IV ***\n\nJoin processes opening a handle and accessing LSASS with potential DLLs loaded in memory and processes loading a few known DLLs."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T14:17:01.599Z","dateModified":"2024-08-28T14:46:00.461Z","id":"paragraph_f3c4d9e0-7e39-4617-b3d8-12de6d4824e3","input":{"inputText":"%ppl\nsource = lsass-memory* | where Channel =\"Microsoft-Windows-Sysmon/Operational\" | where EventID = '7' | where query_string(['ImageLoaded'], '*samlib.dll') OR query_string(['ImageLoaded'], '*vaultcli.dll') OR query_string(['ImageLoaded'], '*hid.dll') OR  query_string(['ImageLoaded'], '*winscard.dll') OR  query_string(['ImageLoaded'], '*cryptdll.dll')| where @timestamp >= '2020-06-01 00:00:00.000' and @timestamp <= '2020-10-20 00:00:00.000'| fields ProcessGuid, Image\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.010 ms","outputType":"QUERY","result":"{\"schema\":[{\"name\":\"ProcessGuid\",\"type\":\"string\"},{\"name\":\"Image\",\"type\":\"string\"}],\"datarows\":[[\"{297bc33e-65d0-5f2d-8207-000000000400}\",\"C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\"],[\"{297bc33e-65d0-5f2d-8207-000000000400}\",\"C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\"],[\"{297bc33e-65d0-5f2d-8207-000000000400}\",\"C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\"],[\"{297bc33e-65d0-5f2d-8207-000000000400}\",\"C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\"],[\"{297bc33e-65d0-5f2d-8207-000000000400}\",\"C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\"]],\"total\":5,\"size\":5}"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T14:20:10.485Z","dateModified":"2024-08-28T15:00:41.494Z","id":"paragraph_5f934e67-b190-4872-92c7-89020f5f7219","input":{"inputText":"%ppl\n\nsource = lsass-memory* | where Channel =\"Microsoft-Windows-Sysmon/Operational\" | where EventID = '10' | where query_string(['TargetImage'], '*lsass.exe') | where query_string(['CallTrace'], '*UNKNOWN*') |where SourceProcessGUID = '{297bc33e-65d0-5f2d-8207-000000000400}'|fields @timestamp, Hostname","inputType":"MARKDOWN"},"output":[{"execution_time":"0.009 ms","outputType":"QUERY","result":"{\"schema\":[{\"name\":\"@timestamp\",\"type\":\"timestamp\"},{\"name\":\"Hostname\",\"type\":\"string\"}],\"datarows\":[[\"2020-08-07 14:32:57.589\",\"WORKSTATION5.theshire.local\"]],\"total\":1,\"size\":1}"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T12:21:09.661Z","dateModified":"2024-09-02T12:21:31.175Z","id":"paragraph_842b50f8-9797-4b75-8d10-4aca040ddbde","input":{"inputText":"%md\nProvided by miter attack","inputType":"MARKDOWN"},"output":[{"execution_time":"0.021 ms","outputType":"MARKDOWN","result":"Provided by miter attack"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T12:11:42.239Z","dateModified":"2024-09-02T12:18:31.726Z","id":"paragraph_d0919701-3200-4bb2-97ea-9ad7e5229865","input":{"inputText":"%ppl\nsource = lsass-memory* | where Channel=\"Microsoft-Windows-Sysmon/Operational\" | where EventID=\"10\" AND TargetImage= \"lsass.exe\" | Where GrantedAccess= \"0x1410\" OR GrantedAccess= \"0x1010\" OR GrantedAccess=\"0x1438\" OR GrantedAccess=\"0x143a\" OR GrantedAccess=\"0x1418\" | where CallTrace=\"C:\\windows\\SYSTEM32\\ntdll.dll+|C:\\windows\\System32\\KERNELBASE.dll+20edd|UNKNOWN()\"| fields Hostname, @timestamp, Image","inputType":"MARKDOWN"},"output":[{"execution_time":"0.016 ms","outputType":"QUERY","result":"{\"schema\":[{\"name\":\"Hostname\",\"type\":\"string\"},{\"name\":\"@timestamp\",\"type\":\"timestamp\"},{\"name\":\"Image\",\"type\":\"string\"}],\"datarows\":[],\"total\":0,\"size\":0}"}]}],"savedNotebook":{"backend":".kibana_1.0","dateCreated":"2024-08-28T14:03:48.917Z","dateModified":"2024-11-25T12:03:12.951Z","name":"LSASS Memory Read Access","paragraphs":[{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-30T11:25:35.445Z","dateModified":"2024-11-25T12:03:12.951Z","id":"paragraph_29d5cbf1-2132-47f9-9b34-2db7a4687fed","input":{"inputText":"%md\nThe purpose of this notebook is to demonstrate how OpenSearch can support threat hunting activities using the Piped Processing Language (PPL).\n\n** Acknowlegement **\n\nThis playbook is inspired by a similar hunt created by the Threat Hunter Playbook Community [Threat Hunter Playbook](https://github.com/OTRF/ThreatHunter-Playbook/tree/master). ","inputType":"MARKDOWN"},"output":[{"execution_time":"0.026 ms","outputType":"MARKDOWN","result":"The purpose of this notebook is to demonstrate how OpenSearch can support threat hunting activities using the Piped Processing Language (PPL).\n\n** Acknowlegement **\n\nThis playbook is inspired by a similar hunt created by the Threat Hunter Playbook Community [Threat Hunter Playbook](https://github.com/OTRF/ThreatHunter-Playbook/tree/master). "}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-30T11:32:30.621Z","dateModified":"2024-11-25T12:02:39.411Z","id":"paragraph_e32294f0-27e9-466c-a8fc-2ac5b63bc9e6","input":{"inputText":"%md\n** Hypothesis**\n\nAdversaries might retrieve credential data from the process memory of the Local Security Authority Subsystem Service (LSASS).\n\n\n** Technical Context**\n\nWhen a user logs on to a system, the Local Security Authority Subsystem Service (LSASS) process in memory generates and stores various types of credentials. These credentials enabling single sign-on (SSO), allowing the user to access multiple resources without needing to re-authenticate each time. The stored credential data can include Kerberos tickets, NTLM password hashes, and LM password hashes. Additionally, LSASS may store clear-text passwords to support legacy authentication protocols like WDigest and Security Support Provider (SSP) authentication.","inputType":"MARKDOWN"},"output":[{"execution_time":"0.026 ms","outputType":"MARKDOWN","result":"** Hypothesis**\n\nAdversaries might retrieve credential data from the process memory of the Local Security Authority Subsystem Service (LSASS).\n\n\n** Technical Context**\n\nWhen a user logs on to a system, the Local Security Authority Subsystem Service (LSASS) process in memory generates and stores various types of credentials. These credentials enabling single sign-on (SSO), allowing the user to access multiple resources without needing to re-authenticate each time. The stored credential data can include Kerberos tickets, NTLM password hashes, and LM password hashes. Additionally, LSASS may store clear-text passwords to support legacy authentication protocols like WDigest and Security Support Provider (SSP) authentication."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-30T15:03:34.684Z","dateModified":"2024-11-25T12:02:52.978Z","id":"paragraph_89e3ed39-e080-428b-8a25-f071a81db663","input":{"inputText":"%md\n** Pre-Recorded Security Datasets**\n\n| **Metadata**   | **Value** |\n|------------|-----------|\n| **docs**   | [Link for document page](https://securitydatasets.com/notebooks/atomic/windows/credential_access/SDWIN-190518202151.html) |\n| **link**   | [Link for download dataset](https://raw.githubusercontent.com/OTRF/Security-Datasets/master/datasets/atomic/windows/credential_access/host/empire_mimikatz_logonpasswords.zip) |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.026 ms","outputType":"MARKDOWN","result":"** Pre-Recorded Security Datasets**\n\n| **Metadata**   | **Value** |\n|------------|-----------|\n| **docs**   | [Link for document page](https://securitydatasets.com/notebooks/atomic/windows/credential_access/SDWIN-190518202151.html) |\n| **link**   | [Link for download dataset](https://raw.githubusercontent.com/OTRF/Security-Datasets/master/datasets/atomic/windows/credential_access/host/empire_mimikatz_logonpasswords.zip) |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T10:48:41.545Z","dateModified":"2024-09-02T12:55:43.651Z","id":"paragraph_5e6f6c77-bc3b-409e-bf82-286aaaf92afd","input":{"inputText":"%md\n*** Analytic I ***\n\nMonitor for non-system accounts that gain access to and interact with LSASS. While many attackers might inject their malicious code into a system process to avoid detection, there are instances where they do not escalate privileges to the System level. Instead, they use an account with administrative rights, as this is sufficient to access LSASS. Detecting such behavior can help identify potential threats that don’t follow more sophisticated methods.\n\n| Data source | Event Provider                        | Relationship               | Event |\n|-------------|---------------------------------------|----------------------------|-------|\n| Process     | Microsoft-Windows-Security-Auditing   | Process accessed Process    | 4663  |\n| Process     | Microsoft-Windows-Security-Auditing   | Process requested_access Process | 4656  |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.013 ms","outputType":"MARKDOWN","result":"*** Analytic I ***\n\nMonitor for non-system accounts that gain access to and interact with LSASS. While many attackers might inject their malicious code into a system process to avoid detection, there are instances where they do not escalate privileges to the System level. Instead, they use an account with administrative rights, as this is sufficient to access LSASS. Detecting such behavior can help identify potential threats that don’t follow more sophisticated methods.\n\n| Data source | Event Provider                        | Relationship               | Event |\n|-------------|---------------------------------------|----------------------------|-------|\n| Process     | Microsoft-Windows-Security-Auditing   | Process accessed Process    | 4663  |\n| Process     | Microsoft-Windows-Security-Auditing   | Process requested_access Process | 4656  |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T14:03:51.903Z","dateModified":"2024-10-17T08:42:10.241Z","id":"paragraph_ebd3110f-7949-47e2-b75a-e794a4566497","input":{"inputText":"%ppl\nsource = lsass-memory* | where match(Channel, 'Security') | where  EventID = '4656' OR EventID = '4663'  | where query_string(['ObjectName'], '*lsass.exe') | where not query_string(['SubjectUserName'], '*$') | fields @timestamp , Hostname, SubjectUserName, ProcessName, ObjectName, AccessMask, EventID\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.033 ms","outputType":"QUERY","result":"\nsource = lsass-memory* | where match(Channel, 'Security') | where  EventID = '4656' OR EventID = '4663'  | where query_string(['ObjectName'], '*lsass.exe') | where not query_string(['SubjectUserName'], '*$') | fields @timestamp , Hostname, SubjectUserName, ProcessName, ObjectName, AccessMask, EventID\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T11:20:12.423Z","dateModified":"2024-09-02T12:55:58.890Z","id":"paragraph_0b6c67ab-ab11-4438-b06e-8f5477e01555","input":{"inputText":"%md\n*** Analytic II ***\n\n Look for processes that open handles and access Lsass, especially those with unknown entries in the CallTrace. An UNKNOWN in CallTrace could indicate that the process is using non-standard or obfuscated code to interact with Lsass, potentially in an attempt to evade detection while accessing sensitive security information.","inputType":"MARKDOWN"},"output":[{"execution_time":"0.017 ms","outputType":"MARKDOWN","result":"*** Analytic II ***\n\n Look for processes that open handles and access Lsass, especially those with unknown entries in the CallTrace. An UNKNOWN in CallTrace could indicate that the process is using non-standard or obfuscated code to interact with Lsass, potentially in an attempt to evade detection while accessing sensitive security information."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T14:07:50.449Z","dateModified":"2024-08-28T14:09:26.025Z","id":"paragraph_b9efb881-3493-44b5-bafc-f03fc1689ccf","input":{"inputText":"%ppl\nsource = lsass-memory* | where Channel =\"Microsoft-Windows-Sysmon/Operational\" | where EventID = '10' | where query_string(['TargetImage'], '*lsass.exe') | where query_string(['CallTrace'], '*UNKNOWN*') | fields @timestamp,Hostname,SourceImage,TargetImage,GrantedAccess,SourceProcessGUID,CallTrace\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.023 ms","outputType":"QUERY","result":"\nsource = lsass-memory* | where Channel =\"Microsoft-Windows-Sysmon/Operational\" | where EventID = '10' | where query_string(['TargetImage'], '*lsass.exe') | where query_string(['CallTrace'], '*UNKNOWN*') | fields @timestamp,Hostname,SourceImage,TargetImage,GrantedAccess,SourceProcessGUID,CallTrace\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T11:41:06.519Z","dateModified":"2024-09-02T12:56:24.488Z","id":"paragraph_d28dad48-110f-4e4d-b91a-f6d5bef49cb0","input":{"inputText":"%md \n*** Analytic III ***\n\nLooking for processes loading several known DLLs loaded by tools like Mimikatz to interact with credentials.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | --Process Loaded Dll--    | 7     |\n\n\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.024 ms","outputType":"MARKDOWN","result":"\n*** Analytic III ***\n\nLooking for processes loading several known DLLs loaded by tools like Mimikatz to interact with credentials.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | --Process Loaded Dll--    | 7     |\n\n\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T14:09:44.844Z","dateModified":"2024-08-28T14:40:56.833Z","id":"paragraph_4a323e05-cce7-480e-b99a-6082b32f8875","input":{"inputText":"%ppl\nsource = lsass-memory* | where Channel =\"Microsoft-Windows-Sysmon/Operational\" | where EventID = '7' | where query_string(['ImageLoaded'], '*samlib.dll') OR query_string(['ImageLoaded'], '*vaultcli.dll') OR query_string(['ImageLoaded'], '*hid.dll') OR  query_string(['ImageLoaded'], '*winscard.dll') OR  query_string(['ImageLoaded'], '*cryptdll.dll')| where @timestamp >= '2020-08-01 00:00:00.000' and @timestamp <= '2020-10-20 00:00:00.000'| stats count() as count by ProcessGuid, Image | fields ProcessGuid, Image, count\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.011 ms","outputType":"QUERY","result":"\nsource = lsass-memory* | where Channel =\"Microsoft-Windows-Sysmon/Operational\" | where EventID = '7' | where query_string(['ImageLoaded'], '*samlib.dll') OR query_string(['ImageLoaded'], '*vaultcli.dll') OR query_string(['ImageLoaded'], '*hid.dll') OR  query_string(['ImageLoaded'], '*winscard.dll') OR  query_string(['ImageLoaded'], '*cryptdll.dll')| where @timestamp >= '2020-08-01 00:00:00.000' and @timestamp <= '2020-10-20 00:00:00.000'| stats count() as count by ProcessGuid, Image | fields ProcessGuid, Image, count\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T12:09:18.531Z","dateModified":"2024-09-02T12:57:54.078Z","id":"paragraph_a6a80fe0-96a2-4427-bd72-31ea952122a6","input":{"inputText":"%md\n\n*** Analytic IV ***\n\nJoin processes opening a handle and accessing LSASS with potential DLLs loaded in memory and processes loading a few known DLLs.","inputType":"MARKDOWN"},"output":[{"execution_time":"0.017 ms","outputType":"MARKDOWN","result":"\n*** Analytic IV ***\n\nJoin processes opening a handle and accessing LSASS with potential DLLs loaded in memory and processes loading a few known DLLs."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T14:17:01.599Z","dateModified":"2024-08-28T14:46:00.461Z","id":"paragraph_f3c4d9e0-7e39-4617-b3d8-12de6d4824e3","input":{"inputText":"%ppl\nsource = lsass-memory* | where Channel =\"Microsoft-Windows-Sysmon/Operational\" | where EventID = '7' | where query_string(['ImageLoaded'], '*samlib.dll') OR query_string(['ImageLoaded'], '*vaultcli.dll') OR query_string(['ImageLoaded'], '*hid.dll') OR  query_string(['ImageLoaded'], '*winscard.dll') OR  query_string(['ImageLoaded'], '*cryptdll.dll')| where @timestamp >= '2020-06-01 00:00:00.000' and @timestamp <= '2020-10-20 00:00:00.000'| fields ProcessGuid, Image\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.010 ms","outputType":"QUERY","result":"\nsource = lsass-memory* | where Channel =\"Microsoft-Windows-Sysmon/Operational\" | where EventID = '7' | where query_string(['ImageLoaded'], '*samlib.dll') OR query_string(['ImageLoaded'], '*vaultcli.dll') OR query_string(['ImageLoaded'], '*hid.dll') OR  query_string(['ImageLoaded'], '*winscard.dll') OR  query_string(['ImageLoaded'], '*cryptdll.dll')| where @timestamp >= '2020-06-01 00:00:00.000' and @timestamp <= '2020-10-20 00:00:00.000'| fields ProcessGuid, Image\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T14:20:10.485Z","dateModified":"2024-08-28T15:00:41.494Z","id":"paragraph_5f934e67-b190-4872-92c7-89020f5f7219","input":{"inputText":"%ppl\n\nsource = lsass-memory* | where Channel =\"Microsoft-Windows-Sysmon/Operational\" | where EventID = '10' | where query_string(['TargetImage'], '*lsass.exe') | where query_string(['CallTrace'], '*UNKNOWN*') |where SourceProcessGUID = '{297bc33e-65d0-5f2d-8207-000000000400}'|fields @timestamp, Hostname","inputType":"MARKDOWN"},"output":[{"execution_time":"0.009 ms","outputType":"QUERY","result":"\n\nsource = lsass-memory* | where Channel =\"Microsoft-Windows-Sysmon/Operational\" | where EventID = '10' | where query_string(['TargetImage'], '*lsass.exe') | where query_string(['CallTrace'], '*UNKNOWN*') |where SourceProcessGUID = '{297bc33e-65d0-5f2d-8207-000000000400}'|fields @timestamp, Hostname"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-04T08:04:15.126Z","dateModified":"2024-09-04T08:04:39.957Z","id":"paragraph_8c06affb-4355-46ab-9963-d147658d9bd9","input":{"inputText":"%md\n\nProvided by MITRE ATTCK","inputType":"MARKDOWN"},"output":[{"execution_time":"0.037 ms","outputType":"MARKDOWN","result":"\nProvided by MITRE ATTCK"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-04T08:04:43.607Z","dateModified":"2024-09-04T08:09:55.688Z","id":"paragraph_61b2d458-a04d-49b6-bc71-1cde00bbf702","input":{"inputText":"%ppl\nsource = lsass-memory* | where Channel=\"Microsoft-Windows-Sysmon/Operational\" | where EventID=\"10\" AND query_string([\"TargetImage\"], \"*lsass.exe\") |Where GrantedAccess= \"0x1410\" OR GrantedAccess= \"0x1010\" OR GrantedAccess=\"0x1438\" OR GrantedAccess=\"0x143a\" OR GrantedAccess=\"0x1418\" | where query_string([\"CallTrace\"], \"*UNKNOWN*\")|  fields Hostname, @timestamp, Image, CallTrace","inputType":"MARKDOWN"},"output":[{"execution_time":"0.021 ms","outputType":"QUERY","result":"\nsource = lsass-memory* | where Channel=\"Microsoft-Windows-Sysmon/Operational\" | where EventID=\"10\" AND query_string([\"TargetImage\"], \"*lsass.exe\") |Where GrantedAccess= \"0x1410\" OR GrantedAccess= \"0x1010\" OR GrantedAccess=\"0x1438\" OR GrantedAccess=\"0x143a\" OR GrantedAccess=\"0x1418\" | where query_string([\"CallTrace\"], \"*UNKNOWN*\")|  fields Hostname, @timestamp, Image, CallTrace"}]}],"path":"LSASS Memory Read Access"}},"id":"59202650-6546-11ef-8b1b-6bee4b7c80eb","references":[],"type":"observability-notebook","updated_at":"2024-11-25T12:03:12.951Z","version":"Wzk5MSw1XQ=="}
{"attributes":{"savedNotebook":{"backend":".kibana_1.0","dateCreated":"2024-08-29T09:11:32.254Z","dateModified":"2024-11-25T12:03:35.827Z","name":"Local PowerShell Execution","paragraphs":[{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-25T11:52:42.705Z","dateModified":"2024-11-25T12:03:35.827Z","id":"paragraph_6b75ef30-a09e-4567-974f-5932cac7a43a","input":{"inputText":"%md\nThe purpose of this notebook is to demonstrate how OpenSearch can support threat hunting activities using the Piped Processing Language (PPL).\n\n** Acknowlegement **\n\nThis playbook is inspired by a similar hunt created by the Threat Hunter Playbook Community [Threat Hunter Playbook](https://github.com/OTRF/ThreatHunter-Playbook/tree/master). ","inputType":"MARKDOWN"},"output":[{"execution_time":"0.088 ms","outputType":"MARKDOWN","result":"The purpose of this notebook is to demonstrate how OpenSearch can support threat hunting activities using the Piped Processing Language (PPL).\n\n** Acknowlegement **\n\nThis playbook is inspired by a similar hunt created by the Threat Hunter Playbook Community [Threat Hunter Playbook](https://github.com/OTRF/ThreatHunter-Playbook/tree/master). "}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T12:33:08.747Z","dateModified":"2024-11-25T11:50:21.651Z","id":"paragraph_dd48f5d4-5385-48e0-a82d-32c5fae10fe2","input":{"inputText":"%md\n** Acknowlegement **\n\nThis notebook is based on methdology from [Threat Hunter Playbook](https://threathunterplaybook.com/intro.html)\n\n** Hypothesis **\n\nAdversaries might abuse PowerShell and scripts for execution.\n\n** Technical Context **\n\nPowerShell commands or scripts can be executed without directly calling the powershell.exe binary. This can be done by leveraging interfaces to PowerShell's underlying System.Management.Automation assembly DLL, which is accessible through the .NET framework and Windows Common Language Interface (CLI).\n\n** Offensive Tradecraft **\n\nAdversaries can leverage PowerShell for various activities, such as gathering information and executing code. For instance, the Start-Process cmdlet can be used to run an executable, while the Invoke-Command cmdlet allows execution of commands either locally or on a remote machine (though administrator privileges are necessary to use PowerShell for remote system connections).","inputType":"MARKDOWN"},"output":[{"execution_time":"0.024 ms","outputType":"MARKDOWN","result":"** Acknowlegement **\n\nThis notebook is based on methdology from [Threat Hunter Playbook](https://threathunterplaybook.com/intro.html)\n\n** Hypothesis **\n\nAdversaries might abuse PowerShell and scripts for execution.\n\n** Technical Context **\n\nPowerShell commands or scripts can be executed without directly calling the powershell.exe binary. This can be done by leveraging interfaces to PowerShell's underlying System.Management.Automation assembly DLL, which is accessible through the .NET framework and Windows Common Language Interface (CLI).\n\n** Offensive Tradecraft **\n\nAdversaries can leverage PowerShell for various activities, such as gathering information and executing code. For instance, the Start-Process cmdlet can be used to run an executable, while the Invoke-Command cmdlet allows execution of commands either locally or on a remote machine (though administrator privileges are necessary to use PowerShell for remote system connections)."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T12:50:24.239Z","dateModified":"2024-09-03T18:36:03.011Z","id":"paragraph_046e0ea4-711f-461b-aba1-60a20942ee6c","input":{"inputText":"%md \n** Pre-Recored Security Datasets **\n\n| **Metadata**   | **Value** |\n|------------|-----------|\n| **docs**   | [Link for document page](\thttps://securitydatasets.com/notebooks/atomic/windows/execution/SDWIN-190518182022.html) |\n| **link**   | [Link for download dataset](https://raw.githubusercontent.com/OTRF/Security-Datasets/master/datasets/atomic/windows/execution/host/empire_launcher_vbs.zip) |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.041 ms","outputType":"MARKDOWN","result":"\n** Pre-Recored Security Datasets **\n\n| **Metadata**   | **Value** |\n|------------|-----------|\n| **docs**   | [Link for document page](\thttps://securitydatasets.com/notebooks/atomic/windows/execution/SDWIN-190518182022.html) |\n| **link**   | [Link for download dataset](https://raw.githubusercontent.com/OTRF/Security-Datasets/master/datasets/atomic/windows/execution/host/empire_launcher_vbs.zip) |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T13:19:22.957Z","dateModified":"2024-09-02T13:20:31.149Z","id":"paragraph_45d1144a-3a4a-48c2-9daf-edee474f8307","input":{"inputText":"%md\n*** Analytic I ***\n\nIn the classic PowerShell log, event ID 400 indicates the start of a new PowerShell host process. Filtering by powershell.exe as the host application can narrow down the results, or leaving it unfiltered will capture all PowerShell host processes.\n\n| Data source | Event Provider                             | Relationship                  | Event |\n|-------------|--------------------------------------------|--------------------------------|-------|\n| Powershell  | Windows PowerShell                         | Application host started       | 400   |\n| Powershell  | Microsoft-Windows-PowerShell/Operational   | User started Application host  | 4103  |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.040 ms","outputType":"MARKDOWN","result":"*** Analytic I ***\n\nIn the classic PowerShell log, event ID 400 indicates the start of a new PowerShell host process. Filtering by powershell.exe as the host application can narrow down the results, or leaving it unfiltered will capture all PowerShell host processes.\n\n| Data source | Event Provider                             | Relationship                  | Event |\n|-------------|--------------------------------------------|--------------------------------|-------|\n| Powershell  | Windows PowerShell                         | Application host started       | 400   |\n| Powershell  | Microsoft-Windows-PowerShell/Operational   | User started Application host  | 4103  |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-29T09:11:51.791Z","dateModified":"2024-11-14T11:23:36.551Z","id":"paragraph_00802e58-b9b8-4727-b770-4a0cba09c96c","input":{"inputText":"%ppl\nsource = local-powershell* | where Channel = \"Microsoft-Windows-PowerShell/Operational\" OR Channel = \"Windows PowerShell\" | where EventID = \"400\" OR EventID = \"4103\" | fields @timestamp, Hostname\n\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.009 ms","outputType":"QUERY","result":"\nsource = local-powershell* | where Channel = \"Microsoft-Windows-PowerShell/Operational\" OR Channel = \"Windows PowerShell\" | where EventID = \"400\" OR EventID = \"4103\" | fields @timestamp, Hostname\n\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T13:21:01.394Z","dateModified":"2024-09-02T14:32:05.526Z","id":"paragraph_285d9703-c1ea-43c9-a9ad-bee959c4c251","input":{"inputText":"%md\n*** Analytic II ***\n\nDetecting non-interactive PowerShell sessions (i.e., those not launched by a user through explorer.exe) may lead to false positives in a production environment. It is advisable to tune any such analytics by including additional logic, such as looking for suspicious parent processes, to help filter these events.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Security-Auditing | Process created Process    | 4688     |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.009 ms","outputType":"MARKDOWN","result":"*** Analytic II ***\n\nDetecting non-interactive PowerShell sessions (i.e., those not launched by a user through explorer.exe) may lead to false positives in a production environment. It is advisable to tune any such analytics by including additional logic, such as looking for suspicious parent processes, to help filter these events.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Security-Auditing | Process created Process    | 4688     |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-29T09:17:02.253Z","dateModified":"2024-08-29T09:25:40.414Z","id":"paragraph_b7c38eb1-dbdd-45ba-a734-8929fd48f9c5","input":{"inputText":"%ppl\nsource = local-powershell*| WHERE match(Channel, \"Security\")  |where EventID = \"4688\" | where query_string([\"NewProcessName\"], \"*powershell.exe\") AND NOT query_string([\"ParentProcessName\"], \"*explorer.exe\")  | fields @timestamp, Hostname, NewProcessName, ParentProcessName, Channel\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.025 ms","outputType":"QUERY","result":"\nsource = local-powershell*| WHERE match(Channel, \"Security\")  |where EventID = \"4688\" | where query_string([\"NewProcessName\"], \"*powershell.exe\") AND NOT query_string([\"ParentProcessName\"], \"*explorer.exe\")  | fields @timestamp, Hostname, NewProcessName, ParentProcessName, Channel\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T14:32:37.110Z","dateModified":"2024-09-02T14:33:15.322Z","id":"paragraph_f49980b8-beda-4082-b76f-623c321e7275","input":{"inputText":"%md\n*** Analytic III ***\n\nDetecting non-interactive PowerShell sessions (i.e., those not launched by a user through explorer.exe) may lead to false positives in a production environment. It is advisable to tune any such analytics by including additional logic, such as looking for suspicious parent processes, to help filter these events.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | Process created Process    | 1     |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.019 ms","outputType":"MARKDOWN","result":"*** Analytic III ***\n\nDetecting non-interactive PowerShell sessions (i.e., those not launched by a user through explorer.exe) may lead to false positives in a production environment. It is advisable to tune any such analytics by including additional logic, such as looking for suspicious parent processes, to help filter these events.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | Process created Process    | 1     |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-29T09:26:39.436Z","dateModified":"2024-08-29T09:28:46.586Z","id":"paragraph_02bea871-90cc-4ce0-a3e9-78fe0b3c164a","input":{"inputText":"%ppl\nsource = local-powershell* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = \"1\" | where query_string([\"Image\"], \"*powershell.exe\") AND NOT query_string([\"ParentImage\"], \"*explorer.exe\") | fields @timestamp, Hostname, Image, ParentImage\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.050 ms","outputType":"QUERY","result":"\nsource = local-powershell* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = \"1\" | where query_string([\"Image\"], \"*powershell.exe\") AND NOT query_string([\"ParentImage\"], \"*explorer.exe\") | fields @timestamp, Hostname, Image, ParentImage\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T14:39:04.296Z","dateModified":"2024-09-02T14:40:35.291Z","id":"paragraph_3363ad3c-f1c8-4197-986c-e90ef3aaf83b","input":{"inputText":"%md\n***Analytic IV ***\n\nMonitor for the loading and/or execution of artifacts related to PowerShell-specific assemblies, such as System.Management.Automation.dll, particularly when associated with unusual process names or locations.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | Process loaded Dll    | 7     |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.011 ms","outputType":"MARKDOWN","result":"***Analytic IV ***\n\nMonitor for the loading and/or execution of artifacts related to PowerShell-specific assemblies, such as System.Management.Automation.dll, particularly when associated with unusual process names or locations.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | Process loaded Dll    | 7     |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-29T09:29:15.778Z","dateModified":"2024-08-29T09:40:28.631Z","id":"paragraph_66fc3d23-c90e-4ee7-9022-e9025ee1b8e8","input":{"inputText":"%ppl\nsource = local-powershell* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = \"7\" | where match(Description, 'system.management.automation') OR query_string([\"ImageLoaded\"], \"*system.management.automation*\") | fields @timestamp, Hostname, Image, ImageLoaded, Description\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.015 ms","outputType":"QUERY","result":"\nsource = local-powershell* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = \"7\" | where match(Description, 'system.management.automation') OR query_string([\"ImageLoaded\"], \"*system.management.automation*\") | fields @timestamp, Hostname, Image, ImageLoaded, Description\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T14:41:42.124Z","dateModified":"2024-09-02T14:43:53.717Z","id":"paragraph_9f81432d-33e8-41e6-b127-a316e3358fa4","input":{"inputText":"%md\n*** Analytic V ***\n\nMonitoring for PSHost* pipes.\n\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | Process created Pipe    | 17     |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.012 ms","outputType":"MARKDOWN","result":"*** Analytic V ***\n\nMonitoring for PSHost* pipes.\n\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | Process created Pipe    | 17     |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-29T09:34:07.374Z","dateModified":"2024-08-29T09:44:48.468Z","id":"paragraph_adea45d4-34db-4459-a8f9-fc3937f7a299","input":{"inputText":"%ppl\nsource = local-powershell* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = \"17\" | where query_string([\"PipeName\"], \"\\pshost*\") | fields @timestamp, Hostname, Image, PipeName\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.016 ms","outputType":"QUERY","result":"\nsource = local-powershell* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = \"17\" | where query_string([\"PipeName\"], \"\\pshost*\") | fields @timestamp, Hostname, Image, PipeName\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-02T14:44:25.444Z","dateModified":"2024-09-02T14:46:17.845Z","id":"paragraph_50f284b1-da26-4dc0-8e20-f037489f6a04","input":{"inputText":"%md\n*** Analytic VI ***\n\nThe PowerShell Named Pipe IPC event identifies the name of the PowerShell AppDomain that initiated, serving as an indicator of PowerShell execution.\n\n\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-PowerShell/Operational | Application domain started    | 53504    |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.012 ms","outputType":"MARKDOWN","result":"*** Analytic VI ***\n\nThe PowerShell Named Pipe IPC event identifies the name of the PowerShell AppDomain that initiated, serving as an indicator of PowerShell execution.\n\n\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-PowerShell/Operational | Application domain started    | 53504    |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-29T09:47:10.526Z","dateModified":"2024-08-29T09:48:17.849Z","id":"paragraph_cf686e61-8385-49ce-8117-401da0b5c212","input":{"inputText":"%ppl\nsource = local-powershell* | where Channel = \"Microsoft-Windows-PowerShell/Operational\" | where EventID = \"53504\" | fields @timestamp, Hostname, Message\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.011 ms","outputType":"QUERY","result":"\nsource = local-powershell* | where Channel = \"Microsoft-Windows-PowerShell/Operational\" | where EventID = \"53504\" | fields @timestamp, Hostname, Message\n\n"}]}],"path":"Local PowerShell Execution"}},"id":"aedfa2f0-65e6-11ef-8b1b-6bee4b7c80eb","references":[],"type":"observability-notebook","updated_at":"2024-11-25T12:03:35.827Z","version":"Wzk5Myw1XQ=="}
{"attributes":{"savedNotebook":{"backend":".kibana_1.0","dateCreated":"2024-08-28T15:46:33.678Z","dateModified":"2024-11-25T12:03:25.298Z","name":"wmi-eventing","paragraphs":[{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-25T11:46:00.122Z","dateModified":"2024-11-25T12:03:25.298Z","id":"paragraph_bbd5ba7d-d179-4665-a294-1b3c1f7e49dc","input":{"inputText":"%md\nThe purpose of this notebook is to demonstrate how OpenSearch can support threat hunting activities using the Piped Processing Language (PPL).\n\n** Acknowlegement **\n\nThis playbook is inspired by a similar hunt created by the Threat Hunter Playbook Community [Threat Hunter Playbook](https://github.com/OTRF/ThreatHunter-Playbook/tree/master).","inputType":"MARKDOWN"},"output":[{"execution_time":"0.014 ms","outputType":"MARKDOWN","result":"The purpose of this notebook is to demonstrate how OpenSearch can support threat hunting activities using the Piped Processing Language (PPL).\n\n** Acknowlegement **\n\nThis playbook is inspired by a similar hunt created by the Threat Hunter Playbook Community [Threat Hunter Playbook](https://github.com/OTRF/ThreatHunter-Playbook/tree/master)."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T19:05:51.931Z","dateModified":"2024-11-14T11:15:45.174Z","id":"paragraph_67ab473a-20ba-43ca-94eb-7a6edd665f30","input":{"inputText":"%md\n** Hypothesis **\n\nAdversaries might exploit Windows Management Instrumentation (WMI) to run harmful commands and deliver payloads.\n\n** Technical Context **\n\nWMI (Windows Management Instrumentation) is Microsoft’s version of Web-Based Enterprise Management (WBEM) and the Common Information Model (CIM). These standards aim to offer a universal approach to gathering and transmitting data about managed components in an enterprise environment. In WMI, a managed component could include a running process, registry key, installed service, or file information. Essentially, Microsoft’s implementation of these standards involves WMI objects—class instances that represent detailed operating system data, such as Win32_Process, Win32_Service, AntiVirusProduct, and Win32_StartupCommand.\n\n** Offensive Tradecraft **\n\nFrom an attacker's standpoint, WMI's capability to respond to almost any imaginable event makes it a powerful method for maintaining persistence.\n\nThree key components:\n\nFilter: Defines the event that will trigger an action.\n\nConsumer: Specifies the action to be taken when the filter is triggered.\n\nBinding: Links the filter and consumer, ensuring the specified action is executed.","inputType":"MARKDOWN"},"output":[{"execution_time":"0.027 ms","outputType":"MARKDOWN","result":"** Hypothesis **\n\nAdversaries might exploit Windows Management Instrumentation (WMI) to run harmful commands and deliver payloads.\n\n** Technical Context **\n\nWMI (Windows Management Instrumentation) is Microsoft’s version of Web-Based Enterprise Management (WBEM) and the Common Information Model (CIM). These standards aim to offer a universal approach to gathering and transmitting data about managed components in an enterprise environment. In WMI, a managed component could include a running process, registry key, installed service, or file information. Essentially, Microsoft’s implementation of these standards involves WMI objects—class instances that represent detailed operating system data, such as Win32_Process, Win32_Service, AntiVirusProduct, and Win32_StartupCommand.\n\n** Offensive Tradecraft **\n\nFrom an attacker's standpoint, WMI's capability to respond to almost any imaginable event makes it a powerful method for maintaining persistence.\n\nThree key components:\n\nFilter: Defines the event that will trigger an action.\n\nConsumer: Specifies the action to be taken when the filter is triggered.\n\nBinding: Links the filter and consumer, ensuring the specified action is executed."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T19:15:28.725Z","dateModified":"2024-09-03T19:16:50.819Z","id":"paragraph_9cf04904-4298-47e8-9b03-cc18f93ede03","input":{"inputText":"%md \n** Pre-Recored Security Datasets **\n\n| **Metadata**   | **Value** |\n|------------|-----------|\n| **docs**   | [Link for document page](\thttps://securitydatasets.com/notebooks/atomic/windows/persistence/SDWIN-190518184306.html) |\n| **link**   | [Link for download dataset](https://raw.githubusercontent.com/OTRF/Security-Datasets/master/datasets/atomic/windows/persistence/host/empire_wmi_local_event_subscriptions_elevated_user.zip) |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.017 ms","outputType":"MARKDOWN","result":"\n** Pre-Recored Security Datasets **\n\n| **Metadata**   | **Value** |\n|------------|-----------|\n| **docs**   | [Link for document page](\thttps://securitydatasets.com/notebooks/atomic/windows/persistence/SDWIN-190518184306.html) |\n| **link**   | [Link for download dataset](https://raw.githubusercontent.com/OTRF/Security-Datasets/master/datasets/atomic/windows/persistence/host/empire_wmi_local_event_subscriptions_elevated_user.zip) |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T19:26:32.282Z","dateModified":"2024-09-03T19:33:08.833Z","id":"paragraph_24697efd-3a78-453d-b167-2c3f26d7aa86","input":{"inputText":"%md\n*** Analytic I ***\n\nLooking for WMI event filters registered.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| WMI object  | Microsoft-Windows-Sysmon/Operational  | User created Wmi filter   | 19    |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.018 ms","outputType":"MARKDOWN","result":"*** Analytic I ***\n\nLooking for WMI event filters registered.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| WMI object  | Microsoft-Windows-Sysmon/Operational  | User created Wmi filter   | 19    |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T15:46:36.800Z","dateModified":"2024-08-28T15:48:21.079Z","id":"paragraph_fc85cda0-5e40-4d33-b0db-6f61a5e4d961","input":{"inputText":"%ppl\nsource = wmi* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = '19' | fields @timestamp, Hostname, User, EventNamespace, Name\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.037 ms","outputType":"QUERY","result":"\nsource = wmi* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = '19' | fields @timestamp, Hostname, User, EventNamespace, Name\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T19:47:40.561Z","dateModified":"2024-09-03T19:50:04.571Z","id":"paragraph_3b25bb87-ffbb-4dc8-a2da-46d2cf983bd7","input":{"inputText":"%md\n*** Analytic II ***\n\nLooking for WMI event consumers registered.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| WMI object  | Microsoft-Windows-Sysmon/Operational  | User created Wmi consumer   | 20    |","inputType":"MARKDOWN"},"output":[{"execution_time":"0.025 ms","outputType":"MARKDOWN","result":"*** Analytic II ***\n\nLooking for WMI event consumers registered.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| WMI object  | Microsoft-Windows-Sysmon/Operational  | User created Wmi consumer   | 20    |"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T15:48:51.098Z","dateModified":"2024-08-28T15:49:33.296Z","id":"paragraph_e3d2453f-ab6f-4e10-ad6d-c7da4e72ed11","input":{"inputText":"%ppl\nsource = wmi* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = '20' | fields @timestamp, Hostname, User,  Name, Type, Destination","inputType":"MARKDOWN"},"output":[{"execution_time":"0.016 ms","outputType":"QUERY","result":"\nsource = wmi* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = '20' | fields @timestamp, Hostname, User,  Name, Type, Destination"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T19:48:50.575Z","dateModified":"2024-09-03T19:50:35.066Z","id":"paragraph_fe010247-22ae-4e8d-99e3-bf6ab2c4d495","input":{"inputText":"%md\n*** Analytic III ***\n\nLooking for WMI consumers binding to filters.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| WMI object  | Microsoft-Windows-Sysmon/Operational  | User created Wmi subscription   | 21    |","inputType":"MARKDOWN"},"output":[{"execution_time":"0.020 ms","outputType":"MARKDOWN","result":"*** Analytic III ***\n\nLooking for WMI consumers binding to filters.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| WMI object  | Microsoft-Windows-Sysmon/Operational  | User created Wmi subscription   | 21    |"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T15:51:49.148Z","dateModified":"2024-08-28T15:52:25.093Z","id":"paragraph_3768e229-c624-4b2c-8353-f3c91231822c","input":{"inputText":"%ppl\nsource = wmi* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = '21' | fields @timestamp, Hostname, User, Operation, Consumer, Filter","inputType":"MARKDOWN"},"output":[{"execution_time":"0.016 ms","outputType":"QUERY","result":"\nsource = wmi* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = '21' | fields @timestamp, Hostname, User, Operation, Consumer, Filter"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T19:51:02.065Z","dateModified":"2024-09-03T19:51:59.244Z","id":"paragraph_c993d9af-cf4b-41fc-a9eb-6d8224d80ab2","input":{"inputText":"%md\n*** Analytic IV ***\n\nLooking for events related to the registration of FilterToConsumerBinding.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| WMI object  | Microsoft-Windows-WMI-Activity/Operational  | Wmi subscription created   | 5861    |","inputType":"MARKDOWN"},"output":[{"execution_time":"0.019 ms","outputType":"MARKDOWN","result":"*** Analytic IV ***\n\nLooking for events related to the registration of FilterToConsumerBinding.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| WMI object  | Microsoft-Windows-WMI-Activity/Operational  | Wmi subscription created   | 5861    |"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-28T15:52:54.642Z","dateModified":"2024-08-28T15:54:03.530Z","id":"paragraph_c3102f5c-a8b2-49c9-a417-91a146ddf9c2","input":{"inputText":"%ppl\nsource = wmi* | where Channel = \"Microsoft-Windows-WMI-Activity/Operational\" | where EventID = '5861' | fields @timestamp, Hostname, Message","inputType":"MARKDOWN"},"output":[{"execution_time":"0.016 ms","outputType":"QUERY","result":"\nsource = wmi* | where Channel = \"Microsoft-Windows-WMI-Activity/Operational\" | where EventID = '5861' | fields @timestamp, Hostname, Message"}]}],"path":"wmi-eventing"}},"id":"b39c06e0-6554-11ef-8b1b-6bee4b7c80eb","references":[],"type":"observability-notebook","updated_at":"2024-11-25T12:03:25.298Z","version":"Wzk5Miw1XQ=="}
{"attributes":{"savedNotebook":{"backend":".kibana_1.0","dateCreated":"2024-08-29T08:30:16.916Z","dateModified":"2024-11-25T12:03:55.294Z","name":"PowerShell-Remote-Session","paragraphs":[{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-25T12:03:52.296Z","dateModified":"2024-11-25T12:03:55.294Z","id":"paragraph_15f1c64a-8489-40f6-97d4-b461484732b7","input":{"inputText":"%md\nThe purpose of this notebook is to demonstrate how OpenSearch can support threat hunting activities using the Piped Processing Language (PPL).\n\n** Acknowlegement **\n\nThis playbook is inspired by a similar hunt created by the Threat Hunter Playbook Community [Threat Hunter Playbook](https://github.com/OTRF/ThreatHunter-Playbook/tree/master). ","inputType":"MARKDOWN"},"output":[{"execution_time":"0.037 ms","outputType":"MARKDOWN","result":"The purpose of this notebook is to demonstrate how OpenSearch can support threat hunting activities using the Piped Processing Language (PPL).\n\n** Acknowlegement **\n\nThis playbook is inspired by a similar hunt created by the Threat Hunter Playbook Community [Threat Hunter Playbook](https://github.com/OTRF/ThreatHunter-Playbook/tree/master). "}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T18:35:03.759Z","dateModified":"2024-09-03T18:35:33.524Z","id":"paragraph_28911d47-025c-4205-ad7d-434dd4136575","input":{"inputText":"%md\n** Hypothesis **\n\nAdversaries might abuse remote PowerShell commands and scripts for execution.\n\n** Technical Context **\n\nPowerShell commands or scripts can be executed without directly calling the powershell.exe binary. This can be done by leveraging interfaces to PowerShell's underlying System.Management.Automation assembly DLL, which is accessible through the .NET framework and Windows Common Language Interface (CLI).\n\n** Offensive Tradecraft **\nAdversaries may utilize PowerShell for various activities, including information discovery and code execution. Additionally, PowerShell can execute code remotely through Windows Remote Management (WinRM) services. As a result, it's important to understand the key artifacts generated when PowerShell is used to execute code in a remote session.\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.055 ms","outputType":"MARKDOWN","result":"** Hypothesis **\n\nAdversaries might abuse remote PowerShell commands and scripts for execution.\n\n** Technical Context **\n\nPowerShell commands or scripts can be executed without directly calling the powershell.exe binary. This can be done by leveraging interfaces to PowerShell's underlying System.Management.Automation assembly DLL, which is accessible through the .NET framework and Windows Common Language Interface (CLI).\n\n** Offensive Tradecraft **\nAdversaries may utilize PowerShell for various activities, including information discovery and code execution. Additionally, PowerShell can execute code remotely through Windows Remote Management (WinRM) services. As a result, it's important to understand the key artifacts generated when PowerShell is used to execute code in a remote session.\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T18:36:12.778Z","dateModified":"2024-09-03T18:39:13.037Z","id":"paragraph_fbcc761a-e72f-4cbf-966f-b3d1b2766a15","input":{"inputText":"%md \n** Pre-Recored Security Datasets **\n\n| **Metadata**   | **Value** |\n|------------|-----------|\n| **docs**   | [Link for document page](\thttps://securitydatasets.com/notebooks/atomic/windows/execution/SDWIN-190518211456.html) |\n| **link**   | [Link for download dataset](https://raw.githubusercontent.com/OTRF/Security-Datasets/master/datasets/atomic/windows/lateral_movement/host/empire_psremoting_stager.zip) |\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.049 ms","outputType":"MARKDOWN","result":"\n** Pre-Recored Security Datasets **\n\n| **Metadata**   | **Value** |\n|------------|-----------|\n| **docs**   | [Link for document page](\thttps://securitydatasets.com/notebooks/atomic/windows/execution/SDWIN-190518211456.html) |\n| **link**   | [Link for download dataset](https://raw.githubusercontent.com/OTRF/Security-Datasets/master/datasets/atomic/windows/lateral_movement/host/empire_psremoting_stager.zip) |\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T18:41:10.641Z","dateModified":"2024-09-03T18:46:27.719Z","id":"paragraph_4c695bb5-1797-4dbb-b501-8c48614dfca4","input":{"inputText":"%md\n*** Analytic I ***\n\nPowerShell can remotely execute commands on a target through WinRM. As a result, it's vital to monitor for the initialization of the PowerShell host process wsmprovhost.\n\n\n| Data source | Event Provider                             | Relationship                  | Event |\n|-------------|--------------------------------------------|--------------------------------|-------|\n| Powershell  | Windows PowerShell                         | Application host started       | 400   |\n| Powershell  | Microsoft-Windows-PowerShell/Operational   | User started Application host  | 4103  |","inputType":"MARKDOWN"},"output":[{"execution_time":"0.047 ms","outputType":"MARKDOWN","result":"*** Analytic I ***\n\nPowerShell can remotely execute commands on a target through WinRM. As a result, it's vital to monitor for the initialization of the PowerShell host process wsmprovhost.\n\n\n| Data source | Event Provider                             | Relationship                  | Event |\n|-------------|--------------------------------------------|--------------------------------|-------|\n| Powershell  | Windows PowerShell                         | Application host started       | 400   |\n| Powershell  | Microsoft-Windows-PowerShell/Operational   | User started Application host  | 4103  |"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-29T08:30:26.551Z","dateModified":"2024-08-29T08:35:18.160Z","id":"paragraph_fd8a9b8b-04d8-4741-9a3a-c62b66f0fe34","input":{"inputText":"%ppl\nsource = powershell* | where Channel = \"Microsoft-Windows-PowerShell/Operational\" OR Channel = \"Windows PowerShell\" | where EventID = \"400\" OR EventID = \"4103\" | where query_string([\"Message\"], \"*HostApplication*wsmprovhost*\") | fields @timestamp, Hostname, Channel\n\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.018 ms","outputType":"QUERY","result":"\nsource = powershell* | where Channel = \"Microsoft-Windows-PowerShell/Operational\" OR Channel = \"Windows PowerShell\" | where EventID = \"400\" OR EventID = \"4103\" | where query_string([\"Message\"], \"*HostApplication*wsmprovhost*\") | fields @timestamp, Hostname, Channel\n\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T18:43:35.608Z","dateModified":"2024-09-03T18:48:32.452Z","id":"paragraph_c643743a-5deb-4c17-8f4b-8a45d48a99a8","input":{"inputText":"%md \n*** Analytic II ***\n\nMonitor for incoming network connections where the destination port is 5985 or 5986, as these ports are likely to be hosted by the System process\n\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Process      |Microsoft-Windows-Security-Auditing | Process connected to Port    | 5156    |","inputType":"MARKDOWN"},"output":[{"execution_time":"0.018 ms","outputType":"MARKDOWN","result":"\n*** Analytic II ***\n\nMonitor for incoming network connections where the destination port is 5985 or 5986, as these ports are likely to be hosted by the System process\n\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Process      |Microsoft-Windows-Security-Auditing | Process connected to Port    | 5156    |"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-29T08:36:05.855Z","dateModified":"2024-08-29T09:26:03.182Z","id":"paragraph_7147fe0a-4a37-48d4-bd04-eb9ed12480f9","input":{"inputText":"%ppl\nsource = powershell* | WHERE match(Channel, \"security\") | where EventID = \"5156\" | where DestPort = \"5985\" OR DestPort = \"5986\" | where LayerRTID = \"44\"|fields @timestamp, Hostname, Application, SourceAddress, DestAddress, LayerName, LayerRTID\n\n\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.043 ms","outputType":"QUERY","result":"\nsource = powershell* | WHERE match(Channel, \"security\") | where EventID = \"5156\" | where DestPort = \"5985\" OR DestPort = \"5986\" | where LayerRTID = \"44\"|fields @timestamp, Hostname, Application, SourceAddress, DestAddress, LayerName, LayerRTID\n\n\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T18:51:12.906Z","dateModified":"2024-09-03T18:53:40.256Z","id":"paragraph_a68e4e98-3670-4431-8093-83ddd3c20180","input":{"inputText":"%md\n*** Analytic III ***\n\nDetect remote PowerShell sessions by monitoring for the execution of wsmprovhost.exe. PowerShell commands can be run remotely on a host using WinRM, which triggers this process when a session is initiated.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Process      | Microsoft-Windows-Security-Auditing | Process created Process    | 4688     |","inputType":"MARKDOWN"},"output":[{"execution_time":"0.019 ms","outputType":"MARKDOWN","result":"*** Analytic III ***\n\nDetect remote PowerShell sessions by monitoring for the execution of wsmprovhost.exe. PowerShell commands can be run remotely on a host using WinRM, which triggers this process when a session is initiated.\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Process      | Microsoft-Windows-Security-Auditing | Process created Process    | 4688     |"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-29T08:40:47.264Z","dateModified":"2024-08-29T08:43:19.400Z","id":"paragraph_5509133c-f800-4a78-a5e0-06d2ad79e95d","input":{"inputText":"%ppl\n\nsource = powershell* | where match(Channel, 'security') | where EventID = '4688' | where query_string(['ParentProcessName'], '*wsmprovhost.exe') OR query_string(['NewProcessName'], '*wsmprovhost.exe') | fields @timestamp, Hostname, ParentProcessName, NewProcessName\n\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.011 ms","outputType":"QUERY","result":"\n\nsource = powershell* | where match(Channel, 'security') | where EventID = '4688' | where query_string(['ParentProcessName'], '*wsmprovhost.exe') OR query_string(['NewProcessName'], '*wsmprovhost.exe') | fields @timestamp, Hostname, ParentProcessName, NewProcessName\n\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T18:54:11.538Z","dateModified":"2024-09-03T18:56:48.385Z","id":"paragraph_a364ac6c-0094-4d63-9c26-b072538ee802","input":{"inputText":"%md\n\n*** Analytic IV ***\n\nProcess wsmprovhost hosts active remote sessions on the target. It is essential to monitor and document any instances of wsmprovhost being created and any processes it subsequently spawns.\n\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | Process created Process    | 1     |","inputType":"MARKDOWN"},"output":[{"execution_time":"0.032 ms","outputType":"MARKDOWN","result":"\n*** Analytic IV ***\n\nProcess wsmprovhost hosts active remote sessions on the target. It is essential to monitor and document any instances of wsmprovhost being created and any processes it subsequently spawns.\n\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | Process created Process    | 1     |"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-29T08:43:48.896Z","dateModified":"2024-08-29T08:45:38.332Z","id":"paragraph_a47d402f-c5c5-4b96-a5b1-62a34e796733","input":{"inputText":"%ppl\nsource = powershell* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = \"1\" | where query_string([\"ParentImage\"], \"*wsmprovhost.exe\") OR query_string([\"Image\"], \"*wsmprovhost.exe\") | fields @timestamp, Hostname, ParentImage, Image\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.018 ms","outputType":"QUERY","result":"\nsource = powershell* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = \"1\" | where query_string([\"ParentImage\"], \"*wsmprovhost.exe\") OR query_string([\"Image\"], \"*wsmprovhost.exe\") | fields @timestamp, Hostname, ParentImage, Image\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-09-03T18:56:57.731Z","dateModified":"2024-09-03T19:01:45.085Z","id":"paragraph_1c746d21-f505-4cfe-8afd-855833c10aa1","input":{"inputText":"%md\n\n*** Analytic V ***\n\nMonitor outbound network connections where the destination port is 5985 or 5986, and the user is not NT AUTHORITY\\NETWORK SERVICE or NT AUTHORITY\\SYSTEM.\n\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | User connected to Port    | 3     |","inputType":"MARKDOWN"},"output":[{"execution_time":"0.025 ms","outputType":"MARKDOWN","result":"\n*** Analytic V ***\n\nMonitor outbound network connections where the destination port is 5985 or 5986, and the user is not NT AUTHORITY\\NETWORK SERVICE or NT AUTHORITY\\SYSTEM.\n\n\n| Data source | Event Provider                       | Relationship          | Event |\n|-------------|--------------------------------------|-----------------------|-------|\n| Module      | Microsoft-Windows-Sysmon/Operational | User connected to Port    | 3     |"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-08-29T08:46:20.661Z","dateModified":"2024-08-29T08:48:11.695Z","id":"paragraph_86220428-66e0-42e6-9f5a-9628ffec8c56","input":{"inputText":"%ppl\nsource = powershell* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = \"3\" | where DestinationPort = \"5985\" OR DestinationPort = \"5986\" | where NOT User = \"NT AUTHORITY\\\\\\\\NETWORK SERVICE\" | fields @timestamp, Hostname, User, Initiated, Image, SourceIp, DestinationIp\n\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.027 ms","outputType":"QUERY","result":"\nsource = powershell* | where Channel = \"Microsoft-Windows-Sysmon/Operational\" | where EventID = \"3\" | where DestinationPort = \"5985\" OR DestinationPort = \"5986\" | where NOT User = \"NT AUTHORITY\\\\\\\\NETWORK SERVICE\" | fields @timestamp, Hostname, User, Initiated, Image, SourceIp, DestinationIp\n\n\n"}]}],"path":"PowerShell-Remote-Session"}},"id":"eb750850-65e0-11ef-8b1b-6bee4b7c80eb","references":[],"type":"observability-notebook","updated_at":"2024-11-25T12:03:55.294Z","version":"Wzk5NSw1XQ=="}
{"attributes":{"dateModified":"2024-10-16T15:02:10.581Z","paragraphs":[{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-10-16T15:00:02.176Z","dateModified":"2024-10-16T15:02:05.601Z","id":"paragraph_0405f33f-4ff2-4e24-9212-3be92e14991a","input":{"inputText":"%md\nThis Notebook describes the SHOW process","inputType":"MARKDOWN"},"output":[{"execution_time":"0.041 ms","outputType":"MARKDOWN","result":"This Notebook describes the SHOW process"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-10-16T14:51:09.294Z","dateModified":"2024-10-16T14:51:26.146Z","id":"paragraph_2351422b-a2e9-42ad-bd0a-2c5e21b637bb","input":{"inputText":"%md\nSHOW – Supporting Threat Hunting with Opensearch and Wazuh\n\nBrian Lee, Xi Lan\n\nTable of Contents\n\n[Introduction 1](#_Toc1535243260)\n\n[Threat Hunting Overview 2](#_Toc2008270899)\n\n[What is Threat Hunting? 2](#_Toc2138436321)\n\n[Threat Hunting Process 2](#_Toc1048050875)\n\n[Threat Hunting Frameworks 2](#_Toc1623305131)\n\n[Threat Hunting Types 4](#_Toc778905970)\n\n[Threat Hunting Tools 4](#_Toc1840659150)\n\n[The SHOW Process 5](#_Toc349870514)\n\n[Prepare for the Hunt 6](#_Toc951503231)\n\n[Conduct the Hunt 8](#_Toc737491126)\n\n[Finish the Hunt 10](#_Toc56087398)\n\n[Annex 1 – MITRE TTP Framework 10](#_Toc2070861446)\n\n[Framework Conceptual Building Blocks 11](#_Toc341449715)\n\n[MITRE TH Process 12](#_Toc226184999)\n\n[Annex 2 –Commonly Observed TTPs 13](#_Toc743926800)\n\n[Reports Overview 13](#_Toc836960953)\n\n[Top 10 Techniques 14](#_Toc1409434483)\n\n[TTP Category 16](#_Toc263321644)\n\n# Introduction\n\nThis work describes how OpenSearch can be used to support threat hunting. It situates this support in the context of a specific threat hunting framework – the ‘TTP Based Hunting ‘ from MITRE and based on the ATT&CK framework. That is to say – SHOW is designed to follow the TTP-based process outlined by MITRE - the reason for this is quite simply to avoid reinventing the wheel. As will be seen from the description below elements of SHOW relate to other frameworks also and the intention is to expand SHOW to incorporate other elements of those frameworks.\n\nThreat hunting is a key activity to support the overall security defense processes for organisations and enterprises. It is an ad-hoc activity as opposed to continuous event monitoring and searches for any malicious activities that might have escaped the other monitoring and threat detection processes. An overview of threat hunting and the most common frameworks is given below. This is followed by a more in depth description of the MITRE threat hunting process with an elaboration of which parts of that process SHOW supports as well as a description of the SHOW implementation components.\n\nThe report also contains an annex outlining the most exploited TTPs over the last few years to provide SHOW users with a starting point for their hunting.\n\n# Threat Hunting Overview\n\n## What is Threat Hunting?\n\nSimply put threat hunting is a proactive activity to look for signs of attacks or malicious activity that may have been missed by other detection processes. It entails not only detecting but also understanding the attack consequences and removing/isolating the threat.\n\nThreat hunting can be triggered for several reasons e.g. by observing Indicators of Compromise (IoC) or other evidence that might lead to the identification of new threats or it could be motivated by appearance of new attacks in the wider business environment \\[ add Nour\\]. Alternatively, threat hunting can be used to explore new approaches to detect malicious behavior that can help can improve cyber defences, which may be more valuable over the longer time frame that the immediate discovery of threat.\\[ add PEAK\\]\n\n## Threat Hunting Process\n\nThreat hunting follows a well-known process cycle \\[add Nour\\] , derived from the **Sqrrl** Threat hunting framework \\[add Sqrrl\\] , as shown in Figure 1.\n\n1. _Create a hypothesis_: At a general level hypothesis is an assumption/supposition or question about a particular attack or some of its behaviours that might be present on the hunters network. At a more detailed level a hypothesis maybe narrowed to a single behaviour or TTP. The information leading to formation of a hypothesis arise from different sources following the motivation to do the threat hunt as outlined above.\n2. _Investigate with Tools & Techniques:_ In this step the hunter seeks to check the validity of the hypothesis using the tools (logs etc.) available. Typically this entails mapping the attack behaviour(s) to querie(s) over the various data source tools.\n3. _Uncover new patterns and TTP’s_: The hunt should return a number of events (“hits”) for the related queries. These may or may not support the hypothesis but are likely to create new pathways and raise new TTPs to be investigated\n4. _Inform hunters and enrich analytics_: In this step the hunter extends the scope or direction of the hunt and generates new queries etc. to follow up on the information thrown up by the previous steps.\n\n## Threat Hunting Frameworks\n\nThe process outlined in Figure 1describes the _execution_ of an actual hunt. There are however other steps , that precede and follow the execution step, in order to establish an comprehensive and effective threat hunting practice. A number of threat hunting _frameworks_ have arisen over the years to meet this need. A threat hunting process is “ a system of repeatable processes designed to make your threat hunting more effective and efficient” \\[PEAK\\]. Some of the more well know frameworks include:\n\n1. **Sqrrl**: This was one of the earliest and most influential frameworks and laid down the basic threat hunting principles that still recur today. Sqrrl incorporates other artefact including a Threat Hunitng maturity Model.\n2. **PEAK**: _The PEAK (Prepare, Execute, Act, Knowledge) framework_ \\[Splunk\\] is a very recent addition and has been designed to overcome some of the limitations in Sqrrl that became apparent over time. It incorporates the Sqrrl hypothesis-based hunt types and add two new threat hunt types - baseline, model-assisted (detailed below). The process steps are common to all three hunt types but their implementation may naturally vary. The steps, in more detail, are:\n3. _Prepare_: Hunters need to decide the focus, scope and outcomes of a threat hunt including the likely data sources and competences needed and need to prepare a plan for the hunt activities.\n4. _Execute:_ This step executes the hunt plan and refines and adapts as needed according to the returned results\n5. _Act :_ This step documents the findings and shares the results with other appropriate colleagues. It also identifies and carries out the any updates to the automated threat detection and defense systems\n6. _Knowledge:_ Knowledge is a broad term that include the human competence and expertise as well as accumulated lessons, data and analytics from previous threat hunts and from the present threat hunt.\n\n8. **TaHiTI** : _Targeted Hunting integrating Threat Intelligence_ \\[<https://www.betaalvereniging.nl/wp-content/uploads/TaHiTI-Threat-Hunting-Methodology-whitepaper.pdf> \\] - As the name implies incorporating cyber threat intelligence (CTI) to provide an starting point for the hunt and to provide context for the hunt. It uses hypotheses driven testing and introduces a new type of hunt – the unstructured threat hunt. It has three phases:\n9. _Initiate:_ Planning and preparation of the hunt.\n10. _Hunt:_ Execution of the hunt.\n11. _Finalise:_ Documentation and handover of the hunt.\n12. **TTP Hunting_:_** _TTP Based Hunting_ \\[<https://www.mitre.org/sites/default/files/2021-11/prs-19-3892-ttp-based-hunting.pdf> \\]. Although TTP are used in all hunting, Mitre has defined a hypothesis-based hunting process focused specifically on the well-known ATT&CK model i.e. “ hunt operations collect and utilize timely, actionable information on the techniques adversaries must employ across all systems of interest” – _actionable_ being the key word here. The model is explored in greater detail below.\n\nIn addition to the above a _general architecture_ for threat hunting is defined by Nour et al. It consists of three components that correspond roughly to the phases of the various frameworks above:\n\n1. **Input Sources** : They identify three types of input data\n2. _CTI –_ CVE’s, information on ongoing attack APT campaigns, AT&CK\n3. _Telemetry:_ logs, alerts (SIEM etc)\n4. _System Representation:_ network and computer system topology\n5. **Threat Hunting System** –. It contains two subsystems:\n6. _Data Knowledge Module:_ this refers to the data collection, processing and storage tolls and databases. It may include not just event logs but also topology representation and other tools.\n7. _Analysis Module:_ the ‘execution engine’ of the hunt – essentially executes the steps shown in Figure 1 above. It in turn consists of three sub modules These are_:_ _Analyser_ -generates hypotheses based on input from data knowledge module; _Tester_ -investigating and analysing each hypothesis using data visualization, search and similar techniques; _Evaluator_ -identifies malicious activities and attack patterns\n8. **Security Outputs:** This consists of two sub-parts\n9. _Responses:_ design and implementation of automated analytics and responses\n10. _Reporting:_ attack related information that could enhance overall security posture and future threat hunting.\n\n## Threat Hunting Types\n\nA number of different threat hunting types defined by the various frameworks are summarized here. Hunt types reflect differing technologies and purposes in executing a hunt.\n\nThe main types are\n\n1. _Hypothesis-based_: this is the original type and is used by all frameworks. As described above this approach is based on an assumption/supposition/question about a particular attack or some of its behaviours that might be present on the hunters network\n2. _Baseline_: this approach is proposed by PEAK. It entails establishing a baseline or profile of normal activity and then searching for deviations form that baseline. In this regard it can be seen as a form of anomaly detection. The hunter establishes a data-dictionary of the data for the entity in question and define statistics (average/median value, top-k values, cardinality of field) to charaterise ‘normal’. Techniques such as Least Frequency of Occurrence or ‘z-scores’ can be used to search for outliers.- See \\[oeak\\] for more detaisl.\n3. _Model-based_: this applies machine learning models to detect aberrant or suspicious behaviour. Algorithms for classification, clustering or time series analysis could be used. It should be pointed out that while these methods are used for threat detection their use here is on archived data and so can be thought of as expanding the original threat hunting process scope beyond hypothesis base through the use of machine learning – this can be said also for the baseline type.\n4. _Unstructured_: -proposed by TAHiTI. This type of hunting is initiated spontaneously based on the data (IoC, TTP) observed by an analyst in the course of their work. It is considered unstructured because hunting does not start with a hypothesis and does not follow a predetermined path.\n5. _Structured_: Opposite to unstructured, i.e. hypothesis based hunting that follows a planned approach using a framework- source TAHiTI\n6. _Situational_: Structured or unstructured hunting based on analysis generated from internal reports – source Nour et al.\\[Nour\\]\n\n#### Scope of the hunt\n\nAs can be seen from the above set of types, threat hunting can be initiated for a wide variety of reasons and starting positions. A hunt may for example start with a very narrow focus on an observed IoC or it may start with a very broad focus such cyber threat intelligence (CTI) emanating from one or more reports or research efforts describing a particular attack campaign. This latter focus would require careful and detailed enumeration of the TTP’s of interest described in the report. The process steps to be taken to prepare for and conduct the hunt are mostly the same – the primary different is the scope with a broader scope requiring some process steps to be repeated and the inclusion, perhaps, of some others\n\n## Threat Hunting Tools\n\nMany commercials tools exist to support threat hunting but these are not considered here. Instead we describe some open-sourced tools and repositories that may be of use to threat hunters. These include\n\nKestrel -\n\n# The SHOW Process\n\nBbbb\n\n## Prepare for the Hunt\n\n**Define the hunt objectives:**\n\nMITRE refers to this phase as “developing a malicious activity model”. The scope of the phase will vary depending on the particular focus and trigger mechanism\n\n#### Select activity\n\nDecide **what type of threat activity** or focus the hunt will address at a general level. This may be based different trigger points such as recent incidents, an overview of the current threat landscape, received threat intelligence .Examples include:\n\n1. TTP’s used by a particular adversary\n2. Particular attack campaign\n3. Attack lifecycle phase\n4. Data exfiltration\n\nGeneral level hypothesis may be formulated at this point e.g. ”_Attackers may be exfiltrating data from our system_” or “_How secure is our system against credential stealing_?’.\n\n#### Research and Refine\n\nResearch the identified focus to **gather as much** information as you can on the threat to help you understand how to shape your hunt approach. Refer to vendor threat intelligent reports, threat intelligence, security new websites, libraries etc. Use Appendix 2 as a starting point.\n\nThis step should add sufficient detail to the hunt focus to identify candidate TTP’s that are relevant to the focus\n\n#### Document findings\n\nDocument this in the notebook keeping track of essential information.\n\n**Define the hunt hypothesis:**\n\nThe previous steps have generated a list of TTP’s that will be used in the hunt. In this step we **generate a detailed hypotheses** for one or more of these TTP’s<sup>[\\[1\\]](#footnote-2)</sup>. The hypothesis should be formulated so that it can be **tested** i.e. so it can be verified, or not as the case may be, based on the evidence that can be collected from the computer system. It should therefore be clear, concise and precise enough. For example “_An attacker may be exfiltrating data using HTTPS tunneling_” or “_Attackers may be using Kerberoasting for credential stealing_”. Refine further if necessary to address e.g. specific enterprise missions or particular types of data.\n\nFor each hypothesis, **define an _analytic_**<sup>[\\[2\\]](#footnote-3)</sup> that will identify the behaviour noted in the TTP. An analytic takes the form of one or more queries to the Opensearch indexes to retrieve the required data. Queries may be formulated using either SQL or PPL.\n\nMITRE recommends to define an the analytic in abstract form i.e. in independent of any particular tool or underlying data source and gives as an example to describe an analytic for ‘process creation’ rather than formulating in OS specific (Linux or Windows) form. This can be useful in system where there are different sensors. For SHOW it is sufficient to use Opensearch queries directly. Worked examples , as Notebooks, showing hypothesis and their related analytics are provided.\n\n**Define the hunt scope:**\n\nDetermine Data Requirements\n\nThis step entails defining the required data sources.\n\nThe **hypothesis analytic** will define the types of data and data sources need to collect for the hunt. This will identify also the types of data sensor e.g. Host Intrusion Detection System (HIDS) or Network IDS or the specific types of log that are needed. In some cases it might require the addition of new sensors or reconfiguring or adding data collection agents (Wazuh agent or Syslog) to collect new logs or add new sources. This will depend also on which parts of the system are to be examined.\n\nAnother factor to consider is the requirements for **contextual informa**tion i.e. information on assets or other artefacts that may be related to the behaviour and that support the analysis and understanding of the behaviour. MITRE notes that sensors focused on automated detection may not give much contextual information and some combination of endpoint selection and response (EDR) tools, application logs and system event logs may be needed. There is of course a trade-off between the amount of contextual information and the volume of such information i.e. the greater the level of context detail (e.g. HIDS alerts vs API/Syscall logging) the greater the volume of data to be collected and analysed.\n\nAs MITRE notes “A good **data model** for hunting will relate what objects and actions an analyst wishes to capture to the key data (fields, values, attributes) needed from the environment’s sensors”. MITRE defines the Cyber Analytic Repository (CAR) model for this purpose – see Appendix 1 for more information on CAR. SHOW recommends also the use of the CAR data model for this step.\n\nDetermine the extent of the Analysis Space:\n\nEvery event that occurs in a computer system can be represented in three dimensions:\n\n- Time – seconds, minutes, ... years\n- Network assets – Windows hosts, Linux hosts, router, switches, etc.\n- Behaviour - TTPs\n\nThese three form a 3D space which (after MITRE) we term the Analysis Space. It is important to **determine the appropriate combination of these dimensions** in order to achieve an effective hunt. A very large analysis space will require a large amount of data and subsequent analysis while a too small analysis space may not yield any interesting or useful results.\n\n## Conduct the Hunt\n\n**Retrieve Data:**\n\nCollect the data\n\nPrevious steps have defined the data types and data sources and extent of the analysis space. In this step the **data is fetched** from the sources to a central collection point i.e. SIEM, data lakehouse etc. In many cases the required data may already have been collected.\n\nIf new or extra sensors are required then the necessary **configuration of agents** must be carried out in this step. Wazuh uses Wazuh agents or Syslog agents to collect data from end points. For new data sources it may be required to write Wazuh decoders and alerting rules to ingest the data and generate alerts. In some cases it may also be appropriate to assign TTP behaviour clarification for new behaviours. Refer to the Wazuh documentation.\n\nTune the analysis space\n\nAlthough an initial analysis space had been defined it may be **necessary to refine** or reshape this based on the actual data collected. SHOW provide visualization support to help with through the use of a heat map which enables the visualization of the three dimension of the analysis space.\n\nFor example if the x and y axes represent time and network assets, respectively, then the colour of each square can indicate the number of behaviours observed for the network assets for that period. Any obvious outliers can help to focus the hunt. Another example might be to switch the network assets and behaviour axes can detail the occurrence of certain behaviour through the network which might reveal the overall flow of an attack,\n\nMITRE provides a more detailed discussion on this topic with some interesting ideas. See especially section 2.4.3.1.\n\n**Evaluate the data:**\n\nAnalyse the Data\n\nAnalysing involves examining and interpreting collected information to discover patterns, relationships, or trends. The goal is to extract meaningful insights that can inform decision-making or improve understanding of the hunt hypothesis.\n\nIt typically includes organizing the data, applying statistical methods, and drawing conclusions based on the findings. There are many different analysis techniques that are used for hypothesis threat hunting. The techniques below are taken from the TaHITi framework \\[Tahiti\\]:\n\n1. _Visualisation_ – exploring relationships between data items visually\n\n- _Clustering_ -  Clustering is a statistical method used to group similar data points based on shared characteristics from a larger dataset. It is often applied in various fields, including for outlier detection, because it helps uncover patterns or behaviors that deviate from the norm, such as identifying an unusual number of occurrences of a typically common event. Hunters can utilize clustering to effectively identify aggregate behaviors in data analysis..\n- _Stack Counting_ -  Stacking entails counting the occurrences of specific values and focusing on identifying and analyzing any outliers within those results.”\n- _Grouping_ – This involves taking distinct artifacts and determining when multiple items from the set appear together according to specific criteria. The key distinction between grouping and clustering is that grouping works with a predefined set of items that are already deemed significant, rather than identifying patterns or similarities from a broader dataset.\n- _Querying_ - searching for specific data in the database.\n\nThere are many other forms of statistical and machine learning analysis that may be appropriate for different situations.\n\nGather Contextual Information\n\nContextual information is any supplementary information related to the collected data that can aid the analysis of the hypothesis. Contextual information can help establish links between other events and artefacts. Some examples of contextual information are\n\n1. Related processes – identifying other relevant processes or process chains can be of great value in the hunt to verify the hypothesis\n2. Network Information – can establish links to other network entities involved and help determine the bigger picture.\n3. System files\n4. User information\n5. Host Security posture e.g. vulnerabilities etc.\n\nThe MITRE document has useful guidelines for this activity.\n\nVerify the Hypothesis\n\nThis step determines if the hypothesis/goal of the hunt was achieved or not. There are three possible outcomes:\n\n1. _Hypothesis is proven_ – corroborating evidence has been found to validate the hypothesis. Further action may be necessary such as incident reporting or escalating the finding to another team e.g. to share findings as threat intelligence or write detector analytics for sensors.\n2. Hypothesis is not proven – no evidence was found to validate the hypothesis.\n3. _Inconclusive_ – There may be a variety of reasons for this – not enough data or incorrect data or the extent of the analysis space is incorrect or misconceived hypothesis.\n\n**Refine/Repeat:**\n\nIf the findings form the hunt are inconclusive or interim result determine the current hypothesis should be amended or replaced then the team may repeat previous steps. Otherwise the team moves to finish the hunt.\n\n## Finish the Hunt\n\n**Report Finding:**\n\nDocument the fundings\n\nThe results of the hunt should be documented. This should include the purpose, approach and conclusion from the hunt, any lesson learned or new information that can inform or improve security posture and practice.\n\nCommunicate the findings\n\nThe findings from the hunt are shared with other departments and interested parties. The actual distribution list may vary but all parties who can benefit from the findings should be included.\n\n**Preserve the Hunt:**\n\nArchive hunt details\n\nThe details of the hunt are stored in case the hunt needs to be revisited in the future. This should include _the_ data, tools and techniques used as well as any external information sources etc.\n\nAdd to hunt backlog\n\nSome teams maintain a backlog of potential future hunts. If so then any ideas for new hunts should be added here\n\n# Annex 1 – MITRE TTP Framework\n\nThe MITRE “TTP-Based Hunting” describes a threat hunting framework based on the use of MITRE ATT&CK based TTP’s that aims to “create a general threat hunting methodology focused on an identifying adversary behavior, structured within an adversary model, that does not depend on specific tools or products but rather describes what data is necessary, what types of data should be available from the sensors and how to use that data within the hunt”\n\nThis annex gives an overview of the MITRE framework – please refer to \\[\\] for a full description.\n\n## Framework Conceptual Building Blocks\n\nThe framework is hinged around a number of conceptual building blocks:\n\n**Adversary**: the bad guy i.e. the attacker or attack group\n\n**TTP’s** – primarily the behaviours and techniques of the ATT&CK model\n\n**Adversary model** – the ATT&CK matrix or more precisely the set of techniques used by an adversary and/or technique pathways through the matrix taken by an adversary\n\n**Analysis Space**; A three-dimensional space in which the hunt activities are situated. The dimensions of the space are formed by\n\n1. The computing and network environment – what MITRE calls the cyber terrain.\n2. The set of behaviours (TTPs) to be explored\n3. The time frame over which the hunt will be conducted.\n\nHunters can use tools such as heatmaps to visualize this space with the goal to refine and narrow down the hunt scope\n\n**Hypothesis**: effectively the behavior and related TTP to hunt.\n\n**Abstract Analytic**: the generic formulation of the search query to search for the behavior. Abstract here means the query is formulated in a tool independent form. Or as MITRE puts it “_analysts should be careful to avoid creating an analytic that is too specific to a particular instantiation of a particular tool_”.\n\nIn the MITRE TH framework analytics are often described using the Cyber Analytics Repository (CAR) \\[<https://car.mitre.org/> \\] CAR is a collection of analytics framed around the CAR data model (see below also) . An example of a CAR analytic for process creation is\n\n“CAR-2013-02-003: Processes Spawning cmd.exe”. The accompanying analytic is\n\nprocess = search Process:Create\n\ncmd = filter process where (exe == \"cmd.exe\")\n\noutput cmd\n\n_process_ and _exe_ are elements of the CAR data model.\n\nThe analytic returns a list of the processes spawned by the CMD shell. A mapping of this analytic to the DNIF SIEM \\[<https://www.dnif.it/en/\\>] is show as\n\n\\_fetch \\* from event where $LogName=WINDOWS-SYSMON AND $EventID=1 AND $Process=regex(.\\*cmd\\\\.exe.\\*)i limit 100\n\n**Data Model**: A data model provides a set of defined entity types to represent and reason about the data to be collected and processed during the hunt i.e. the data model relates “ _the system activities one wishes to capture to the key data (fields, values, attributes) needed from the sensors_”\n\nMITRE user the Cyber Analytics Repository (CAR) data model \\[<https://car.mitre.org/data_model/\\>] to model the system activity and data – see for example Figure x (derived from \\[\\]) in which a subset of this model based around the _process object_ is shown. The model describes the relationship between the _process_ and other object e.g. a process can create a _file_ which is the _loaded_as_ a _module_ and _launched_as_ a _process_. The CAR defines the action and attributes of the entities see table y \\[car\\] for the definition of the _file_ object – refer to \\[car data model \\] for a complete description of the data.\n\nTable x\n\n| Object | Action | Fields |\n| --- | --- | --- |\n| file | acl_modify  <br>create  <br>delete  <br>modify  <br>read  <br>timestomp  <br>write | company  <br>content  <br>creation_time  <br>extension  <br>file_name  <br>file_path  <br>fqdn  <br>gid  <br>group  <br>hostname  <br>image_path  <br>link_target  <br>md5_hash  <br>mime_type  <br>mode  <br>owner  <br>owner_uid  <br>pid  <br>ppid  <br>previous_creation_time  <br>sha1_hash  <br>sha256_hash  <br>signature_valid  <br>signer  <br>uid  <br>user |\n\nThe use of data models is not restricted to the MITRE TH framework. For example, Kestrel\n\n## MITRE TH Process\n\njj\n\n# Annex 2 –Commonly Observed TTPs\n\nThe purpose of this annex is to provide an understanding of the most common Tactics, Techniques, and Procedures (TTPs) employed by attackers, as highlighted in the key findings from the M-Trends 2023 and 2024 reports, as well as DBIR 2023 and 2024 reports. Understanding these TTPs is important to enable organizations to detect and quickly mitigate potential threats.\n\nThis chapter is structured into several sections, each focusing on different aspects of the TTPs reported in the reports above:\n\n1. Reports Overview: This section provides a summary of the four reports—M-Trends 2023, M-Trends 2024, DBIR 2023, and DBIR 2024. It outlies the context of these reports in understanding the current threat landscape.\n2. Top 10 Techniques: we enumerate and discuss the top 10 most observed TTPs from the M-Trends reports of 2023 and 2024.\n3. TTP Category: This section categorizes the top two TTPs for each phase of the Mandiant Targeted Attack Lifecycle as outlined in the M-Trends 2024 report. Also, we explore the ATT&CK techniques related to the attack categories discussed in the DBIR 2024 report.\n\n## Reports Overview\n\nThe Data Breach Investigations Report (DBIR) and M-Trends reports serve distinct but complementary purposes with each providing insights tailored to different audiences.\n\nThe **DBIR** reports, produced annually, are designed to provide a broad analysis of data breaches across various industries. Their primary purpose is to help organizations understand the patterns and trends in cyber incidents, enabling them to better anticipate and defend against potential threats. The 2023 and 2024 editions of the DBIR offer a detailed exploration of the evolving landscape of cyber threats and data breaches. Both reports utilize the VERIS (Vocabulary for Event Recording and Incident Sharing) framework, which categorizes incidents by the actors involved, the methods used, and the assets targeted. In the 2023 report, there is a clear emphasis on the role of external actors, predominantly financially motivated criminals, in executing data breaches. The report goes through common attack patterns such as system intrusion, social engineering, and basic web application attacks, providing a statistical overview of how these threats have manifested across various industries.\n\nThe 2024 DBIR builds on these insights, offering updated statistics and highlighting emerging threats. This report pays attention to the growing complexity of attack vectors, such as adversary-in-the-middle techniques that bypass multi-factor authentication (MFA). The 2024 edition also reflects on how the cybersecurity landscape has evolved, noting that while many of the same attack patterns persist, the methods employed by attackers are becoming increasingly advanced, necessitating a more robust approach to defense.\n\nIn contrast, the **M-Trends** reports from Mandiant are more specialized, focusing on advanced persistent threats (APTs) and the activities of attackers. The purpose of these reports is to provide in-depth analysis of the TTPs used by these adversaries. The 2023 M-Trends report highlights campaigns by groups like APT29, which have targeted both government and private sector organizations using advanced tactics, including phishing and the deployment of malware. Additionally, the report provides detailed mappings of the MITRE ATT&CK Techniques to the Mandiant Targeted Attack Lifecycle (see Table 5 below), offering organizations a clear framework to understand and defend against the specific TTPs used by these adversaries. This integration helps security professionals align their defenses with known threat behaviors, enhancing their ability to detect, respond to, and mitigate targeted attacks effectively.\n\nThe 2024 M-Trends report continues this analysis, documenting how attackers are increasingly bypassing traditional defenses, including MFA, through techniques such as session token theft and QR code phishing. This report not only details the threats but also offers mitigation strategies, emphasizing the need for organizations to stay ahead of these evolving tactics by adopting advanced detection and defense mechanisms.\n\nTogether, these four reports paint a picture of the cybersecurity landscape over two years. The DBIR reports offer broad insights into data breaches across industries, while the M-Trends reports provide a deeper dive into the strategies and techniques employed by most attackers. Both sets of reports underscore the importance of understanding and adapting to the ever-changing tactics used by cybercriminals, as well as the need for organizations to continuously evolve their defenses to keep pace with these threats.\n\nTop 10 Techniques\n\nIn both the 2023 and 2024 M-Trends reports, metrics are provided around the most observed techniques used by adversaries. However, the DBIR reports do not include a similar summary of frequently used TTPs. As a result, our focus in this chapter is on the insights provided by the M-Trends reports, highlighting the most prevalent techniques and sub-techniques utilized by adversaries as identified by Mandiant's analysis.\n\nTable 1 Top10 Most Frequently Seen Techniques Based On M_Trends_2023\n\n| Rank | Technique ID | Technique Name | Percentage |\n| --- | --- | --- | --- |\n| 1   | T1059 | Command and Scripting Interpreter | 50.90% |\n| 2   | T1027 | Obfuscated Files or Information | 43.50% |\n| 3   | T1071 | Application Layer Protocol | 33.10% |\n| 4   | T1082 | System Information Discovery | 31.60% |\n| 5   | T1070 | Indicator Removal | 31.50% |\n| 6   | T1083 | File and Directory Discovery | 29.50% |\n| 7   | T1140 | Deobfuscate/Decode Files or Information | 27.30% |\n| 8   | T1021 | Remote Services | 26.40% |\n| 9   | T1105 | Ingress Tool Transfer | 24.90% |\n| 10  | T1543 | Create or Modify System Process | 24.70% |\n\nTable 2 Top5 Most Frequently Seen Sub-Techniques Based On M_Trends_2023\n\n| Rank | Sub-Technique ID | Sub-Technique Name | Percentage |\n| --- | --- | --- | --- |\n| 1   | T1059.001 | PowerShell | 33.20% |\n| 2   | T1070.004 | File Deletion | 25.20% |\n| 3   | T1071.001 | Web Protocols | 24.30% |\n| 4   | T1569.002 | Service Execution | 21.80% |\n| 5   | T1021.001 | Remote Desktop Protocol | 20.30% |\n\nTable 1 and Table 2 show that adversaries frequently leveraged a command or scripting interpreter (T1059) in 50.9% of cases, with one-third of those intrusions involving the use of PowerShell (T1059.001). Mandiant's analysis also reveals the continued frequent use of web protocols (T1071.001) and Remote Desktop (T1021.001) across intrusions, suggesting that adversaries heavily rely on the organization's existing technologies to carry out their operations. These sub-techniques have consistently ranked in the top five over the past three years. This trend could indicate that detection capabilities for these techniques have improved, leading organizations to prioritize other evidence sources to capture additional techniques.\n\nTable 3 Top10 Most Frequently Seen Techniques Based On M_Trends_2024\n\n| Rank | Technique ID | Technique Name | Percentage |\n| --- | --- | --- | --- |\n| 1   | T1059 | Command and Scripting Interpreter | 52.30% |\n| 2   | T1027 | Obfuscated Files or Information | 46.50% |\n| 3   | T1083 | File and Directory Discovery | 38.60% |\n| 4   | T1021 | Remote Services | 37.30% |\n| 5   | T1082 | System Information Discovery | 37.10% |\n| 6   | T1070 | Indicator Removal | 35.10% |\n| 7   | T1071 | Application Layer Protocol | 34.00% |\n| 8   | T1033 | System Owner/User Discovery | 31.70% |\n| 9   | T1140 | Deobfuscate/Decode Files or Information | 31.50% |\n| 10  | T1190 | Exploit Public-Facing Application | 28.70% |\n\nTable 4 Top5 Most Frequently Seen Sub-Techniques Based On M_Trends_2024\n\n| Rank | Sub-Technique ID | Sub-Technique Name | Percentage |\n| --- | --- | --- | --- |\n| 1   | T1059.001 | PowerShell | 32.30% |\n| 2   | T1071.001 | Web Protocols | 29.60% |\n| 3   | T1021.001 | Remote Desktop Protocol | 28.30% |\n| 4   | T1569.002 | Service Execution | 26.80% |\n| 5   | T1070.004 | File Deletion | 26.60% |\n\nIn these tables, the techniques used by attackers in 2023, as detailed in the M-Trends 2024 report, remain consistent with those observed in 2022, as shown in the M-Trends 2023 report. Tables 3 and 4 demonstrate that the top 10 most frequently seen techniques have shown little variance over the past several years. **In more than half of the investigations, Mandiant noted the use of a command or scripting interpreter (T1059) by attackers.** A difference in the 2023 dataset is the inclusion of **System Owner or User Discovery (T1033)** and the **exploitation of public-facing applications (T1190)** among the top 10 observed techniques. These additions correlate with the rise in ransomware-related intrusions and the increase in mass exploitation campaigns observed in 2023.\n\nIt's unsurprising that the top five observed sub-techniques—PowerShell (T1059.001), Web Protocols (T1071.001), Remote Desktop Protocol (T1021.001), Service Execution (T1569.002), and File Deletion (T1070.004). Attackers likely favor these sub-techniques because they exploit readily available tools within a system, making them easy to abuse. Their proven success in compromising systems, coupled with their ability to sometimes evade security measures, makes them a highly effective part of an attacker’s toolkit. This persistent trend highlights the standard tactics employed by attackers to achieve their objectives. As such, organizations must prioritize detecting these sub-techniques if they have not already done so.\n\n## TTP Category\n\nMandiant provides techniques related to Mandiant’s Targeted Attack Lifecycle, which outlines the predictable sequence of events that cyber attackers use to carry out their attacks. To highlight the most impactful tactics, we have selected the top two techniques from each phase of the lifecycle, as shown in Table 5. This selection provides a detailed view of the most observed methods used by adversaries, thereby helping to understand into their operational patterns.\n\nTable 5 Techniques Related To M_Trends_2024 Targeted Attack Lifecycle\n\n| Mandiant Lifecycle Phase | Category | Technique ID | Technique Name | % of Attacks |\n| --- | --- | --- | --- | --- |\n| Initial Reconnaissance | Reconnaissance | T1595 | Active Scanning | 1.10% |\n| Resource Development | T1608 | Stage Capabilities | 12.80% |\n| T1583 | Acquire Infrastructure | 5.40% |\n| Initial Compromise | Initial Access | T1190 | Exploit Public-Facing Application | 28.70% |\n| T1133 | External Remote Services | 20.30% |\n| Establish Foothold | Persistence | T1543 | Create or Modify System Process | 28.30% |\n| T1098 | Account Manipulation | 18.60% |\n| Escalate Privileges | Privilege Escalation | T1543 | Create or Modify System Process | 28.30% |\n| T1055 | Process Injection | 25.10% |\n| Internal Reconnaissance | Discovery | T1083 | File and Directory Discovery | 38.60% |\n| T1082 | System Information Discovery | 37.10% |\n| Lateral Movement | Lateral Movement | T1021 | Remote Services | 37.30% |\n| T1570 | Lateral Tool Transfer | 2.30% |\n| Maintain Presence | Persistence | T1027 | Obfuscated Files or Information | 46.50% |\n| T1070 | Indicator Removal | 35.10% |\n| Mission Completion | Collection | T1213 | Data from Information Repositories | 16.70% |\n| T1560 | Archive Collected Data | 14.60% |\n| Exfiltration | T1567 | Exfiltration Over Web Service | 5.60% |\n| T1041 | Exfiltration Over C2 Channel | 3.60% |\n| Impact | T1486 | Data Encrypted for Impact | 25.50% |\n| T1489 | Service Stop | 15.90% |\n\nIn both the DBIR 2023 and 2024 reports, Verizon provided relevant ATT&CK techniques based on **three types o**f attacks, as defined in DBIR, which remained consistent across both years. These are:\n\n1. **Basic Web Application Attacks**, where threat actors continue to exploit assets with default, simplistic, and easily guessable credentials by brute forcing them, purchasing them, or reusing credentials from previous breaches.\n2. **Social Engineering**, where pretexting remains the leading cause of cybersecurity incidents, with actors targeting users through existing email chains and context. The prevalence of extortion also saw a dramatic increase, largely due to the large-scale MOVEit incident.\n3. **System Intrusion**, where, despite shifts in tactics leveraged by attackers, the overall impact of these actors continues to affect a majority of industries and organizations of all sizes.\n\nTable 6 shows the specific ATT&CK techniques related to these attack types as outlined in the DBIR 2024 report.\n\nTable 6 Relevant ATT&CK techniques relative to DBIR_2024\n\n| Type of attack | ATT&CK Technique | Technique Name | Sub-Technique | Sub-Technique Name |\n| --- | --- | --- | --- | --- |\n| Basic Web Application Attacks | T1110 | Brute Force | T1110.004 | Credential Stuffing |\n| T1110.002 | Password Cracking |\n| T1110.001 | Password Guessing |\n| T1110.003 | Password Spraying |\n| T1586 | Compromise Accounts | T1586.002 | Email Accounts |\n| T1190 | Exploit Public-Facing Application |     |     |\n| T1133 | External Remote Services |     |     |\n| T1586 | Compromise Accounts | T1586.002 | Email Accounts |\n| T1078 | Valid Accounts | T1078.001 | Default Accounts |\n| T1078.002 | Domain Accounts |\n| T1550 | Use Alternate Authentication Material | T1550.001 | Application Access Token |\n| T1595 | Active Scanning | T1595.002 | Vulnerability Scanning |\n| Social Engineering | T1586 | Compromise Accounts | T1586.002 | Email Accounts |\n| T1585 | Establish Accounts | T1585.002 | Email Accounts |\n| T1133 | External Remote Services |     |     |\n| T1534 | Internal Spearphishing |     |     |\n| T1566 | Phishing | T1566.001 | Spearphishing Attachment |\n| T1566.002 | Spearphishing Link |\n| T1566.003 | Spearphishing via Service |\n| T1598 | Phishing for Information | T1598.001 | Spearphishing Service |\n| T1550 | Use Alternate Authentication Material | T1550.001 | Application Access Token |\n| T1078 | Valid Accounts | T1078.002 | Domain Accounts |\n| System Intrusion | T1190 | Exploit Public-Facing Application |     |     |\n| T1212 | Exploitation for Credential Access |     |     |\n| T1211 | Exploitation for Defense Evasion |     |     |\n| T1068 | Exploitation for Privilege Escalation |     |     |\n| T1210 | Exploitation of Remote Services |     |     |\n| T1595 | Active Scanning | T1595.002 | Vulnerability Scanning |\n| T1586 | Compromise Accounts | T1586.001 | Social Media Accounts |\n| T1586 | Compromise Accounts | T1586.002 | Email Accounts |\n| T1133 | External Remote Services |     |     |\n| T1021 | Remote Services | T1021.001 | Remote Desktop Protocol |\n| T1550 | Use Alternate Authentication Material | T1550.004 | Web Session Cookie |\n| T1078 | Valid Accounts | T1078.001 | Default Accounts |\n| T1078.002 | Domain Accounts |\n| T1078.003 | Local Accounts |\n| T1078.004 | Cloud Accounts |\n| TA0002 | Execution |     |     |\n| TA0003 | Persistence |     |     |\n| TA0004 | Privilege Escalation |     |     |\n| TA0005 | Defense Evasion |     |     |\n| TA0006 | Credential Access |     |     |\n\n1. Recall that a hypothesis, at a general level, is an assumption, supposition/ or question about a particular attack or some of its behaviours or a detailed level about a single behaviour or TTP. [↑](#footnote-ref-2)\n\n2. This term is from MITRE [↑](#footnote-ref-3)","inputType":"MARKDOWN"},"output":[{"execution_time":"0.061 ms","outputType":"MARKDOWN","result":"SHOW – Supporting Threat Hunting with Opensearch and Wazuh\n\nBrian Lee, Xi Lan\n\nTable of Contents\n\n[Introduction 1](#_Toc1535243260)\n\n[Threat Hunting Overview 2](#_Toc2008270899)\n\n[What is Threat Hunting? 2](#_Toc2138436321)\n\n[Threat Hunting Process 2](#_Toc1048050875)\n\n[Threat Hunting Frameworks 2](#_Toc1623305131)\n\n[Threat Hunting Types 4](#_Toc778905970)\n\n[Threat Hunting Tools 4](#_Toc1840659150)\n\n[The SHOW Process 5](#_Toc349870514)\n\n[Prepare for the Hunt 6](#_Toc951503231)\n\n[Conduct the Hunt 8](#_Toc737491126)\n\n[Finish the Hunt 10](#_Toc56087398)\n\n[Annex 1 – MITRE TTP Framework 10](#_Toc2070861446)\n\n[Framework Conceptual Building Blocks 11](#_Toc341449715)\n\n[MITRE TH Process 12](#_Toc226184999)\n\n[Annex 2 –Commonly Observed TTPs 13](#_Toc743926800)\n\n[Reports Overview 13](#_Toc836960953)\n\n[Top 10 Techniques 14](#_Toc1409434483)\n\n[TTP Category 16](#_Toc263321644)\n\n# Introduction\n\nThis work describes how OpenSearch can be used to support threat hunting. It situates this support in the context of a specific threat hunting framework – the ‘TTP Based Hunting ‘ from MITRE and based on the ATT&CK framework. That is to say – SHOW is designed to follow the TTP-based process outlined by MITRE - the reason for this is quite simply to avoid reinventing the wheel. As will be seen from the description below elements of SHOW relate to other frameworks also and the intention is to expand SHOW to incorporate other elements of those frameworks.\n\nThreat hunting is a key activity to support the overall security defense processes for organisations and enterprises. It is an ad-hoc activity as opposed to continuous event monitoring and searches for any malicious activities that might have escaped the other monitoring and threat detection processes. An overview of threat hunting and the most common frameworks is given below. This is followed by a more in depth description of the MITRE threat hunting process with an elaboration of which parts of that process SHOW supports as well as a description of the SHOW implementation components.\n\nThe report also contains an annex outlining the most exploited TTPs over the last few years to provide SHOW users with a starting point for their hunting.\n\n# Threat Hunting Overview\n\n## What is Threat Hunting?\n\nSimply put threat hunting is a proactive activity to look for signs of attacks or malicious activity that may have been missed by other detection processes. It entails not only detecting but also understanding the attack consequences and removing/isolating the threat.\n\nThreat hunting can be triggered for several reasons e.g. by observing Indicators of Compromise (IoC) or other evidence that might lead to the identification of new threats or it could be motivated by appearance of new attacks in the wider business environment \\[ add Nour\\]. Alternatively, threat hunting can be used to explore new approaches to detect malicious behavior that can help can improve cyber defences, which may be more valuable over the longer time frame that the immediate discovery of threat.\\[ add PEAK\\]\n\n## Threat Hunting Process\n\nThreat hunting follows a well-known process cycle \\[add Nour\\] , derived from the **Sqrrl** Threat hunting framework \\[add Sqrrl\\] , as shown in Figure 1.\n\n1. _Create a hypothesis_: At a general level hypothesis is an assumption/supposition or question about a particular attack or some of its behaviours that might be present on the hunters network. At a more detailed level a hypothesis maybe narrowed to a single behaviour or TTP. The information leading to formation of a hypothesis arise from different sources following the motivation to do the threat hunt as outlined above.\n2. _Investigate with Tools & Techniques:_ In this step the hunter seeks to check the validity of the hypothesis using the tools (logs etc.) available. Typically this entails mapping the attack behaviour(s) to querie(s) over the various data source tools.\n3. _Uncover new patterns and TTP’s_: The hunt should return a number of events (“hits”) for the related queries. These may or may not support the hypothesis but are likely to create new pathways and raise new TTPs to be investigated\n4. _Inform hunters and enrich analytics_: In this step the hunter extends the scope or direction of the hunt and generates new queries etc. to follow up on the information thrown up by the previous steps.\n\n## Threat Hunting Frameworks\n\nThe process outlined in Figure 1describes the _execution_ of an actual hunt. There are however other steps , that precede and follow the execution step, in order to establish an comprehensive and effective threat hunting practice. A number of threat hunting _frameworks_ have arisen over the years to meet this need. A threat hunting process is “ a system of repeatable processes designed to make your threat hunting more effective and efficient” \\[PEAK\\]. Some of the more well know frameworks include:\n\n1. **Sqrrl**: This was one of the earliest and most influential frameworks and laid down the basic threat hunting principles that still recur today. Sqrrl incorporates other artefact including a Threat Hunitng maturity Model.\n2. **PEAK**: _The PEAK (Prepare, Execute, Act, Knowledge) framework_ \\[Splunk\\] is a very recent addition and has been designed to overcome some of the limitations in Sqrrl that became apparent over time. It incorporates the Sqrrl hypothesis-based hunt types and add two new threat hunt types - baseline, model-assisted (detailed below). The process steps are common to all three hunt types but their implementation may naturally vary. The steps, in more detail, are:\n3. _Prepare_: Hunters need to decide the focus, scope and outcomes of a threat hunt including the likely data sources and competences needed and need to prepare a plan for the hunt activities.\n4. _Execute:_ This step executes the hunt plan and refines and adapts as needed according to the returned results\n5. _Act :_ This step documents the findings and shares the results with other appropriate colleagues. It also identifies and carries out the any updates to the automated threat detection and defense systems\n6. _Knowledge:_ Knowledge is a broad term that include the human competence and expertise as well as accumulated lessons, data and analytics from previous threat hunts and from the present threat hunt.\n\n8. **TaHiTI** : _Targeted Hunting integrating Threat Intelligence_ \\[<https://www.betaalvereniging.nl/wp-content/uploads/TaHiTI-Threat-Hunting-Methodology-whitepaper.pdf> \\] - As the name implies incorporating cyber threat intelligence (CTI) to provide an starting point for the hunt and to provide context for the hunt. It uses hypotheses driven testing and introduces a new type of hunt – the unstructured threat hunt. It has three phases:\n9. _Initiate:_ Planning and preparation of the hunt.\n10. _Hunt:_ Execution of the hunt.\n11. _Finalise:_ Documentation and handover of the hunt.\n12. **TTP Hunting_:_** _TTP Based Hunting_ \\[<https://www.mitre.org/sites/default/files/2021-11/prs-19-3892-ttp-based-hunting.pdf> \\]. Although TTP are used in all hunting, Mitre has defined a hypothesis-based hunting process focused specifically on the well-known ATT&CK model i.e. “ hunt operations collect and utilize timely, actionable information on the techniques adversaries must employ across all systems of interest” – _actionable_ being the key word here. The model is explored in greater detail below.\n\nIn addition to the above a _general architecture_ for threat hunting is defined by Nour et al. It consists of three components that correspond roughly to the phases of the various frameworks above:\n\n1. **Input Sources** : They identify three types of input data\n2. _CTI –_ CVE’s, information on ongoing attack APT campaigns, AT&CK\n3. _Telemetry:_ logs, alerts (SIEM etc)\n4. _System Representation:_ network and computer system topology\n5. **Threat Hunting System** –. It contains two subsystems:\n6. _Data Knowledge Module:_ this refers to the data collection, processing and storage tolls and databases. It may include not just event logs but also topology representation and other tools.\n7. _Analysis Module:_ the ‘execution engine’ of the hunt – essentially executes the steps shown in Figure 1 above. It in turn consists of three sub modules These are_:_ _Analyser_ -generates hypotheses based on input from data knowledge module; _Tester_ -investigating and analysing each hypothesis using data visualization, search and similar techniques; _Evaluator_ -identifies malicious activities and attack patterns\n8. **Security Outputs:** This consists of two sub-parts\n9. _Responses:_ design and implementation of automated analytics and responses\n10. _Reporting:_ attack related information that could enhance overall security posture and future threat hunting.\n\n## Threat Hunting Types\n\nA number of different threat hunting types defined by the various frameworks are summarized here. Hunt types reflect differing technologies and purposes in executing a hunt.\n\nThe main types are\n\n1. _Hypothesis-based_: this is the original type and is used by all frameworks. As described above this approach is based on an assumption/supposition/question about a particular attack or some of its behaviours that might be present on the hunters network\n2. _Baseline_: this approach is proposed by PEAK. It entails establishing a baseline or profile of normal activity and then searching for deviations form that baseline. In this regard it can be seen as a form of anomaly detection. The hunter establishes a data-dictionary of the data for the entity in question and define statistics (average/median value, top-k values, cardinality of field) to charaterise ‘normal’. Techniques such as Least Frequency of Occurrence or ‘z-scores’ can be used to search for outliers.- See \\[oeak\\] for more detaisl.\n3. _Model-based_: this applies machine learning models to detect aberrant or suspicious behaviour. Algorithms for classification, clustering or time series analysis could be used. It should be pointed out that while these methods are used for threat detection their use here is on archived data and so can be thought of as expanding the original threat hunting process scope beyond hypothesis base through the use of machine learning – this can be said also for the baseline type.\n4. _Unstructured_: -proposed by TAHiTI. This type of hunting is initiated spontaneously based on the data (IoC, TTP) observed by an analyst in the course of their work. It is considered unstructured because hunting does not start with a hypothesis and does not follow a predetermined path.\n5. _Structured_: Opposite to unstructured, i.e. hypothesis based hunting that follows a planned approach using a framework- source TAHiTI\n6. _Situational_: Structured or unstructured hunting based on analysis generated from internal reports – source Nour et al.\\[Nour\\]\n\n#### Scope of the hunt\n\nAs can be seen from the above set of types, threat hunting can be initiated for a wide variety of reasons and starting positions. A hunt may for example start with a very narrow focus on an observed IoC or it may start with a very broad focus such cyber threat intelligence (CTI) emanating from one or more reports or research efforts describing a particular attack campaign. This latter focus would require careful and detailed enumeration of the TTP’s of interest described in the report. The process steps to be taken to prepare for and conduct the hunt are mostly the same – the primary different is the scope with a broader scope requiring some process steps to be repeated and the inclusion, perhaps, of some others\n\n## Threat Hunting Tools\n\nMany commercials tools exist to support threat hunting but these are not considered here. Instead we describe some open-sourced tools and repositories that may be of use to threat hunters. These include\n\nKestrel -\n\n# The SHOW Process\n\nBbbb\n\n## Prepare for the Hunt\n\n**Define the hunt objectives:**\n\nMITRE refers to this phase as “developing a malicious activity model”. The scope of the phase will vary depending on the particular focus and trigger mechanism\n\n#### Select activity\n\nDecide **what type of threat activity** or focus the hunt will address at a general level. This may be based different trigger points such as recent incidents, an overview of the current threat landscape, received threat intelligence .Examples include:\n\n1. TTP’s used by a particular adversary\n2. Particular attack campaign\n3. Attack lifecycle phase\n4. Data exfiltration\n\nGeneral level hypothesis may be formulated at this point e.g. ”_Attackers may be exfiltrating data from our system_” or “_How secure is our system against credential stealing_?’.\n\n#### Research and Refine\n\nResearch the identified focus to **gather as much** information as you can on the threat to help you understand how to shape your hunt approach. Refer to vendor threat intelligent reports, threat intelligence, security new websites, libraries etc. Use Appendix 2 as a starting point.\n\nThis step should add sufficient detail to the hunt focus to identify candidate TTP’s that are relevant to the focus\n\n#### Document findings\n\nDocument this in the notebook keeping track of essential information.\n\n**Define the hunt hypothesis:**\n\nThe previous steps have generated a list of TTP’s that will be used in the hunt. In this step we **generate a detailed hypotheses** for one or more of these TTP’s<sup>[\\[1\\]](#footnote-2)</sup>. The hypothesis should be formulated so that it can be **tested** i.e. so it can be verified, or not as the case may be, based on the evidence that can be collected from the computer system. It should therefore be clear, concise and precise enough. For example “_An attacker may be exfiltrating data using HTTPS tunneling_” or “_Attackers may be using Kerberoasting for credential stealing_”. Refine further if necessary to address e.g. specific enterprise missions or particular types of data.\n\nFor each hypothesis, **define an _analytic_**<sup>[\\[2\\]](#footnote-3)</sup> that will identify the behaviour noted in the TTP. An analytic takes the form of one or more queries to the Opensearch indexes to retrieve the required data. Queries may be formulated using either SQL or PPL.\n\nMITRE recommends to define an the analytic in abstract form i.e. in independent of any particular tool or underlying data source and gives as an example to describe an analytic for ‘process creation’ rather than formulating in OS specific (Linux or Windows) form. This can be useful in system where there are different sensors. For SHOW it is sufficient to use Opensearch queries directly. Worked examples , as Notebooks, showing hypothesis and their related analytics are provided.\n\n**Define the hunt scope:**\n\nDetermine Data Requirements\n\nThis step entails defining the required data sources.\n\nThe **hypothesis analytic** will define the types of data and data sources need to collect for the hunt. This will identify also the types of data sensor e.g. Host Intrusion Detection System (HIDS) or Network IDS or the specific types of log that are needed. In some cases it might require the addition of new sensors or reconfiguring or adding data collection agents (Wazuh agent or Syslog) to collect new logs or add new sources. This will depend also on which parts of the system are to be examined.\n\nAnother factor to consider is the requirements for **contextual informa**tion i.e. information on assets or other artefacts that may be related to the behaviour and that support the analysis and understanding of the behaviour. MITRE notes that sensors focused on automated detection may not give much contextual information and some combination of endpoint selection and response (EDR) tools, application logs and system event logs may be needed. There is of course a trade-off between the amount of contextual information and the volume of such information i.e. the greater the level of context detail (e.g. HIDS alerts vs API/Syscall logging) the greater the volume of data to be collected and analysed.\n\nAs MITRE notes “A good **data model** for hunting will relate what objects and actions an analyst wishes to capture to the key data (fields, values, attributes) needed from the environment’s sensors”. MITRE defines the Cyber Analytic Repository (CAR) model for this purpose – see Appendix 1 for more information on CAR. SHOW recommends also the use of the CAR data model for this step.\n\nDetermine the extent of the Analysis Space:\n\nEvery event that occurs in a computer system can be represented in three dimensions:\n\n- Time – seconds, minutes, ... years\n- Network assets – Windows hosts, Linux hosts, router, switches, etc.\n- Behaviour - TTPs\n\nThese three form a 3D space which (after MITRE) we term the Analysis Space. It is important to **determine the appropriate combination of these dimensions** in order to achieve an effective hunt. A very large analysis space will require a large amount of data and subsequent analysis while a too small analysis space may not yield any interesting or useful results.\n\n## Conduct the Hunt\n\n**Retrieve Data:**\n\nCollect the data\n\nPrevious steps have defined the data types and data sources and extent of the analysis space. In this step the **data is fetched** from the sources to a central collection point i.e. SIEM, data lakehouse etc. In many cases the required data may already have been collected.\n\nIf new or extra sensors are required then the necessary **configuration of agents** must be carried out in this step. Wazuh uses Wazuh agents or Syslog agents to collect data from end points. For new data sources it may be required to write Wazuh decoders and alerting rules to ingest the data and generate alerts. In some cases it may also be appropriate to assign TTP behaviour clarification for new behaviours. Refer to the Wazuh documentation.\n\nTune the analysis space\n\nAlthough an initial analysis space had been defined it may be **necessary to refine** or reshape this based on the actual data collected. SHOW provide visualization support to help with through the use of a heat map which enables the visualization of the three dimension of the analysis space.\n\nFor example if the x and y axes represent time and network assets, respectively, then the colour of each square can indicate the number of behaviours observed for the network assets for that period. Any obvious outliers can help to focus the hunt. Another example might be to switch the network assets and behaviour axes can detail the occurrence of certain behaviour through the network which might reveal the overall flow of an attack,\n\nMITRE provides a more detailed discussion on this topic with some interesting ideas. See especially section 2.4.3.1.\n\n**Evaluate the data:**\n\nAnalyse the Data\n\nAnalysing involves examining and interpreting collected information to discover patterns, relationships, or trends. The goal is to extract meaningful insights that can inform decision-making or improve understanding of the hunt hypothesis.\n\nIt typically includes organizing the data, applying statistical methods, and drawing conclusions based on the findings. There are many different analysis techniques that are used for hypothesis threat hunting. The techniques below are taken from the TaHITi framework \\[Tahiti\\]:\n\n1. _Visualisation_ – exploring relationships between data items visually\n\n- _Clustering_ -  Clustering is a statistical method used to group similar data points based on shared characteristics from a larger dataset. It is often applied in various fields, including for outlier detection, because it helps uncover patterns or behaviors that deviate from the norm, such as identifying an unusual number of occurrences of a typically common event. Hunters can utilize clustering to effectively identify aggregate behaviors in data analysis..\n- _Stack Counting_ -  Stacking entails counting the occurrences of specific values and focusing on identifying and analyzing any outliers within those results.”\n- _Grouping_ – This involves taking distinct artifacts and determining when multiple items from the set appear together according to specific criteria. The key distinction between grouping and clustering is that grouping works with a predefined set of items that are already deemed significant, rather than identifying patterns or similarities from a broader dataset.\n- _Querying_ - searching for specific data in the database.\n\nThere are many other forms of statistical and machine learning analysis that may be appropriate for different situations.\n\nGather Contextual Information\n\nContextual information is any supplementary information related to the collected data that can aid the analysis of the hypothesis. Contextual information can help establish links between other events and artefacts. Some examples of contextual information are\n\n1. Related processes – identifying other relevant processes or process chains can be of great value in the hunt to verify the hypothesis\n2. Network Information – can establish links to other network entities involved and help determine the bigger picture.\n3. System files\n4. User information\n5. Host Security posture e.g. vulnerabilities etc.\n\nThe MITRE document has useful guidelines for this activity.\n\nVerify the Hypothesis\n\nThis step determines if the hypothesis/goal of the hunt was achieved or not. There are three possible outcomes:\n\n1. _Hypothesis is proven_ – corroborating evidence has been found to validate the hypothesis. Further action may be necessary such as incident reporting or escalating the finding to another team e.g. to share findings as threat intelligence or write detector analytics for sensors.\n2. Hypothesis is not proven – no evidence was found to validate the hypothesis.\n3. _Inconclusive_ – There may be a variety of reasons for this – not enough data or incorrect data or the extent of the analysis space is incorrect or misconceived hypothesis.\n\n**Refine/Repeat:**\n\nIf the findings form the hunt are inconclusive or interim result determine the current hypothesis should be amended or replaced then the team may repeat previous steps. Otherwise the team moves to finish the hunt.\n\n## Finish the Hunt\n\n**Report Finding:**\n\nDocument the fundings\n\nThe results of the hunt should be documented. This should include the purpose, approach and conclusion from the hunt, any lesson learned or new information that can inform or improve security posture and practice.\n\nCommunicate the findings\n\nThe findings from the hunt are shared with other departments and interested parties. The actual distribution list may vary but all parties who can benefit from the findings should be included.\n\n**Preserve the Hunt:**\n\nArchive hunt details\n\nThe details of the hunt are stored in case the hunt needs to be revisited in the future. This should include _the_ data, tools and techniques used as well as any external information sources etc.\n\nAdd to hunt backlog\n\nSome teams maintain a backlog of potential future hunts. If so then any ideas for new hunts should be added here\n\n# Annex 1 – MITRE TTP Framework\n\nThe MITRE “TTP-Based Hunting” describes a threat hunting framework based on the use of MITRE ATT&CK based TTP’s that aims to “create a general threat hunting methodology focused on an identifying adversary behavior, structured within an adversary model, that does not depend on specific tools or products but rather describes what data is necessary, what types of data should be available from the sensors and how to use that data within the hunt”\n\nThis annex gives an overview of the MITRE framework – please refer to \\[\\] for a full description.\n\n## Framework Conceptual Building Blocks\n\nThe framework is hinged around a number of conceptual building blocks:\n\n**Adversary**: the bad guy i.e. the attacker or attack group\n\n**TTP’s** – primarily the behaviours and techniques of the ATT&CK model\n\n**Adversary model** – the ATT&CK matrix or more precisely the set of techniques used by an adversary and/or technique pathways through the matrix taken by an adversary\n\n**Analysis Space**; A three-dimensional space in which the hunt activities are situated. The dimensions of the space are formed by\n\n1. The computing and network environment – what MITRE calls the cyber terrain.\n2. The set of behaviours (TTPs) to be explored\n3. The time frame over which the hunt will be conducted.\n\nHunters can use tools such as heatmaps to visualize this space with the goal to refine and narrow down the hunt scope\n\n**Hypothesis**: effectively the behavior and related TTP to hunt.\n\n**Abstract Analytic**: the generic formulation of the search query to search for the behavior. Abstract here means the query is formulated in a tool independent form. Or as MITRE puts it “_analysts should be careful to avoid creating an analytic that is too specific to a particular instantiation of a particular tool_”.\n\nIn the MITRE TH framework analytics are often described using the Cyber Analytics Repository (CAR) \\[<https://car.mitre.org/> \\] CAR is a collection of analytics framed around the CAR data model (see below also) . An example of a CAR analytic for process creation is\n\n“CAR-2013-02-003: Processes Spawning cmd.exe”. The accompanying analytic is\n\nprocess = search Process:Create\n\ncmd = filter process where (exe == \"cmd.exe\")\n\noutput cmd\n\n_process_ and _exe_ are elements of the CAR data model.\n\nThe analytic returns a list of the processes spawned by the CMD shell. A mapping of this analytic to the DNIF SIEM \\[<https://www.dnif.it/en/\\>] is show as\n\n\\_fetch \\* from event where $LogName=WINDOWS-SYSMON AND $EventID=1 AND $Process=regex(.\\*cmd\\\\.exe.\\*)i limit 100\n\n**Data Model**: A data model provides a set of defined entity types to represent and reason about the data to be collected and processed during the hunt i.e. the data model relates “ _the system activities one wishes to capture to the key data (fields, values, attributes) needed from the sensors_”\n\nMITRE user the Cyber Analytics Repository (CAR) data model \\[<https://car.mitre.org/data_model/\\>] to model the system activity and data – see for example Figure x (derived from \\[\\]) in which a subset of this model based around the _process object_ is shown. The model describes the relationship between the _process_ and other object e.g. a process can create a _file_ which is the _loaded_as_ a _module_ and _launched_as_ a _process_. The CAR defines the action and attributes of the entities see table y \\[car\\] for the definition of the _file_ object – refer to \\[car data model \\] for a complete description of the data.\n\nTable x\n\n| Object | Action | Fields |\n| --- | --- | --- |\n| file | acl_modify  <br>create  <br>delete  <br>modify  <br>read  <br>timestomp  <br>write | company  <br>content  <br>creation_time  <br>extension  <br>file_name  <br>file_path  <br>fqdn  <br>gid  <br>group  <br>hostname  <br>image_path  <br>link_target  <br>md5_hash  <br>mime_type  <br>mode  <br>owner  <br>owner_uid  <br>pid  <br>ppid  <br>previous_creation_time  <br>sha1_hash  <br>sha256_hash  <br>signature_valid  <br>signer  <br>uid  <br>user |\n\nThe use of data models is not restricted to the MITRE TH framework. For example, Kestrel\n\n## MITRE TH Process\n\njj\n\n# Annex 2 –Commonly Observed TTPs\n\nThe purpose of this annex is to provide an understanding of the most common Tactics, Techniques, and Procedures (TTPs) employed by attackers, as highlighted in the key findings from the M-Trends 2023 and 2024 reports, as well as DBIR 2023 and 2024 reports. Understanding these TTPs is important to enable organizations to detect and quickly mitigate potential threats.\n\nThis chapter is structured into several sections, each focusing on different aspects of the TTPs reported in the reports above:\n\n1. Reports Overview: This section provides a summary of the four reports—M-Trends 2023, M-Trends 2024, DBIR 2023, and DBIR 2024. It outlies the context of these reports in understanding the current threat landscape.\n2. Top 10 Techniques: we enumerate and discuss the top 10 most observed TTPs from the M-Trends reports of 2023 and 2024.\n3. TTP Category: This section categorizes the top two TTPs for each phase of the Mandiant Targeted Attack Lifecycle as outlined in the M-Trends 2024 report. Also, we explore the ATT&CK techniques related to the attack categories discussed in the DBIR 2024 report.\n\n## Reports Overview\n\nThe Data Breach Investigations Report (DBIR) and M-Trends reports serve distinct but complementary purposes with each providing insights tailored to different audiences.\n\nThe **DBIR** reports, produced annually, are designed to provide a broad analysis of data breaches across various industries. Their primary purpose is to help organizations understand the patterns and trends in cyber incidents, enabling them to better anticipate and defend against potential threats. The 2023 and 2024 editions of the DBIR offer a detailed exploration of the evolving landscape of cyber threats and data breaches. Both reports utilize the VERIS (Vocabulary for Event Recording and Incident Sharing) framework, which categorizes incidents by the actors involved, the methods used, and the assets targeted. In the 2023 report, there is a clear emphasis on the role of external actors, predominantly financially motivated criminals, in executing data breaches. The report goes through common attack patterns such as system intrusion, social engineering, and basic web application attacks, providing a statistical overview of how these threats have manifested across various industries.\n\nThe 2024 DBIR builds on these insights, offering updated statistics and highlighting emerging threats. This report pays attention to the growing complexity of attack vectors, such as adversary-in-the-middle techniques that bypass multi-factor authentication (MFA). The 2024 edition also reflects on how the cybersecurity landscape has evolved, noting that while many of the same attack patterns persist, the methods employed by attackers are becoming increasingly advanced, necessitating a more robust approach to defense.\n\nIn contrast, the **M-Trends** reports from Mandiant are more specialized, focusing on advanced persistent threats (APTs) and the activities of attackers. The purpose of these reports is to provide in-depth analysis of the TTPs used by these adversaries. The 2023 M-Trends report highlights campaigns by groups like APT29, which have targeted both government and private sector organizations using advanced tactics, including phishing and the deployment of malware. Additionally, the report provides detailed mappings of the MITRE ATT&CK Techniques to the Mandiant Targeted Attack Lifecycle (see Table 5 below), offering organizations a clear framework to understand and defend against the specific TTPs used by these adversaries. This integration helps security professionals align their defenses with known threat behaviors, enhancing their ability to detect, respond to, and mitigate targeted attacks effectively.\n\nThe 2024 M-Trends report continues this analysis, documenting how attackers are increasingly bypassing traditional defenses, including MFA, through techniques such as session token theft and QR code phishing. This report not only details the threats but also offers mitigation strategies, emphasizing the need for organizations to stay ahead of these evolving tactics by adopting advanced detection and defense mechanisms.\n\nTogether, these four reports paint a picture of the cybersecurity landscape over two years. The DBIR reports offer broad insights into data breaches across industries, while the M-Trends reports provide a deeper dive into the strategies and techniques employed by most attackers. Both sets of reports underscore the importance of understanding and adapting to the ever-changing tactics used by cybercriminals, as well as the need for organizations to continuously evolve their defenses to keep pace with these threats.\n\nTop 10 Techniques\n\nIn both the 2023 and 2024 M-Trends reports, metrics are provided around the most observed techniques used by adversaries. However, the DBIR reports do not include a similar summary of frequently used TTPs. As a result, our focus in this chapter is on the insights provided by the M-Trends reports, highlighting the most prevalent techniques and sub-techniques utilized by adversaries as identified by Mandiant's analysis.\n\nTable 1 Top10 Most Frequently Seen Techniques Based On M_Trends_2023\n\n| Rank | Technique ID | Technique Name | Percentage |\n| --- | --- | --- | --- |\n| 1   | T1059 | Command and Scripting Interpreter | 50.90% |\n| 2   | T1027 | Obfuscated Files or Information | 43.50% |\n| 3   | T1071 | Application Layer Protocol | 33.10% |\n| 4   | T1082 | System Information Discovery | 31.60% |\n| 5   | T1070 | Indicator Removal | 31.50% |\n| 6   | T1083 | File and Directory Discovery | 29.50% |\n| 7   | T1140 | Deobfuscate/Decode Files or Information | 27.30% |\n| 8   | T1021 | Remote Services | 26.40% |\n| 9   | T1105 | Ingress Tool Transfer | 24.90% |\n| 10  | T1543 | Create or Modify System Process | 24.70% |\n\nTable 2 Top5 Most Frequently Seen Sub-Techniques Based On M_Trends_2023\n\n| Rank | Sub-Technique ID | Sub-Technique Name | Percentage |\n| --- | --- | --- | --- |\n| 1   | T1059.001 | PowerShell | 33.20% |\n| 2   | T1070.004 | File Deletion | 25.20% |\n| 3   | T1071.001 | Web Protocols | 24.30% |\n| 4   | T1569.002 | Service Execution | 21.80% |\n| 5   | T1021.001 | Remote Desktop Protocol | 20.30% |\n\nTable 1 and Table 2 show that adversaries frequently leveraged a command or scripting interpreter (T1059) in 50.9% of cases, with one-third of those intrusions involving the use of PowerShell (T1059.001). Mandiant's analysis also reveals the continued frequent use of web protocols (T1071.001) and Remote Desktop (T1021.001) across intrusions, suggesting that adversaries heavily rely on the organization's existing technologies to carry out their operations. These sub-techniques have consistently ranked in the top five over the past three years. This trend could indicate that detection capabilities for these techniques have improved, leading organizations to prioritize other evidence sources to capture additional techniques.\n\nTable 3 Top10 Most Frequently Seen Techniques Based On M_Trends_2024\n\n| Rank | Technique ID | Technique Name | Percentage |\n| --- | --- | --- | --- |\n| 1   | T1059 | Command and Scripting Interpreter | 52.30% |\n| 2   | T1027 | Obfuscated Files or Information | 46.50% |\n| 3   | T1083 | File and Directory Discovery | 38.60% |\n| 4   | T1021 | Remote Services | 37.30% |\n| 5   | T1082 | System Information Discovery | 37.10% |\n| 6   | T1070 | Indicator Removal | 35.10% |\n| 7   | T1071 | Application Layer Protocol | 34.00% |\n| 8   | T1033 | System Owner/User Discovery | 31.70% |\n| 9   | T1140 | Deobfuscate/Decode Files or Information | 31.50% |\n| 10  | T1190 | Exploit Public-Facing Application | 28.70% |\n\nTable 4 Top5 Most Frequently Seen Sub-Techniques Based On M_Trends_2024\n\n| Rank | Sub-Technique ID | Sub-Technique Name | Percentage |\n| --- | --- | --- | --- |\n| 1   | T1059.001 | PowerShell | 32.30% |\n| 2   | T1071.001 | Web Protocols | 29.60% |\n| 3   | T1021.001 | Remote Desktop Protocol | 28.30% |\n| 4   | T1569.002 | Service Execution | 26.80% |\n| 5   | T1070.004 | File Deletion | 26.60% |\n\nIn these tables, the techniques used by attackers in 2023, as detailed in the M-Trends 2024 report, remain consistent with those observed in 2022, as shown in the M-Trends 2023 report. Tables 3 and 4 demonstrate that the top 10 most frequently seen techniques have shown little variance over the past several years. **In more than half of the investigations, Mandiant noted the use of a command or scripting interpreter (T1059) by attackers.** A difference in the 2023 dataset is the inclusion of **System Owner or User Discovery (T1033)** and the **exploitation of public-facing applications (T1190)** among the top 10 observed techniques. These additions correlate with the rise in ransomware-related intrusions and the increase in mass exploitation campaigns observed in 2023.\n\nIt's unsurprising that the top five observed sub-techniques—PowerShell (T1059.001), Web Protocols (T1071.001), Remote Desktop Protocol (T1021.001), Service Execution (T1569.002), and File Deletion (T1070.004). Attackers likely favor these sub-techniques because they exploit readily available tools within a system, making them easy to abuse. Their proven success in compromising systems, coupled with their ability to sometimes evade security measures, makes them a highly effective part of an attacker’s toolkit. This persistent trend highlights the standard tactics employed by attackers to achieve their objectives. As such, organizations must prioritize detecting these sub-techniques if they have not already done so.\n\n## TTP Category\n\nMandiant provides techniques related to Mandiant’s Targeted Attack Lifecycle, which outlines the predictable sequence of events that cyber attackers use to carry out their attacks. To highlight the most impactful tactics, we have selected the top two techniques from each phase of the lifecycle, as shown in Table 5. This selection provides a detailed view of the most observed methods used by adversaries, thereby helping to understand into their operational patterns.\n\nTable 5 Techniques Related To M_Trends_2024 Targeted Attack Lifecycle\n\n| Mandiant Lifecycle Phase | Category | Technique ID | Technique Name | % of Attacks |\n| --- | --- | --- | --- | --- |\n| Initial Reconnaissance | Reconnaissance | T1595 | Active Scanning | 1.10% |\n| Resource Development | T1608 | Stage Capabilities | 12.80% |\n| T1583 | Acquire Infrastructure | 5.40% |\n| Initial Compromise | Initial Access | T1190 | Exploit Public-Facing Application | 28.70% |\n| T1133 | External Remote Services | 20.30% |\n| Establish Foothold | Persistence | T1543 | Create or Modify System Process | 28.30% |\n| T1098 | Account Manipulation | 18.60% |\n| Escalate Privileges | Privilege Escalation | T1543 | Create or Modify System Process | 28.30% |\n| T1055 | Process Injection | 25.10% |\n| Internal Reconnaissance | Discovery | T1083 | File and Directory Discovery | 38.60% |\n| T1082 | System Information Discovery | 37.10% |\n| Lateral Movement | Lateral Movement | T1021 | Remote Services | 37.30% |\n| T1570 | Lateral Tool Transfer | 2.30% |\n| Maintain Presence | Persistence | T1027 | Obfuscated Files or Information | 46.50% |\n| T1070 | Indicator Removal | 35.10% |\n| Mission Completion | Collection | T1213 | Data from Information Repositories | 16.70% |\n| T1560 | Archive Collected Data | 14.60% |\n| Exfiltration | T1567 | Exfiltration Over Web Service | 5.60% |\n| T1041 | Exfiltration Over C2 Channel | 3.60% |\n| Impact | T1486 | Data Encrypted for Impact | 25.50% |\n| T1489 | Service Stop | 15.90% |\n\nIn both the DBIR 2023 and 2024 reports, Verizon provided relevant ATT&CK techniques based on **three types o**f attacks, as defined in DBIR, which remained consistent across both years. These are:\n\n1. **Basic Web Application Attacks**, where threat actors continue to exploit assets with default, simplistic, and easily guessable credentials by brute forcing them, purchasing them, or reusing credentials from previous breaches.\n2. **Social Engineering**, where pretexting remains the leading cause of cybersecurity incidents, with actors targeting users through existing email chains and context. The prevalence of extortion also saw a dramatic increase, largely due to the large-scale MOVEit incident.\n3. **System Intrusion**, where, despite shifts in tactics leveraged by attackers, the overall impact of these actors continues to affect a majority of industries and organizations of all sizes.\n\nTable 6 shows the specific ATT&CK techniques related to these attack types as outlined in the DBIR 2024 report.\n\nTable 6 Relevant ATT&CK techniques relative to DBIR_2024\n\n| Type of attack | ATT&CK Technique | Technique Name | Sub-Technique | Sub-Technique Name |\n| --- | --- | --- | --- | --- |\n| Basic Web Application Attacks | T1110 | Brute Force | T1110.004 | Credential Stuffing |\n| T1110.002 | Password Cracking |\n| T1110.001 | Password Guessing |\n| T1110.003 | Password Spraying |\n| T1586 | Compromise Accounts | T1586.002 | Email Accounts |\n| T1190 | Exploit Public-Facing Application |     |     |\n| T1133 | External Remote Services |     |     |\n| T1586 | Compromise Accounts | T1586.002 | Email Accounts |\n| T1078 | Valid Accounts | T1078.001 | Default Accounts |\n| T1078.002 | Domain Accounts |\n| T1550 | Use Alternate Authentication Material | T1550.001 | Application Access Token |\n| T1595 | Active Scanning | T1595.002 | Vulnerability Scanning |\n| Social Engineering | T1586 | Compromise Accounts | T1586.002 | Email Accounts |\n| T1585 | Establish Accounts | T1585.002 | Email Accounts |\n| T1133 | External Remote Services |     |     |\n| T1534 | Internal Spearphishing |     |     |\n| T1566 | Phishing | T1566.001 | Spearphishing Attachment |\n| T1566.002 | Spearphishing Link |\n| T1566.003 | Spearphishing via Service |\n| T1598 | Phishing for Information | T1598.001 | Spearphishing Service |\n| T1550 | Use Alternate Authentication Material | T1550.001 | Application Access Token |\n| T1078 | Valid Accounts | T1078.002 | Domain Accounts |\n| System Intrusion | T1190 | Exploit Public-Facing Application |     |     |\n| T1212 | Exploitation for Credential Access |     |     |\n| T1211 | Exploitation for Defense Evasion |     |     |\n| T1068 | Exploitation for Privilege Escalation |     |     |\n| T1210 | Exploitation of Remote Services |     |     |\n| T1595 | Active Scanning | T1595.002 | Vulnerability Scanning |\n| T1586 | Compromise Accounts | T1586.001 | Social Media Accounts |\n| T1586 | Compromise Accounts | T1586.002 | Email Accounts |\n| T1133 | External Remote Services |     |     |\n| T1021 | Remote Services | T1021.001 | Remote Desktop Protocol |\n| T1550 | Use Alternate Authentication Material | T1550.004 | Web Session Cookie |\n| T1078 | Valid Accounts | T1078.001 | Default Accounts |\n| T1078.002 | Domain Accounts |\n| T1078.003 | Local Accounts |\n| T1078.004 | Cloud Accounts |\n| TA0002 | Execution |     |     |\n| TA0003 | Persistence |     |     |\n| TA0004 | Privilege Escalation |     |     |\n| TA0005 | Defense Evasion |     |     |\n| TA0006 | Credential Access |     |     |\n\n1. Recall that a hypothesis, at a general level, is an assumption, supposition/ or question about a particular attack or some of its behaviours or a detailed level about a single behaviour or TTP. [↑](#footnote-ref-2)\n\n2. This term is from MITRE [↑](#footnote-ref-3)"}]}],"savedNotebook":{"backend":".kibana_1.0","dateCreated":"2024-10-16T14:44:57.345Z","dateModified":"2024-12-17T09:58:42.480Z","name":"Resilmesh-SHOW-Opensearch Threat Hunting","paragraphs":[{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-10-16T14:51:09.294Z","dateModified":"2024-12-17T09:58:42.480Z","id":"paragraph_2351422b-a2e9-42ad-bd0a-2c5e21b637bb","input":{"inputText":"%md\n# SHOW – Supporting Threat Hunting with OpenSearch and Wazuh\n\n**Authors**: Brian Lee, Xi Lan\n\n---\n\n## Table of Contents\n1. [Introduction](#introduction)\n2. [Threat Hunting Overview](#threat-hunting-overview)\n   - [What is Threat Hunting?](#what-is-threat-hunting)\n   - [Threat Hunting Process](#threat-hunting-process)\n3. [Threat Hunting Frameworks](#threat-hunting-frameworks)\n4. [Threat Hunting Types](#threat-hunting-types)\n5. [Threat Hunting Process](#threat-hunting-process)\n6. [The SHOW Process](#the-show-process)\n   - [Prepare for the hunt](#prepare-for-the-hunt)\n   - [Conduct the Hunt](#conduct-the-hunt)\n   - [Finish the Hunt](#finish-the-hunt)\n7. [Use of Wazuh and OpenSearch Tools and Visualisations](#use-of-wazuh-and-opensearch-tools-and-visualisations)\n8. [Annex 1: MITRE TTP Framework](#annex-1--mitre-ttp-framwork)\n9. [Annex 2 – Commonly Observed TTPs](#annex-2--commonly-observed-ttps)\n10. [References](#references)\n\n---\n\n## Introduction\n\nThis work describes a methodology (SHOW) to support threat hunting in OpenSearch and Wazuh. \nIt situates this support in the context of a specific threat hunting framework – the ‘TTP Based Hunting‘  [1]\nfrom MITRE based on the ATT&CK framework. SHOW is designed to follow the TTP-based process outlined by MITRE - the reason for this is quite simply to avoid reinventing the wheel. As will be seen from the description below elements of SHOW relate to other frameworks also and the intention is to expand SHOW, over time, to incorporate other elements of those frameworks. \nThreat hunting is a key activity to support the overall security defense processes for organisations and enterprises. It is an ad-hoc activity as opposed to continuous event monitoring and searches for any malicious activities that might have escaped the other monitoring and threat detection processes. An overview of  threat hunting and the most common frameworks is given below. This is followed by a more in depth description of the MITRE threat hunting  process, which parts of that process SHOW supports as well as a description of the SHOW implementation components.\nThe report also contains an annex outlining the most exploited TTPs over the last few years to provide SHOW users with a starting point for their hunting.\n\n\n---\n## Threat Hunting Overview \n\n## What is Threat Hunting?\n\nSimply put, threat hunting is a proactive activity to look for signs of attacks or malicious activity that may have been missed by other detection processes. It entails not only detecting but also understanding the attack consequences and removing/isolating the threat.\nThreat hunting can be triggered for several reasons e.g. by observing Indicators of Compromise (IoC) or other evidence that might lead to the identification of new threats or it could be motivated by appearance of new attacks in the wider business environment[3]. Alternatively, threat hunting can be used to explore new approaches to detect malicious behavior that can help improve cyber defences, which may be more valuable over alonger time frame than the immediate discovery of threat.\n\n\n---\n## Threat Hunting Process \nThreat hunting follows a well-known  process cycle derived from the Sqrrl threat hunting framework [2], as shown in Figure 1.\n![Figure 1](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure1.png)\n1.Create a hypothesis: At a general level hypothesis is an assumption/supposition or question about a particular attack or some of its behaviours that might be present on the hunters network. At a more detailed level, a hypothesis may be narrowed to a single behaviour or TTP.  The information leading to formation of a hypothesis arises from different sources following the motivation to do the threat hunt as outlined above.  \n\n2.Investigate with Tools & Techniques: In this step the hunter seeks to check the validity of the hypothesis using the tools (logs etc.) available. Typically this entails mapping the attack behaviour(s) to querie(s) over the various data source tools. \n\n3.Uncover new patterns and TTP’s: The hunt should return a number of events events (“hits”) for the related queries. These may or may not support the hypothesis but are likely to create new pathways and raise new TTPs to be investigated.\n\n4.Inform and enrich analytics: In this step the hunter extends the scope or direction of the hunt and generates new queries etc. to follow up on the information thrown up by the previous steps.\n\n\n---\n## Threat Hunting Frameworks\n\nThe process outlined in Figure 1describes the execution of an actual hunt. There are however other steps , that precede and follow the execution step, in order to establish an comprehensive and effective threat hunting practice. A number of threat hunting  frameworks have arisen over the years to meet this need. A threat hunting framework is “ a system of repeatable processes designed to make your threat hunting more effective and  efficient” [3]. Some of the more well know frameworks include:\n\n1. **Sqrrl Framework**: This was one of the earliest and most influential frameworks and laid down the basic threat hunting principles that still recur today. Sqrrl incorporates other artefact including a Threat Hunting Maturity Model [2].\n2. **PEAK Framework (Prepare, Execute, Act, Knowledge)**: The PEAK  (Prepare, Execute, Act, Knowledge) framework [4] is a very recent addition, from Splunk, and has been designed to overcome some of the limitations in Sqrrl that became apparent over time. It incorporates the Sqrrl hypothesis-based hunt types and add  two new threat hunt types – baseline and model-assisted (detailed below). The process steps are common to all three hunt types but their implementation may naturally vary. The steps, in more detail, are:\n   - Prepare: Hunters need to decide the focus, scope and outcomes of a threat hunt including the likely data sources and competences needed and need to prepare a plan for the hunt activities.\n   - Execute: This step executes the hunt plan and refines and adapts as needed according to the returned results.\n   - Act : This step documents the findings and shares the results with other appropriate colleagues. It also identifies and carries out the any updates to the automated threat detection and defense systems\n   - Knowledge: Knowledge is a broad term that include the human competence and expertise as well as accumulated lessons, data and analytics  from previous threat hunts and from the present threat hunt.\n\n3. **TaHiTI**: Targeted Hunting integrating Threat Intelligence [5] - As the name implies incorporating cyber  threat intelligence (CTI) to provide a starting point for the hunt and to provide context for the hunt. It uses hypotheses driven testing and introduces a new type of hunt – the unstructured threat hunt. It has three phases:\n   - Initiate: Planning and preparation of the hunt.\n   - Hunt: Execution of the hunt.\n   - Finalise: Documentation and handover of the hunt.\n\n4. **TTP-based Hunting**: Although TTP are used in all hunting, Mitre has defined a  hypothesis-based hunting process [1] focused specifically on the well-known ATT&CK model i.e. “ hunt operations collect and utilize timely, actionable information on the techniques adversaries must employ across all systems of interest” – actionable being the key word here.  The model is explored in greater detail in Annex 1.\n\nIn addition to the above a general architecture for threat hunting is defined by Nour et al. [2]. It consists of three components that correspond roughly to the phases of the various frameworks above:\n   - **Input Sources**: They identify three types of input data \n       - CTI – CVE’s, information on ongoing attack APT campaigns, ATT&CK\n       - Telemetry: logs, alerts (SIEM etc.) \n       - System Representation: network and computer system topology \n   - **Threat Hunting System**: It contains two subsystems:\n       - Data Knowledge Module: this refers to the data collection, processing and storage tolls and databases. It may include not just event logs but also topology representation and other tools.\n       - Analysis Module: the ‘execution engine’ of the hunt – essentially executes the steps shown in Figure 1 above. It in turn consists of three sub modules These are: Analyser -generates hypotheses  based on input from data knowledge  module;  Tester -investigating and analysing each hypothesis using data visualization, search and similar techniques; Evaluator -identifies malicious activities and attack patterns.\n   - **Security Outputs**:This consists of two sub-parts\n       - Responses: design and implementation of automated analytics and responses\n       - Reporting: attack related information that could enhance overall security posture and future threat hunting.\n\n\n\n\n\n---\n\n## Threat Hunting Types\nA number of different threat hunting types defined by the various frameworks are summarized here. Hunt types reflect differing technologies and purposes in executing a hunt. \nThreat hunting can be categorized into several types:\n\n- **Hypothesis-based Hunting**: this is the original type and is used by all frameworks. As described above this approach is based on an assumption/supposition/question about a particular attack or some of its behaviours that might be present on the hunters network.\n- **Baseline-based Hunting**: this approach is proposed by PEAK. It entails establishing a baseline or profile of normal activity and then searching for deviations form that baseline. In this regard it can be seen as a form of anomaly detection. The hunter establishes a data-dictionary of the data for the entity in question and define statistics  (average/median value, top-k values, cardinality of field) to charaterise ‘normal’. Techniques such as Least Frequency of Occurrence (“Stacking”) or ‘z-scores’ can be used to search for outliers.- See for “Visualisations and Tools” chapter  more details.\n- **Model-based Hunting**: this applies machine learning models to detect aberrant or suspicious behaviour. Algorithms for classification, clustering or time series analysis could be used. It should be pointed out that while these methods are used for threat detection their use here is on archived data and so can be thought of as expanding the original threat hunting process scope beyond hypothesis base through the use of machine learning – this can be said also for the baseline type.\n- **Unstructured Hunting**: -proposed by TAHiTI .  This type of hunting is initiated spontaneously based on the data (IoC, TTP) observed by an analyst in the course of their work.  It is considered unstructured because hunting does not start with a hypothesis and does not follow a predetermined path.\n- **Structured Hunting**: Opposite to unstructured, i.e. hypothesis based hunting that follows a planned  approach using a framework- source TAHiTI[5].\n- **Situational: **: Structured or unstructured hunting based on analysis generated from internal reports – source Nour et al[2].\n---\n\n## Threat Hunting Process\n\nThreat hunting typically follows a continuous cycle, which can be summarized as:\n\n1. **Create a Hypothesis**:\n   - Formulate a question or assumption about a specific attack or behavior.\n2. **Investigate Using Tools and Techniques**:\n   - Validate hypotheses using logs, queries, OpenSearch dashboards, and other tools.\n3. **Uncover New Patterns**:\n   - Discover additional pathways, connections, and emerging TTPs.\n4. **Inform and Enrich Analytics**:\n   - Refine queries, enrich data, and expand the scope of the hunt.\n\n---\n\n## The SHOW Process\n\nThe process is described below and outlined in Figure 2. Individual hunt progress, according to this process, should be documented in OpenSearch notebook(s).\n![Figure 2](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure2.png)\n1. **Prepare for the Hunt**:\n\n   ***Define the hunt objectives***: \n      \nMITRE refers to this phase as “developing a malicious activity model”. The scope of the phase will vary depending on the particular focus and trigger mechanism.\n   - Select activity:\n     \n     Decide what type of threat activity or focus the hunt will address at a general level. This may be based different trigger points such as recent incidents, an overview of the current threat landscape, received threat intelligence .Examples include:\n      - TTP’s used by a particular adversary \n      - Particular attack campaign \n      - Attack lifecycle phase  \n      - Data exfiltration \n     General level hypothesis may be formulated at this point e.g. ”Attackers may be exfiltrating data from our system” or “How secure is our system against credential stealing?’.\n   - Research and Refine\n     Research the identified focus to gather as much information as you can on the threat  to help you understand how to shape your hunt approach. Refer to vendor threat intelligent reports, threat intelligence,  security new websites, libraries etc. Use Annex 2 as a starting point. \n\n   ***Define the hunt hypothesis***:\n\nThe previous steps have generated a list of TTP’s that will be used in the hunt. In this step we generate a detailed hypotheses for one or more of these TTP’s .  The hypothesis should be formulated so that it can be tested i.e. so it can be verified, or not as the case may be,  based on the evidence that can be collected from the computer system. It should therefore be clear, concise and precise enough.\nFor example  “An attacker may be exfiltrating data using HTTPS tunneling” or “Attackers may be using Kerberoasting for credential stealing”. Refine further if necessary to address e.g. specific enterprise missions or particular types of data.\nFor each hypothesis, define an  analytic  that will identify the behaviour noted in the TTP. An analytic takes the form of one or more queries to the Opensearch indexes to retrieve the required data. Queries may be formulated using either SQL or PPL.\nMITRE recommends to define an the analytic in abstract form i.e. in independent of any particular tool or underlying data source and gives as an example to describe an analytic for ‘process creation’ rather than formulating in OS specific (Linux or Windows) form. This can be useful in system where there are different sensors. For SHOW it is sufficient to use Opensearch queries directly. Worked examples , as Notebooks, showing hypothesis and their related analytics are provided.\n\n   ***Define the hunt scope***:\n\n   - Determine Data Requirements:\n\nThis step entails defining the required data sources.\nThe hypothesis analytic will define the types of data and data sources need to collect for the hunt. This will identify also the types of data sensor e.g. Host Intrusion Detection System (HIDS) or Network IDS or the specific types of log that are needed. In some cases it might require the addition of new sensors or reconfiguring or adding data collection agents (Wazuh agent or Syslog) to collect new logs or add new sources. This will depend also on which parts of the system are to be examined.\nAnother factor to consider is the requirements for contextual information i.e. information on assets or other artefacts that may be related to the behaviour and that support the analysis and understanding of the behaviour. MITRE notes that sensors focused on automated detection may not give much contextual information and some combination of endpoint selection and response (EDR) tools, application logs and system event logs may be needed. There is of course a trade-off between the amount of contextual information and the volume of such information i.e. the greater the level of context detail (e.g. HIDS alerts vs API/Syscall logging) the greater the volume of data to be collected and analysed.\nAs MITRE notes  “A good data model for hunting will relate what objects and actions an analyst wishes to capture to the key data (fields, values, attributes) needed from the environment’s sensors”. MITRE defines the Cyber Analytic Repository (CAR) model for this purpose – see Appendix 1 for more information on CAR. SHOW recommends also the use of the CAR data model for this step.\n\n   - Determine the extent of the Analysis Space:\n     \nEvery event that occurs in a computer system can be represented in three dimensions:\n\n        - Time – seconds, minutes, ... years\n        - Network assets – Windows hosts, Linux hosts, router, switches, etc. \n        - Behaviour - TTPs\n\nThese three form a 3D space which (after MITRE) we term the Analysis Space – see Figure 3 depicts the 3D analysis space (based on [1]) . It is important to determine the appropriate combination of these dimensions in order to achieve an effective hunt.  A very large analysis space will require a large amount of data and subsequent analysis while a too small analysis space may not yield any interesting or useful results.\n![Figure3](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure3.png)\n\n2. **Conduct the Hunt**:\n   \n   ***Retrieve Data***: \n\n   - Collect the data : Previous steps have defined the data types and data sources and extent of the analysis space. In this step the data is fetched from the sources to a central collection point i.e. SIEM, data lakehouse etc. In many cases the required data may already have been collected. \nIf new or extra sensors are required then the necessary configuration of agents must be carried out in this step. Wazuh uses Wazuh, Syslog, or other (Vector, Fluentbit etc.) agents to collect data from end points. For new data sources it may be required to write Wazuh decoders and alerting rules to ingest the data and generate alerts. In some cases it may also be appropriate to assign TTP behaviour clarification for new behaviours. Refer to the Wazuh documentation.\n\n   - Tune the analysis space: \n\nAlthough an initial analysis space had been defined it may be necessary to refine or reshape this based on the actual data collected. SHOW provide visualization support to help with through the use of a heat map which enables the visualization of the three dimension of the analysis space e.g. see Figure 4 below.\nFor example if the x and y axes represent time and network assets, respectively, then the colour of each square can indicate the number of behaviours observed for the network assets for that period. Any obvious outliers can help to focus the hunt. Another example might be to switch the network assets and behaviour axes can detail the occurrence of certain behaviour through the network which might reveal the overall flow of an attack. MITRE provides a more detailed discussion on this topic with some interesting ideas. See especially section 2.4.3.1.\n![Figure4](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure4.png)\n   ***Evaluate the data***:\n\n   - Analyse the Data\n\nAnalysing involves examining and interpreting collected information to discover patterns, relationships, or trends. The goal is to extract meaningful insights that can inform decision-making or improve understanding of the hunt hypothesis.\nIt typically includes organizing the data, applying statistical methods, and drawing conclusions based on the findings. There are many different analysis techniques that are used for hypothesis threat hunting. The techniques below are taken from the TaHITi framework [5]:\n     - Visualisation – exploring relationships between data items visually\n     - Clustering -  Clustering is a statistical method used to group similar data points based on shared characteristics from a larger dataset. It is often applied in various fields, including for outlier detection, because it helps uncover patterns or behaviors that deviate from the norm, such as identifying an unusual number of occurrences of a typically common event. Hunters can utilize clustering to effectively identify aggregate behaviors in data analysis.\n     - Z-value test- a z test is a simple model to estimate outliers. It calculates the number of standard deviations by which the data deviates from the mean. Very often a value of z > 3 is used to indicate an anomalous data point. \n     - Stack Counting -  Stacking entails counting the occurrences of specific values and focusing on identifying and analyzing any outliers within those results-normally based on ‘least frequency of occurrence’.\n     - Grouping – This involves taking distinct artifacts and determining when multiple items from the set appear together according to specific criteria. The key distinction between grouping and clustering is that grouping works with a predefined set of items that are already deemed significant, rather than identifying patterns or similarities from a broader dataset. \n     - Querying -  searching for specific data in the database.\nThere are many other forms of statistical and machine learning analysis that may be appropriate for different situations.\n\n   - Gather Contextual Information\n\nContextual information is any supplementary information related to the collected data that can aid the analysis of the hypothesis. Contextual information can help establish links between other events and artefacts. Some examples of contextual information are:\n     - Related processes – identifying other relevant processes or process chains can be of great value in the hunt to verify the hypothesis\n     - Network Information – can establish links to other network entities involved and help determine the bigger picture.\n     - System files\n     - User information\n     - Host Security posture  e.g. vulnerabilities etc.\nThe MITRE document has useful guidelines for this activity.\n\n   - Verify the Hypothesis\n\nThis step determines if the hypothesis/goal of the hunt was achieved or not. There are three possible outcomes:\n     - Hypothesis proven - – corroborating evidence has been found to validate the hypothesis. Further action may be necessary such as incident reporting or escalating the finding to another team e.g. to  share findings as threat intelligence  or write detector analytics for sensors\n     - Hypothesis is not proven - no evidence was found to validate the hypothesis.\n     - Inconclusive – There may be a variety of reasons for this – not enough data or incorrect data or the extent of the analysis space is incorrect or misconceived hypothesis.\n\n   ***Refine/Repeat:***\n\nIf the findings from the hunt are inconclusive or interim results determine the current hypothesis should be amended or replaced then the team may repeat previous steps. Otherwise the team moves to finish the hunt.\n\n3. **Finish the Hunt**:\n\n   ***Report findings***\n\n   - Document the findings:\n\nThe results of the hunt should be documented, as a notebook This should include the purpose, approach and conclusion from the hunt, any lesson learned or new information that can inform or improve security posture and practice.\n\n   - Communicate the findings:\n\nThe findings from the hunt are shared with other departments and interested parties. The actual distribution list may vary but all parties who can benefit from the findings should be included.\n\n   ***Preserve the Hunt***:\n\n   - Archive hunt details: \nThe details of the hunt are stored in case the hunt needs to be revisited in the future. This should include the data, tools and techniques used as well as any external information sources etc. Reports may be generated by the OpenSearch reporting activity.\n\n   - Add to hunt backlog:\nSome teams maintain a backlog of potential future hunts. If so then any ideas for new hunts should be added  here.\n\n---\n\n## Use of Wazuh and OpenSearch Tools and Visualisations\nWazuh and OpenSearch provide several tool and visualisation support to support the threat hunting process. A summary of the main supports are given here and a more in depth description including worked examples is provided in a OpenSearch Notebook.\n### Visualizations\nOpenSearch Dashboards is used in both Wazuh and OpenSearch for visualiations (equivalent to Kibana in Elasticsearch). It provides several of the predefined visualisations and users may also create custom visualisations  - see Figure 4 below, which shows a range of the type of visualisations that OpenSearch offers. \nFigure 4 shows an example of a heatmap to visualize the analysis space depicted in Figure x above. It shows the distribution of TTP over time with the coloured cells indicating the number of machines impacted. Several other examples are shown in the example’s notebooks accompanying this process description.\nIn addition to the capability to define own visualisations, Wazuh has a number of predefined dashboards including “Threat Hunting” and  “MITRE ATT&CK” which provide much useful information.\n![Figure4](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure4.png)\n![Figure5](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure5.png)\n\n###Search Techniques\nOpenSearch has several ways to search for data including the following (not all methods are described) :\n- **SQL**:  Full SQL syntax support for querying, aggregations, and joins and can be integrated with dashboards for visualization.\n- **PPL (Piped Processing Language)**: Executes queries step-by-step using piped syntax (|). Moreover, it handles filtering, aggregation, and transformations in a single query. It is ideal for log analytics and ad-hoc querying. PPL is the default language used in SHOW hunting notebooks.\n- **Query DSL**: OpenSearch provides a search language called query domain-specific language (DSL) that you can use to search your data. Query DSL is a flexible language with a JSON interface. It enables creation of complex queries and can be used structure keyword and full text queries as well as geographic queries.\n- **Text search**: OpenSearch support both keyword search (traditional search based on exact or partial matches of terms in text field)  and full text based search (Advanced text search using relevance-based ranking (TF-IDF, BM25).\n- **Vector/Semantic search**: Indexes and searches high-dimensional vectors using deep learning techniques. This enables semantic search for similar meanings (e.g., “laptop” matches “notebook”) and is useful for AI/ML-driven applications like recommendation systems and image search.\n- **Conversational search**: allows you to ask questions in natural language and refine the answers by asking follow-up questions. Thus, the conversation becomes a dialog between you and a large language model (LLM). Conversational search is a recent feature in OpenSearch.\n- **Neural search** transforms text into vectors and facilitates vector search both at ingestion time and at search time. During ingestion, neural search transforms document text into vector embeddings and indexes both the text and its vector embeddings in a vector index. When you use a neural query during search, neural search converts the query text into vector embeddings, uses vector search to compare the query and document embeddings, and returns the closest results.\nThe reader is referred to  OpenSearch documentation for more information on all query types.\n### Visualization Tools:\n- OpenSearch **dashboards**, heatmaps, and graphs.\n\n### Tools for Analysis\nIn addition to the visualisation capabilities referred to above OpenSearch provides other features which can be used for data analysis. In the “Analyse the Data” some analysis  techniques were described\nZ-test – a z score can be calculated in OpenSearch using SQL as in the example below:\n\n```PPL\nsource=my_logs\n| stats avg(response_time) AS mean_response, stddev(response_time) AS stddev_response\n| eval z_score = (response_time - mean_response) / stddev_response\n| where abs(z_score) > 3\n```\n\nGrouping – can be implemented using the PPL stats function and the BY clause e.g.\n```PPL\nsource=wazuh-alert* | stats count(data.win.system.eventID) AS total_event, avg(rule.firedtimes) AS avg_time BY data.win.system.eventID\n```\n\nStacking - can be implemented using the PPL stats function and by sorting in ascending frequency (as below). Descending frequency could also be used. See also the Visualisation examples notebook.\n```PPL\nsource=wazuh-alert*\n| stats count(data.win.system.eventID) AS frequency BY data.win.system.eventID\n| sort + frequency\n```\nClustering – clustering, as noted above, is a statistical method to group similar items. It is not so easily done, on first sight at least, using simple querying as it involves the use of a statistical or machine learning algorithm. OpenSearch provides a number of ways to enable clustering including K-means and Random Cut Forest (RCF) which are provided through the ML Plugin -RCF is discussed in detail below in Anomaly Detection. K-means is an unsupervised learning algorithm that partitions data points into k clusters – see the OpenSearch documentation for a fuller description of its use. It can also be used as part of a PPL query as in the example \n```PPL\nsource=iris_data | fields sepal_length_in_cm, sepal_width_in_cm, petal_length_in_cm, petal_width_in_cm | kmeans centroids=3\n```\nbelow to group flowers in the iris dataset.  PPL also supports the use of clustering using RCF  as in the below example which detects anomalies in the ridership data. \n```PPL\nsource=nyc_taxi | fields value, timestamp | AD time_field=’timestamp’ | where value=10844.0\n```\n\n***Anomaly Detection***\nAnomaly detection can help threat hunting by detecting deviations from baseline i.e. normal behaviour. There many approaches to detect anomalies depending on the domain, data characteristics (e.g. time series vs random data occurrences..) etc. Anomaly detection in OpenSearch is directly supported by the Anomaly Detector Plugin as well as the opensearch-py  Python libraries (see below).  \nThe Anomaly Detection plugin supports the use of the Random Cut Forest (RCF) algorithm for anomaly detection. RCF is optimized for detecting anomaly detection in streaming or time-series data. .Based on the input, the plugin uses two types of RCF algorithms: fixed in time RCF for processing time-series data and batch RCF for processing non-time-series data. It can also be used in this way for collecting cybersecurity logs. RCF works by building decision trees to isolate individual points of data. Data is which is denser (clustered) will take more cuts to isolate and hence will be deeper in the tree. RCF gauges anomalies as (the inverse of)  the ratio between the  depth of a point in the tree and the depth of a random point in the tree with points being marked anomalous above some threshold chosen by the user. In fact RCF builds a number of trees and averages the measurements across the trees – it is therefore an ensemble method. RCF is an unsupervised learning approach and adapts to any changes in data distribution etc. and can be considered a form of online learning.\n\nOpenSearch allows up to 5 features to be included as the base for the algorithm. Features must be aggregated through the use of functions such as sum(), count(), min(), max() etc. This both minimizes noise effects and also enables the detection of particular data patterns. For example to detect anomalous peaks/spikes in network traffic the max() function would be used while to detect variation in user logins in a system the count() function could be used.\n\n***Machine Learning (ML) Commons Plugin***\nThe ML plugin introduces a Machine Learning library inside the OpenSearch cluster. The major functionalities in this solution include:\n   - **Unified Client Interfaces**: clients can use common interfaces for training and inference tasks, and then follow the algorithm interface to give right input parameters, such as input data, hyperparameters. A client library will be built for easy use.\n   - **ML Plugin**: ML plugin will help to initiate the ML nodes, and choose the right nodes and allocate the resources for each request, and manage machine learning tasks with monitoring and failure handing supports, and store the model results; it will be the bridge for the communication between OpenSearch process and ML engine.\n   - **ML Engine**: This engine will be the host for ML algorithms. Java based machine learning algorithms will be supported in the first release.\nUser can use a pretrained model provided by OpenSearch, upload their own model to the OpenSearch cluster, or connect to a foundation model hosted on an external platform. \nML function can provide many types of analytic support for threat hunting including anomaly detection, topology models to learn the representation or structure of the connections and relationships between elements in a system e.g. to generate systems provenance data models showing causal links between process, files, registry and other system entities. \nAs well as k-means and RCF the plugin has native support for linear and logistic regression and localisation (finds subset-level information for aggregate data (for example, aggregated over time) that demonstrates the activity of interest, such as spikes, drops, changes, or anomalies).\n\n***Opensearch-py***\nThis provides a Pythonic interface to perform operations such as indexing, querying, and managing OpenSearch clusters thereby enabling developers to integrate OpenSearch functionalities into Python applications. It gives full access to AI libraries such as Scikit, Keras etc. enabling the use of numerous algorithms therein. Typical use cases include: \n   - **Search Applications**: Build Python applications with OpenSearch-powered search features.\n   - **Analytics Dashboards**: Integrate with tools like Dash, Flask, or Django to display search and analytics results.\n   - **AI/ML Pipelines**: Use vector search for semantic matching or integrate OpenSearch with ML workflows.\nWhile these AI/ML features provide powerful analytic features they require sometimes considerable work to set up and configure and while they can be regarded as ad-hoc tools to assist hypotheses based hunts they can also form stand-alone hunt methodologies as pointed out by  [1][4]. For that reason , since this version of SHOW is only hypothesis-based, we defer further discussion on these approaches to a later version.\n\n###Mapping to Hunt Phases\n\nThe relationship between the tools above and the hunt steps is shown in Table 1  \n*Table 1 Tool use in the Hunt phases.*\n\n| **Hunt Phase**           | **Visualizations** | **ML** | **Anomaly Detection** | **Search** | **LLM** | **Notebooks (Reporting)** |\n|---------------------------|--------------------|--------|-----------------------|------------|---------|---------------------------|\n| **Define Hunt Objectives**| X                  |        | X                     | X          | X       | X                         |\n| **Determine Hypothesis**  | X                  |        |                       | X          | X       |                           |\n| **Define Scope**          | X                  |        |                       | X          | X       |                           |\n| **Retrieve Data**         |                    |        |                       |            | X       |                           |\n| **Evaluate the Data**     | X                  | X      | X                     |            | X       |                           |\n| **Report**                |                    |        |                       |            |         | X                         |\n| **Preserve Hunt**         |                    |        |                       |            |         | X                         |\n\nLLM is shown as potential area for evaluation in future versions.\n\n\n\n\n\n---\n\n## Annex 1: MITRE TTP Framework\nThe MITRE “TTP-Based Hunting” describes a threat hunting framework based on the use of MITRE ATT&CK based TTP’s that aims to “create a general threat  hunting methodology focused on an identifying adversary behavior,   structured within an adversary model, that does not depend on specific tools or products but rather describes what data is necessary, what types of data should be available from the sensors and how to use that data within the hunt”\nThis annex gives an overview of the MITRE framework – please refer to [1]for a full description.\n\n### Framework Conceptual Building Blocks\nThe framework is hinged around a number of conceptual building blocks:\n\nAdversary: the bad guy i.e. the attacker or attack group\n\nTTP’s – primarily the behaviours and techniques of the ATT&CK model\n\nAdversary model – the ATT&CK matrix or more precisely the set of techniques used by an adversary  and/or  technique pathways through the matrix taken by an adversary\n\nAnalysis Space; A three-dimensional space in which the hunt activities are situated. The dimensions of the space are formed by:\n   - The computing and network environment – what MITRE calls the cyber terrain.\n   - The set of behaviours (TTPs) to be explored\n   - The time frame over which the hunt will be conducted.\nHunters can use tools such as heatmaps to visualize this space with the goal to refine and narrow down the hunt scope.\n\nHypothesis: effectively the behavior and related TTP to hunt.\n\nAbstract Analytic: the generic formulation of the search query to search for the behavior. Abstract here means the query is formulated in a tool independent form. Or as MITRE puts it “analysts should be careful to avoid creating an analytic that is too specific to a particular instantiation of a particular tool”. \n\nIn the MITRE TH framework analytics are often described using the Cyber Analytics Repository (CAR) [https://car.mitre.org/ ] CAR is a collection of analytics framed around the CAR data model (see below also) . An example of a CAR analytic for process creation is  \n“CAR-2013-02-003: Processes Spawning cmd.exe”. The accompanying analytic is \n```SQL\nprocess = search Process:Create\ncmd = filter process where (exe == \"cmd.exe\")\noutput cmd\n```\nprocess and exe are elements of the CAR data model.\n\nThe analytic returns a list of the processes spawned by the CMD shell.  A mapping of this analytic to the DNIF SIEM [https://www.dnif.it/en/] is show as \n```SQL\n_fetch * from event where $LogName=WINDOWS-SYSMON AND $EventID=1 AND $Process=regex(.*cmd\\.exe.*)i limit 100\n```\n\nData Model: A data model provides a set of defined entity types to represent and reason about the data to be collected and processed during the hunt i.e. the data model relates “ the system activities one wishes to capture to the key data (fields, values, attributes) needed from the sensors” \n\nMITRE user the Cyber Analytics Repository (CAR) data model [6] to model the system activity and data – see for example Figure 6(derived from [6]) in which a subset of this model based around the process object is shown. The model describes the relationship between the process and other object e.g. a process can create a file which is the loaded_as a module and launched_as a process. The CAR defines the action and attributes of the entities see Table 1 for the definition of the file object – refer to [6] for a complete description of the data.\n![Figure6](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure6.png)\n\n![Table2](https://github.com/XiLan-ashley/threat_hunting/raw/main/table2.PNG)\n\n### MITRE TH Process\nThe MITRE TTP threat hunting process is outlined in Figure 6 below. A detailed explanation id give in [1].\n![Figure7](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure7.png)\nThe steps on the left side of the V can be mapped to the SHOW ‘Prepare’ phase while the remaining four steps are mapped to the SHOW ‘Conduct’ phase.\n\n\n---\n\n## Annex 2: Commonly Observed TTPs\nThe purpose of this annex is to provide an understanding of the most common Tactics, Techniques, and Procedures (TTPs) employed by attackers, as highlighted in the key findings from the M-Trends 2023 and 2024 reports, as well as DBIR 2023 and 2024 reports. Understanding these TTPs is important to enable organizations to detect and quickly mitigate potential threats.\n\nBased on industry trends (e.g., **M-Trends 2023/2024 Reports**), commonly observed TTPs include:\nThis chapter is structured into several sections, each focusing on different aspects of the TTPs reported in the reports above:\n\n   1.Reports Overview: This section provides a summary of the four reports—M-Trends 2023, M-Trends 2024, DBIR 2023, and DBIR 2024. It outlies the context of these reports in understanding the current threat landscape.\n   2.Top 10 Techniques: we enumerate and discuss the top 10 most observed TTPs from the M-Trends reports of 2023 and 2024.\n   3.TTP Category: This section categorizes the top two TTPs for each phase of the Mandiant Targeted Attack Lifecycle as outlined in the M-Trends 2024 report. Also, we explore the ATT&CK techniques related to the attack categories discussed in the DBIR 2024 report.  \n\n### Reports Overview\nThe Data Breach Investigations Report (DBIR) and M-Trends reports serve distinct but complementary purposes with each providing insights tailored to different audiences.\nThe DBIR reports, produced annually, are designed to provide a broad analysis of data breaches across various industries. Their primary purpose is to help organizations understand the patterns and trends in cyber incidents, enabling them to better anticipate and defend against potential threats. The 2023 and 2024 editions of the DBIR offer a detailed exploration of the evolving landscape of cyber threats and data breaches. Both reports utilize the VERIS (Vocabulary for Event Recording and Incident Sharing) framework, which categorizes incidents by the actors involved, the methods used, and the assets targeted. In the 2023 report, there is a clear emphasis on the role of external actors, predominantly financially motivated criminals, in executing data breaches. The report goes through common attack patterns such as system intrusion, social engineering, and basic web application attacks, providing a statistical overview of how these threats have manifested across various industries. \nThe 2024 DBIR builds on these insights, offering updated statistics and highlighting emerging threats. This report pays attention to the growing complexity of attack vectors, such as adversary-in-the-middle techniques that bypass multi-factor authentication (MFA). The 2024 edition also reflects on how the cybersecurity landscape has evolved, noting that while many of the same attack patterns persist, the methods employed by attackers are becoming increasingly advanced, necessitating a more robust approach to defense.\n\nIn contrast, the M-Trends reports from Mandiant are more specialized, focusing on advanced persistent threats (APTs) and the activities of attackers. The purpose of these reports is to provide in-depth analysis of the TTPs used by these adversaries. The 2023 M-Trends report highlights campaigns by groups like APT29, which have targeted both government and private sector organizations using advanced tactics, including phishing and the deployment of malware. Additionally, the report provides detailed mappings of the MITRE ATT&CK Techniques to the Mandiant Targeted Attack Lifecycle (see Table 5 below), offering organizations a clear framework to understand and defend against the specific TTPs used by these adversaries. This integration helps security professionals align their defenses with known threat behaviors, enhancing their ability to detect, respond to, and mitigate targeted attacks effectively.\nThe 2024 M-Trends report continues this analysis, documenting how attackers are increasingly bypassing traditional defenses, including MFA, through techniques such as session token theft and QR code phishing. This report not only details the threats but also offers mitigation strategies, emphasizing the need for organizations to stay ahead of these evolving tactics by adopting advanced detection and defense mechanisms.\nTogether, these four reports paint a picture of the cybersecurity landscape over two years. The DBIR reports offer broad insights into data breaches across industries, while the M-Trends reports provide a deeper dive into the strategies and techniques employed by most attackers. Both sets of reports underscore the importance of understanding and adapting to the ever-changing tactics used by cybercriminals, as well as the need for organizations to continuously evolve their defenses to keep pace with these threats.\n\n\n\n### Top 10 Techniques\nIn both the 2023 and 2024 M-Trends reports, metrics are provided around the most observed techniques used by adversaries. However, the DBIR reports do not include a similar summary of frequently used TTPs. As a result, our focus in this chapter is on the insights provided by the M-Trends reports, highlighting the most prevalent techniques and sub-techniques utilized by adversaries as identified by Mandiant's analysis.\n![Table3](https://github.com/XiLan-ashley/threat_hunting/raw/main/table3.PNG)\n![Table4](https://github.com/XiLan-ashley/threat_hunting/raw/main/table4.PNG)\nTable 3 and Table 4 show that adversaries frequently leveraged a command or scripting interpreter (T1059) in 50.9% of cases, with one-third of those intrusions involving the use of PowerShell (T1059.001). Mandiant's analysis also reveals the continued frequent use of web protocols (T1071.001) and Remote Desktop (T1021.001) across intrusions, suggesting that adversaries heavily rely on the organization's existing technologies to carry out their operations. These sub-techniques have consistently ranked in the top five over the past three years. This trend could indicate that detection capabilities for these techniques have improved, leading organizations to prioritize other evidence sources to capture additional techniques.\n\n![Table5](https://github.com/XiLan-ashley/threat_hunting/raw/main/table5.PNG)\n![Table6](https://github.com/XiLan-ashley/threat_hunting/raw/main/table6.PNG)\n\nIn these tables, the techniques used by attackers in 2023, as detailed in the M-Trends 2024 report, remain consistent with those observed in 2022, as shown in the M-Trends 2023 report. Tables 3 and 4 demonstrate that the top 10 most frequently seen techniques have shown little variance over the past several years. In more than half of the investigations, Mandiant noted the use of a command or scripting interpreter (T1059) by attackers. A difference in the 2023 dataset is the inclusion of System Owner or User Discovery (T1033) and the exploitation of public-facing applications (T1190) among the top 10 observed techniques. These additions correlate with the rise in ransomware-related intrusions and the increase in mass exploitation campaigns observed in 2023.  \nIt's unsurprising that the top five observed sub-techniques are PowerShell (T1059.001), Web Protocols (T1071.001), Remote Desktop Protocol (T1021.001), Service Execution (T1569.002), and File Deletion (T1070.004).  Attackers likely favor these sub-techniques because they exploit readily available tools within a system, making them easy to abuse. Their proven success in compromising systems, coupled with their ability to sometimes evade security measures, makes them a highly effective part of an attacker’s toolkit. This persistent trend highlights the standard tactics employed by attackers to achieve their objectives. As such, organizations must prioritize detecting these sub-techniques if they have not already done so.\n\n\n### TTP Category\nMandiant provides techniques related to Mandiant’s Targeted Attack Lifecycle, which outlines the predictable sequence of events that cyber attackers use to carry out their attacks. To highlight the most impactful tactics, we have selected the top two techniques from each phase of the lifecycle, as shown in Table 5. This selection provides a detailed view of the most observed methods used by adversaries, thereby helping to understand into their operational patterns.\n![Table7](https://github.com/XiLan-ashley/threat_hunting/raw/main/table7.PNG)\n\nIn both the DBIR 2023 and 2024 reports, Verizon provided relevant ATT&CK techniques based on three types of attacks, as defined in DBIR,  which remained consistent across both years. These are:\n   - **Basic Web Application Attack**s,   where threat actors continue to exploit assets with default, simplistic, and easily guessable credentials by brute forcing them, purchasing them, or reusing credentials from previous breaches. \n   - **Social Engineering**, where pretexting remains the leading cause of cybersecurity incidents, with actors targeting users through existing email chains and context. The prevalence of extortion also saw a dramatic increase, largely due to the large-scale MOVEit incident. \n  - **System Intrusion**, where, despite shifts in tactics leveraged by attackers, the overall impact of these actors continues to affect a majority of industries and organizations of all sizes. \n\nTable 6 shows the specific ATT&CK techniques related to these attack types as outlined in the DBIR 2024 report.\n\n\n![Table8](https://github.com/XiLan-ashley/threat_hunting/raw/main/table8-1.PNG)\n![Table8](https://github.com/XiLan-ashley/threat_hunting/raw/main/table8-2.PNG)\n![Table8](https://github.com/XiLan-ashley/threat_hunting/raw/main/table8-3.PNG)\n\n---\n\n## References\n\n1. [MITRE ATT&CK Framework for TTP Hunting](https://www.mitre.org/sites/default/files/2021-11/prs-19-3892-ttp-based-hunting.pdf)\n2. [Sqrrl Threat Hunting Framework](https://www.threathunting.net/files/framework-for-threat-hunting-whitepaper.pdf)\n3. [B. Nour, M. Pourzandi, and M. Debbabi](“A Survey on Threat Hunting in Enterprise Networks,” IEEE Commun. Surv. Tutor., vol. 25, no. 4, pp. 2299–2324, 2023, doi: 10.1109/COMST.2023.3299519.)\n4. [PEAK Framework](“The PEAK Threat Hunting Framework,” Splunk Inc. Accessed: Nov. 06, 2024. [Online]. Available: https://www.splunk.com/en_us/blog/security/peak-threat-hunting-framework.htm)\n5. [TaHiTI Threat Hunting Methodology](https://www.betaalvereniging.nl/wp-content/uploads/TaHiTI-Threat-Hunting-Methodology-whitepaper.pdf)\n6. [MITRE](MITRE, “CAR Data Model.” [Online]. Available: https://car.mitre.org/data_model/)\n\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.048 ms","outputType":"MARKDOWN","result":"# SHOW – Supporting Threat Hunting with OpenSearch and Wazuh\n\n**Authors**: Brian Lee, Xi Lan\n\n---\n\n## Table of Contents\n1. [Introduction](#introduction)\n2. [Threat Hunting Overview](#threat-hunting-overview)\n   - [What is Threat Hunting?](#what-is-threat-hunting)\n   - [Threat Hunting Process](#threat-hunting-process)\n3. [Threat Hunting Frameworks](#threat-hunting-frameworks)\n4. [Threat Hunting Types](#threat-hunting-types)\n5. [Threat Hunting Process](#threat-hunting-process)\n6. [The SHOW Process](#the-show-process)\n   - [Prepare for the hunt](#prepare-for-the-hunt)\n   - [Conduct the Hunt](#conduct-the-hunt)\n   - [Finish the Hunt](#finish-the-hunt)\n7. [Use of Wazuh and OpenSearch Tools and Visualisations](#use-of-wazuh-and-opensearch-tools-and-visualisations)\n8. [Annex 1: MITRE TTP Framework](#annex-1--mitre-ttp-framwork)\n9. [Annex 2 – Commonly Observed TTPs](#annex-2--commonly-observed-ttps)\n10. [References](#references)\n\n---\n\n## Introduction\n\nThis work describes a methodology (SHOW) to support threat hunting in OpenSearch and Wazuh. \nIt situates this support in the context of a specific threat hunting framework – the ‘TTP Based Hunting‘  [1]\nfrom MITRE based on the ATT&CK framework. SHOW is designed to follow the TTP-based process outlined by MITRE - the reason for this is quite simply to avoid reinventing the wheel. As will be seen from the description below elements of SHOW relate to other frameworks also and the intention is to expand SHOW, over time, to incorporate other elements of those frameworks. \nThreat hunting is a key activity to support the overall security defense processes for organisations and enterprises. It is an ad-hoc activity as opposed to continuous event monitoring and searches for any malicious activities that might have escaped the other monitoring and threat detection processes. An overview of  threat hunting and the most common frameworks is given below. This is followed by a more in depth description of the MITRE threat hunting  process, which parts of that process SHOW supports as well as a description of the SHOW implementation components.\nThe report also contains an annex outlining the most exploited TTPs over the last few years to provide SHOW users with a starting point for their hunting.\n\n\n---\n## Threat Hunting Overview \n\n## What is Threat Hunting?\n\nSimply put, threat hunting is a proactive activity to look for signs of attacks or malicious activity that may have been missed by other detection processes. It entails not only detecting but also understanding the attack consequences and removing/isolating the threat.\nThreat hunting can be triggered for several reasons e.g. by observing Indicators of Compromise (IoC) or other evidence that might lead to the identification of new threats or it could be motivated by appearance of new attacks in the wider business environment[3]. Alternatively, threat hunting can be used to explore new approaches to detect malicious behavior that can help improve cyber defences, which may be more valuable over alonger time frame than the immediate discovery of threat.\n\n\n---\n## Threat Hunting Process \nThreat hunting follows a well-known  process cycle derived from the Sqrrl threat hunting framework [2], as shown in Figure 1.\n![Figure 1](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure1.png)\n1.Create a hypothesis: At a general level hypothesis is an assumption/supposition or question about a particular attack or some of its behaviours that might be present on the hunters network. At a more detailed level, a hypothesis may be narrowed to a single behaviour or TTP.  The information leading to formation of a hypothesis arises from different sources following the motivation to do the threat hunt as outlined above.  \n\n2.Investigate with Tools & Techniques: In this step the hunter seeks to check the validity of the hypothesis using the tools (logs etc.) available. Typically this entails mapping the attack behaviour(s) to querie(s) over the various data source tools. \n\n3.Uncover new patterns and TTP’s: The hunt should return a number of events events (“hits”) for the related queries. These may or may not support the hypothesis but are likely to create new pathways and raise new TTPs to be investigated.\n\n4.Inform and enrich analytics: In this step the hunter extends the scope or direction of the hunt and generates new queries etc. to follow up on the information thrown up by the previous steps.\n\n\n---\n## Threat Hunting Frameworks\n\nThe process outlined in Figure 1describes the execution of an actual hunt. There are however other steps , that precede and follow the execution step, in order to establish an comprehensive and effective threat hunting practice. A number of threat hunting  frameworks have arisen over the years to meet this need. A threat hunting framework is “ a system of repeatable processes designed to make your threat hunting more effective and  efficient” [3]. Some of the more well know frameworks include:\n\n1. **Sqrrl Framework**: This was one of the earliest and most influential frameworks and laid down the basic threat hunting principles that still recur today. Sqrrl incorporates other artefact including a Threat Hunting Maturity Model [2].\n2. **PEAK Framework (Prepare, Execute, Act, Knowledge)**: The PEAK  (Prepare, Execute, Act, Knowledge) framework [4] is a very recent addition, from Splunk, and has been designed to overcome some of the limitations in Sqrrl that became apparent over time. It incorporates the Sqrrl hypothesis-based hunt types and add  two new threat hunt types – baseline and model-assisted (detailed below). The process steps are common to all three hunt types but their implementation may naturally vary. The steps, in more detail, are:\n   - Prepare: Hunters need to decide the focus, scope and outcomes of a threat hunt including the likely data sources and competences needed and need to prepare a plan for the hunt activities.\n   - Execute: This step executes the hunt plan and refines and adapts as needed according to the returned results.\n   - Act : This step documents the findings and shares the results with other appropriate colleagues. It also identifies and carries out the any updates to the automated threat detection and defense systems\n   - Knowledge: Knowledge is a broad term that include the human competence and expertise as well as accumulated lessons, data and analytics  from previous threat hunts and from the present threat hunt.\n\n3. **TaHiTI**: Targeted Hunting integrating Threat Intelligence [5] - As the name implies incorporating cyber  threat intelligence (CTI) to provide a starting point for the hunt and to provide context for the hunt. It uses hypotheses driven testing and introduces a new type of hunt – the unstructured threat hunt. It has three phases:\n   - Initiate: Planning and preparation of the hunt.\n   - Hunt: Execution of the hunt.\n   - Finalise: Documentation and handover of the hunt.\n\n4. **TTP-based Hunting**: Although TTP are used in all hunting, Mitre has defined a  hypothesis-based hunting process [1] focused specifically on the well-known ATT&CK model i.e. “ hunt operations collect and utilize timely, actionable information on the techniques adversaries must employ across all systems of interest” – actionable being the key word here.  The model is explored in greater detail in Annex 1.\n\nIn addition to the above a general architecture for threat hunting is defined by Nour et al. [2]. It consists of three components that correspond roughly to the phases of the various frameworks above:\n   - **Input Sources**: They identify three types of input data \n       - CTI – CVE’s, information on ongoing attack APT campaigns, ATT&CK\n       - Telemetry: logs, alerts (SIEM etc.) \n       - System Representation: network and computer system topology \n   - **Threat Hunting System**: It contains two subsystems:\n       - Data Knowledge Module: this refers to the data collection, processing and storage tolls and databases. It may include not just event logs but also topology representation and other tools.\n       - Analysis Module: the ‘execution engine’ of the hunt – essentially executes the steps shown in Figure 1 above. It in turn consists of three sub modules These are: Analyser -generates hypotheses  based on input from data knowledge  module;  Tester -investigating and analysing each hypothesis using data visualization, search and similar techniques; Evaluator -identifies malicious activities and attack patterns.\n   - **Security Outputs**:This consists of two sub-parts\n       - Responses: design and implementation of automated analytics and responses\n       - Reporting: attack related information that could enhance overall security posture and future threat hunting.\n\n\n\n\n\n---\n\n## Threat Hunting Types\nA number of different threat hunting types defined by the various frameworks are summarized here. Hunt types reflect differing technologies and purposes in executing a hunt. \nThreat hunting can be categorized into several types:\n\n- **Hypothesis-based Hunting**: this is the original type and is used by all frameworks. As described above this approach is based on an assumption/supposition/question about a particular attack or some of its behaviours that might be present on the hunters network.\n- **Baseline-based Hunting**: this approach is proposed by PEAK. It entails establishing a baseline or profile of normal activity and then searching for deviations form that baseline. In this regard it can be seen as a form of anomaly detection. The hunter establishes a data-dictionary of the data for the entity in question and define statistics  (average/median value, top-k values, cardinality of field) to charaterise ‘normal’. Techniques such as Least Frequency of Occurrence (“Stacking”) or ‘z-scores’ can be used to search for outliers.- See for “Visualisations and Tools” chapter  more details.\n- **Model-based Hunting**: this applies machine learning models to detect aberrant or suspicious behaviour. Algorithms for classification, clustering or time series analysis could be used. It should be pointed out that while these methods are used for threat detection their use here is on archived data and so can be thought of as expanding the original threat hunting process scope beyond hypothesis base through the use of machine learning – this can be said also for the baseline type.\n- **Unstructured Hunting**: -proposed by TAHiTI .  This type of hunting is initiated spontaneously based on the data (IoC, TTP) observed by an analyst in the course of their work.  It is considered unstructured because hunting does not start with a hypothesis and does not follow a predetermined path.\n- **Structured Hunting**: Opposite to unstructured, i.e. hypothesis based hunting that follows a planned  approach using a framework- source TAHiTI[5].\n- **Situational: **: Structured or unstructured hunting based on analysis generated from internal reports – source Nour et al[2].\n---\n\n## Threat Hunting Process\n\nThreat hunting typically follows a continuous cycle, which can be summarized as:\n\n1. **Create a Hypothesis**:\n   - Formulate a question or assumption about a specific attack or behavior.\n2. **Investigate Using Tools and Techniques**:\n   - Validate hypotheses using logs, queries, OpenSearch dashboards, and other tools.\n3. **Uncover New Patterns**:\n   - Discover additional pathways, connections, and emerging TTPs.\n4. **Inform and Enrich Analytics**:\n   - Refine queries, enrich data, and expand the scope of the hunt.\n\n---\n\n## The SHOW Process\n\nThe process is described below and outlined in Figure 2. Individual hunt progress, according to this process, should be documented in OpenSearch notebook(s).\n![Figure 2](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure2.png)\n1. **Prepare for the Hunt**:\n\n   ***Define the hunt objectives***: \n      \nMITRE refers to this phase as “developing a malicious activity model”. The scope of the phase will vary depending on the particular focus and trigger mechanism.\n   - Select activity:\n     \n     Decide what type of threat activity or focus the hunt will address at a general level. This may be based different trigger points such as recent incidents, an overview of the current threat landscape, received threat intelligence .Examples include:\n      - TTP’s used by a particular adversary \n      - Particular attack campaign \n      - Attack lifecycle phase  \n      - Data exfiltration \n     General level hypothesis may be formulated at this point e.g. ”Attackers may be exfiltrating data from our system” or “How secure is our system against credential stealing?’.\n   - Research and Refine\n     Research the identified focus to gather as much information as you can on the threat  to help you understand how to shape your hunt approach. Refer to vendor threat intelligent reports, threat intelligence,  security new websites, libraries etc. Use Annex 2 as a starting point. \n\n   ***Define the hunt hypothesis***:\n\nThe previous steps have generated a list of TTP’s that will be used in the hunt. In this step we generate a detailed hypotheses for one or more of these TTP’s .  The hypothesis should be formulated so that it can be tested i.e. so it can be verified, or not as the case may be,  based on the evidence that can be collected from the computer system. It should therefore be clear, concise and precise enough.\nFor example  “An attacker may be exfiltrating data using HTTPS tunneling” or “Attackers may be using Kerberoasting for credential stealing”. Refine further if necessary to address e.g. specific enterprise missions or particular types of data.\nFor each hypothesis, define an  analytic  that will identify the behaviour noted in the TTP. An analytic takes the form of one or more queries to the Opensearch indexes to retrieve the required data. Queries may be formulated using either SQL or PPL.\nMITRE recommends to define an the analytic in abstract form i.e. in independent of any particular tool or underlying data source and gives as an example to describe an analytic for ‘process creation’ rather than formulating in OS specific (Linux or Windows) form. This can be useful in system where there are different sensors. For SHOW it is sufficient to use Opensearch queries directly. Worked examples , as Notebooks, showing hypothesis and their related analytics are provided.\n\n   ***Define the hunt scope***:\n\n   - Determine Data Requirements:\n\nThis step entails defining the required data sources.\nThe hypothesis analytic will define the types of data and data sources need to collect for the hunt. This will identify also the types of data sensor e.g. Host Intrusion Detection System (HIDS) or Network IDS or the specific types of log that are needed. In some cases it might require the addition of new sensors or reconfiguring or adding data collection agents (Wazuh agent or Syslog) to collect new logs or add new sources. This will depend also on which parts of the system are to be examined.\nAnother factor to consider is the requirements for contextual information i.e. information on assets or other artefacts that may be related to the behaviour and that support the analysis and understanding of the behaviour. MITRE notes that sensors focused on automated detection may not give much contextual information and some combination of endpoint selection and response (EDR) tools, application logs and system event logs may be needed. There is of course a trade-off between the amount of contextual information and the volume of such information i.e. the greater the level of context detail (e.g. HIDS alerts vs API/Syscall logging) the greater the volume of data to be collected and analysed.\nAs MITRE notes  “A good data model for hunting will relate what objects and actions an analyst wishes to capture to the key data (fields, values, attributes) needed from the environment’s sensors”. MITRE defines the Cyber Analytic Repository (CAR) model for this purpose – see Appendix 1 for more information on CAR. SHOW recommends also the use of the CAR data model for this step.\n\n   - Determine the extent of the Analysis Space:\n     \nEvery event that occurs in a computer system can be represented in three dimensions:\n\n        - Time – seconds, minutes, ... years\n        - Network assets – Windows hosts, Linux hosts, router, switches, etc. \n        - Behaviour - TTPs\n\nThese three form a 3D space which (after MITRE) we term the Analysis Space – see Figure 3 depicts the 3D analysis space (based on [1]) . It is important to determine the appropriate combination of these dimensions in order to achieve an effective hunt.  A very large analysis space will require a large amount of data and subsequent analysis while a too small analysis space may not yield any interesting or useful results.\n![Figure3](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure3.png)\n\n2. **Conduct the Hunt**:\n   \n   ***Retrieve Data***: \n\n   - Collect the data : Previous steps have defined the data types and data sources and extent of the analysis space. In this step the data is fetched from the sources to a central collection point i.e. SIEM, data lakehouse etc. In many cases the required data may already have been collected. \nIf new or extra sensors are required then the necessary configuration of agents must be carried out in this step. Wazuh uses Wazuh, Syslog, or other (Vector, Fluentbit etc.) agents to collect data from end points. For new data sources it may be required to write Wazuh decoders and alerting rules to ingest the data and generate alerts. In some cases it may also be appropriate to assign TTP behaviour clarification for new behaviours. Refer to the Wazuh documentation.\n\n   - Tune the analysis space: \n\nAlthough an initial analysis space had been defined it may be necessary to refine or reshape this based on the actual data collected. SHOW provide visualization support to help with through the use of a heat map which enables the visualization of the three dimension of the analysis space e.g. see Figure 4 below.\nFor example if the x and y axes represent time and network assets, respectively, then the colour of each square can indicate the number of behaviours observed for the network assets for that period. Any obvious outliers can help to focus the hunt. Another example might be to switch the network assets and behaviour axes can detail the occurrence of certain behaviour through the network which might reveal the overall flow of an attack. MITRE provides a more detailed discussion on this topic with some interesting ideas. See especially section 2.4.3.1.\n![Figure4](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure4.png)\n   ***Evaluate the data***:\n\n   - Analyse the Data\n\nAnalysing involves examining and interpreting collected information to discover patterns, relationships, or trends. The goal is to extract meaningful insights that can inform decision-making or improve understanding of the hunt hypothesis.\nIt typically includes organizing the data, applying statistical methods, and drawing conclusions based on the findings. There are many different analysis techniques that are used for hypothesis threat hunting. The techniques below are taken from the TaHITi framework [5]:\n     - Visualisation – exploring relationships between data items visually\n     - Clustering -  Clustering is a statistical method used to group similar data points based on shared characteristics from a larger dataset. It is often applied in various fields, including for outlier detection, because it helps uncover patterns or behaviors that deviate from the norm, such as identifying an unusual number of occurrences of a typically common event. Hunters can utilize clustering to effectively identify aggregate behaviors in data analysis.\n     - Z-value test- a z test is a simple model to estimate outliers. It calculates the number of standard deviations by which the data deviates from the mean. Very often a value of z > 3 is used to indicate an anomalous data point. \n     - Stack Counting -  Stacking entails counting the occurrences of specific values and focusing on identifying and analyzing any outliers within those results-normally based on ‘least frequency of occurrence’.\n     - Grouping – This involves taking distinct artifacts and determining when multiple items from the set appear together according to specific criteria. The key distinction between grouping and clustering is that grouping works with a predefined set of items that are already deemed significant, rather than identifying patterns or similarities from a broader dataset. \n     - Querying -  searching for specific data in the database.\nThere are many other forms of statistical and machine learning analysis that may be appropriate for different situations.\n\n   - Gather Contextual Information\n\nContextual information is any supplementary information related to the collected data that can aid the analysis of the hypothesis. Contextual information can help establish links between other events and artefacts. Some examples of contextual information are:\n     - Related processes – identifying other relevant processes or process chains can be of great value in the hunt to verify the hypothesis\n     - Network Information – can establish links to other network entities involved and help determine the bigger picture.\n     - System files\n     - User information\n     - Host Security posture  e.g. vulnerabilities etc.\nThe MITRE document has useful guidelines for this activity.\n\n   - Verify the Hypothesis\n\nThis step determines if the hypothesis/goal of the hunt was achieved or not. There are three possible outcomes:\n     - Hypothesis proven - – corroborating evidence has been found to validate the hypothesis. Further action may be necessary such as incident reporting or escalating the finding to another team e.g. to  share findings as threat intelligence  or write detector analytics for sensors\n     - Hypothesis is not proven - no evidence was found to validate the hypothesis.\n     - Inconclusive – There may be a variety of reasons for this – not enough data or incorrect data or the extent of the analysis space is incorrect or misconceived hypothesis.\n\n   ***Refine/Repeat:***\n\nIf the findings from the hunt are inconclusive or interim results determine the current hypothesis should be amended or replaced then the team may repeat previous steps. Otherwise the team moves to finish the hunt.\n\n3. **Finish the Hunt**:\n\n   ***Report findings***\n\n   - Document the findings:\n\nThe results of the hunt should be documented, as a notebook This should include the purpose, approach and conclusion from the hunt, any lesson learned or new information that can inform or improve security posture and practice.\n\n   - Communicate the findings:\n\nThe findings from the hunt are shared with other departments and interested parties. The actual distribution list may vary but all parties who can benefit from the findings should be included.\n\n   ***Preserve the Hunt***:\n\n   - Archive hunt details: \nThe details of the hunt are stored in case the hunt needs to be revisited in the future. This should include the data, tools and techniques used as well as any external information sources etc. Reports may be generated by the OpenSearch reporting activity.\n\n   - Add to hunt backlog:\nSome teams maintain a backlog of potential future hunts. If so then any ideas for new hunts should be added  here.\n\n---\n\n## Use of Wazuh and OpenSearch Tools and Visualisations\nWazuh and OpenSearch provide several tool and visualisation support to support the threat hunting process. A summary of the main supports are given here and a more in depth description including worked examples is provided in a OpenSearch Notebook.\n### Visualizations\nOpenSearch Dashboards is used in both Wazuh and OpenSearch for visualiations (equivalent to Kibana in Elasticsearch). It provides several of the predefined visualisations and users may also create custom visualisations  - see Figure 4 below, which shows a range of the type of visualisations that OpenSearch offers. \nFigure 4 shows an example of a heatmap to visualize the analysis space depicted in Figure x above. It shows the distribution of TTP over time with the coloured cells indicating the number of machines impacted. Several other examples are shown in the example’s notebooks accompanying this process description.\nIn addition to the capability to define own visualisations, Wazuh has a number of predefined dashboards including “Threat Hunting” and  “MITRE ATT&CK” which provide much useful information.\n![Figure4](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure4.png)\n![Figure5](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure5.png)\n\n###Search Techniques\nOpenSearch has several ways to search for data including the following (not all methods are described) :\n- **SQL**:  Full SQL syntax support for querying, aggregations, and joins and can be integrated with dashboards for visualization.\n- **PPL (Piped Processing Language)**: Executes queries step-by-step using piped syntax (|). Moreover, it handles filtering, aggregation, and transformations in a single query. It is ideal for log analytics and ad-hoc querying. PPL is the default language used in SHOW hunting notebooks.\n- **Query DSL**: OpenSearch provides a search language called query domain-specific language (DSL) that you can use to search your data. Query DSL is a flexible language with a JSON interface. It enables creation of complex queries and can be used structure keyword and full text queries as well as geographic queries.\n- **Text search**: OpenSearch support both keyword search (traditional search based on exact or partial matches of terms in text field)  and full text based search (Advanced text search using relevance-based ranking (TF-IDF, BM25).\n- **Vector/Semantic search**: Indexes and searches high-dimensional vectors using deep learning techniques. This enables semantic search for similar meanings (e.g., “laptop” matches “notebook”) and is useful for AI/ML-driven applications like recommendation systems and image search.\n- **Conversational search**: allows you to ask questions in natural language and refine the answers by asking follow-up questions. Thus, the conversation becomes a dialog between you and a large language model (LLM). Conversational search is a recent feature in OpenSearch.\n- **Neural search** transforms text into vectors and facilitates vector search both at ingestion time and at search time. During ingestion, neural search transforms document text into vector embeddings and indexes both the text and its vector embeddings in a vector index. When you use a neural query during search, neural search converts the query text into vector embeddings, uses vector search to compare the query and document embeddings, and returns the closest results.\nThe reader is referred to  OpenSearch documentation for more information on all query types.\n### Visualization Tools:\n- OpenSearch **dashboards**, heatmaps, and graphs.\n\n### Tools for Analysis\nIn addition to the visualisation capabilities referred to above OpenSearch provides other features which can be used for data analysis. In the “Analyse the Data” some analysis  techniques were described\nZ-test – a z score can be calculated in OpenSearch using SQL as in the example below:\n\n```PPL\nsource=my_logs\n| stats avg(response_time) AS mean_response, stddev(response_time) AS stddev_response\n| eval z_score = (response_time - mean_response) / stddev_response\n| where abs(z_score) > 3\n```\n\nGrouping – can be implemented using the PPL stats function and the BY clause e.g.\n```PPL\nsource=wazuh-alert* | stats count(data.win.system.eventID) AS total_event, avg(rule.firedtimes) AS avg_time BY data.win.system.eventID\n```\n\nStacking - can be implemented using the PPL stats function and by sorting in ascending frequency (as below). Descending frequency could also be used. See also the Visualisation examples notebook.\n```PPL\nsource=wazuh-alert*\n| stats count(data.win.system.eventID) AS frequency BY data.win.system.eventID\n| sort + frequency\n```\nClustering – clustering, as noted above, is a statistical method to group similar items. It is not so easily done, on first sight at least, using simple querying as it involves the use of a statistical or machine learning algorithm. OpenSearch provides a number of ways to enable clustering including K-means and Random Cut Forest (RCF) which are provided through the ML Plugin -RCF is discussed in detail below in Anomaly Detection. K-means is an unsupervised learning algorithm that partitions data points into k clusters – see the OpenSearch documentation for a fuller description of its use. It can also be used as part of a PPL query as in the example \n```PPL\nsource=iris_data | fields sepal_length_in_cm, sepal_width_in_cm, petal_length_in_cm, petal_width_in_cm | kmeans centroids=3\n```\nbelow to group flowers in the iris dataset.  PPL also supports the use of clustering using RCF  as in the below example which detects anomalies in the ridership data. \n```PPL\nsource=nyc_taxi | fields value, timestamp | AD time_field=’timestamp’ | where value=10844.0\n```\n\n***Anomaly Detection***\nAnomaly detection can help threat hunting by detecting deviations from baseline i.e. normal behaviour. There many approaches to detect anomalies depending on the domain, data characteristics (e.g. time series vs random data occurrences..) etc. Anomaly detection in OpenSearch is directly supported by the Anomaly Detector Plugin as well as the opensearch-py  Python libraries (see below).  \nThe Anomaly Detection plugin supports the use of the Random Cut Forest (RCF) algorithm for anomaly detection. RCF is optimized for detecting anomaly detection in streaming or time-series data. .Based on the input, the plugin uses two types of RCF algorithms: fixed in time RCF for processing time-series data and batch RCF for processing non-time-series data. It can also be used in this way for collecting cybersecurity logs. RCF works by building decision trees to isolate individual points of data. Data is which is denser (clustered) will take more cuts to isolate and hence will be deeper in the tree. RCF gauges anomalies as (the inverse of)  the ratio between the  depth of a point in the tree and the depth of a random point in the tree with points being marked anomalous above some threshold chosen by the user. In fact RCF builds a number of trees and averages the measurements across the trees – it is therefore an ensemble method. RCF is an unsupervised learning approach and adapts to any changes in data distribution etc. and can be considered a form of online learning.\n\nOpenSearch allows up to 5 features to be included as the base for the algorithm. Features must be aggregated through the use of functions such as sum(), count(), min(), max() etc. This both minimizes noise effects and also enables the detection of particular data patterns. For example to detect anomalous peaks/spikes in network traffic the max() function would be used while to detect variation in user logins in a system the count() function could be used.\n\n***Machine Learning (ML) Commons Plugin***\nThe ML plugin introduces a Machine Learning library inside the OpenSearch cluster. The major functionalities in this solution include:\n   - **Unified Client Interfaces**: clients can use common interfaces for training and inference tasks, and then follow the algorithm interface to give right input parameters, such as input data, hyperparameters. A client library will be built for easy use.\n   - **ML Plugin**: ML plugin will help to initiate the ML nodes, and choose the right nodes and allocate the resources for each request, and manage machine learning tasks with monitoring and failure handing supports, and store the model results; it will be the bridge for the communication between OpenSearch process and ML engine.\n   - **ML Engine**: This engine will be the host for ML algorithms. Java based machine learning algorithms will be supported in the first release.\nUser can use a pretrained model provided by OpenSearch, upload their own model to the OpenSearch cluster, or connect to a foundation model hosted on an external platform. \nML function can provide many types of analytic support for threat hunting including anomaly detection, topology models to learn the representation or structure of the connections and relationships between elements in a system e.g. to generate systems provenance data models showing causal links between process, files, registry and other system entities. \nAs well as k-means and RCF the plugin has native support for linear and logistic regression and localisation (finds subset-level information for aggregate data (for example, aggregated over time) that demonstrates the activity of interest, such as spikes, drops, changes, or anomalies).\n\n***Opensearch-py***\nThis provides a Pythonic interface to perform operations such as indexing, querying, and managing OpenSearch clusters thereby enabling developers to integrate OpenSearch functionalities into Python applications. It gives full access to AI libraries such as Scikit, Keras etc. enabling the use of numerous algorithms therein. Typical use cases include: \n   - **Search Applications**: Build Python applications with OpenSearch-powered search features.\n   - **Analytics Dashboards**: Integrate with tools like Dash, Flask, or Django to display search and analytics results.\n   - **AI/ML Pipelines**: Use vector search for semantic matching or integrate OpenSearch with ML workflows.\nWhile these AI/ML features provide powerful analytic features they require sometimes considerable work to set up and configure and while they can be regarded as ad-hoc tools to assist hypotheses based hunts they can also form stand-alone hunt methodologies as pointed out by  [1][4]. For that reason , since this version of SHOW is only hypothesis-based, we defer further discussion on these approaches to a later version.\n\n###Mapping to Hunt Phases\n\nThe relationship between the tools above and the hunt steps is shown in Table 1  \n*Table 1 Tool use in the Hunt phases.*\n\n| **Hunt Phase**           | **Visualizations** | **ML** | **Anomaly Detection** | **Search** | **LLM** | **Notebooks (Reporting)** |\n|---------------------------|--------------------|--------|-----------------------|------------|---------|---------------------------|\n| **Define Hunt Objectives**| X                  |        | X                     | X          | X       | X                         |\n| **Determine Hypothesis**  | X                  |        |                       | X          | X       |                           |\n| **Define Scope**          | X                  |        |                       | X          | X       |                           |\n| **Retrieve Data**         |                    |        |                       |            | X       |                           |\n| **Evaluate the Data**     | X                  | X      | X                     |            | X       |                           |\n| **Report**                |                    |        |                       |            |         | X                         |\n| **Preserve Hunt**         |                    |        |                       |            |         | X                         |\n\nLLM is shown as potential area for evaluation in future versions.\n\n\n\n\n\n---\n\n## Annex 1: MITRE TTP Framework\nThe MITRE “TTP-Based Hunting” describes a threat hunting framework based on the use of MITRE ATT&CK based TTP’s that aims to “create a general threat  hunting methodology focused on an identifying adversary behavior,   structured within an adversary model, that does not depend on specific tools or products but rather describes what data is necessary, what types of data should be available from the sensors and how to use that data within the hunt”\nThis annex gives an overview of the MITRE framework – please refer to [1]for a full description.\n\n### Framework Conceptual Building Blocks\nThe framework is hinged around a number of conceptual building blocks:\n\nAdversary: the bad guy i.e. the attacker or attack group\n\nTTP’s – primarily the behaviours and techniques of the ATT&CK model\n\nAdversary model – the ATT&CK matrix or more precisely the set of techniques used by an adversary  and/or  technique pathways through the matrix taken by an adversary\n\nAnalysis Space; A three-dimensional space in which the hunt activities are situated. The dimensions of the space are formed by:\n   - The computing and network environment – what MITRE calls the cyber terrain.\n   - The set of behaviours (TTPs) to be explored\n   - The time frame over which the hunt will be conducted.\nHunters can use tools such as heatmaps to visualize this space with the goal to refine and narrow down the hunt scope.\n\nHypothesis: effectively the behavior and related TTP to hunt.\n\nAbstract Analytic: the generic formulation of the search query to search for the behavior. Abstract here means the query is formulated in a tool independent form. Or as MITRE puts it “analysts should be careful to avoid creating an analytic that is too specific to a particular instantiation of a particular tool”. \n\nIn the MITRE TH framework analytics are often described using the Cyber Analytics Repository (CAR) [https://car.mitre.org/ ] CAR is a collection of analytics framed around the CAR data model (see below also) . An example of a CAR analytic for process creation is  \n“CAR-2013-02-003: Processes Spawning cmd.exe”. The accompanying analytic is \n```SQL\nprocess = search Process:Create\ncmd = filter process where (exe == \"cmd.exe\")\noutput cmd\n```\nprocess and exe are elements of the CAR data model.\n\nThe analytic returns a list of the processes spawned by the CMD shell.  A mapping of this analytic to the DNIF SIEM [https://www.dnif.it/en/] is show as \n```SQL\n_fetch * from event where $LogName=WINDOWS-SYSMON AND $EventID=1 AND $Process=regex(.*cmd\\.exe.*)i limit 100\n```\n\nData Model: A data model provides a set of defined entity types to represent and reason about the data to be collected and processed during the hunt i.e. the data model relates “ the system activities one wishes to capture to the key data (fields, values, attributes) needed from the sensors” \n\nMITRE user the Cyber Analytics Repository (CAR) data model [6] to model the system activity and data – see for example Figure 6(derived from [6]) in which a subset of this model based around the process object is shown. The model describes the relationship between the process and other object e.g. a process can create a file which is the loaded_as a module and launched_as a process. The CAR defines the action and attributes of the entities see Table 1 for the definition of the file object – refer to [6] for a complete description of the data.\n![Figure6](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure6.png)\n\n![Table2](https://github.com/XiLan-ashley/threat_hunting/raw/main/table2.PNG)\n\n### MITRE TH Process\nThe MITRE TTP threat hunting process is outlined in Figure 6 below. A detailed explanation id give in [1].\n![Figure7](https://github.com/XiLan-ashley/threat_hunting/raw/main/figure7.png)\nThe steps on the left side of the V can be mapped to the SHOW ‘Prepare’ phase while the remaining four steps are mapped to the SHOW ‘Conduct’ phase.\n\n\n---\n\n## Annex 2: Commonly Observed TTPs\nThe purpose of this annex is to provide an understanding of the most common Tactics, Techniques, and Procedures (TTPs) employed by attackers, as highlighted in the key findings from the M-Trends 2023 and 2024 reports, as well as DBIR 2023 and 2024 reports. Understanding these TTPs is important to enable organizations to detect and quickly mitigate potential threats.\n\nBased on industry trends (e.g., **M-Trends 2023/2024 Reports**), commonly observed TTPs include:\nThis chapter is structured into several sections, each focusing on different aspects of the TTPs reported in the reports above:\n\n   1.Reports Overview: This section provides a summary of the four reports—M-Trends 2023, M-Trends 2024, DBIR 2023, and DBIR 2024. It outlies the context of these reports in understanding the current threat landscape.\n   2.Top 10 Techniques: we enumerate and discuss the top 10 most observed TTPs from the M-Trends reports of 2023 and 2024.\n   3.TTP Category: This section categorizes the top two TTPs for each phase of the Mandiant Targeted Attack Lifecycle as outlined in the M-Trends 2024 report. Also, we explore the ATT&CK techniques related to the attack categories discussed in the DBIR 2024 report.  \n\n### Reports Overview\nThe Data Breach Investigations Report (DBIR) and M-Trends reports serve distinct but complementary purposes with each providing insights tailored to different audiences.\nThe DBIR reports, produced annually, are designed to provide a broad analysis of data breaches across various industries. Their primary purpose is to help organizations understand the patterns and trends in cyber incidents, enabling them to better anticipate and defend against potential threats. The 2023 and 2024 editions of the DBIR offer a detailed exploration of the evolving landscape of cyber threats and data breaches. Both reports utilize the VERIS (Vocabulary for Event Recording and Incident Sharing) framework, which categorizes incidents by the actors involved, the methods used, and the assets targeted. In the 2023 report, there is a clear emphasis on the role of external actors, predominantly financially motivated criminals, in executing data breaches. The report goes through common attack patterns such as system intrusion, social engineering, and basic web application attacks, providing a statistical overview of how these threats have manifested across various industries. \nThe 2024 DBIR builds on these insights, offering updated statistics and highlighting emerging threats. This report pays attention to the growing complexity of attack vectors, such as adversary-in-the-middle techniques that bypass multi-factor authentication (MFA). The 2024 edition also reflects on how the cybersecurity landscape has evolved, noting that while many of the same attack patterns persist, the methods employed by attackers are becoming increasingly advanced, necessitating a more robust approach to defense.\n\nIn contrast, the M-Trends reports from Mandiant are more specialized, focusing on advanced persistent threats (APTs) and the activities of attackers. The purpose of these reports is to provide in-depth analysis of the TTPs used by these adversaries. The 2023 M-Trends report highlights campaigns by groups like APT29, which have targeted both government and private sector organizations using advanced tactics, including phishing and the deployment of malware. Additionally, the report provides detailed mappings of the MITRE ATT&CK Techniques to the Mandiant Targeted Attack Lifecycle (see Table 5 below), offering organizations a clear framework to understand and defend against the specific TTPs used by these adversaries. This integration helps security professionals align their defenses with known threat behaviors, enhancing their ability to detect, respond to, and mitigate targeted attacks effectively.\nThe 2024 M-Trends report continues this analysis, documenting how attackers are increasingly bypassing traditional defenses, including MFA, through techniques such as session token theft and QR code phishing. This report not only details the threats but also offers mitigation strategies, emphasizing the need for organizations to stay ahead of these evolving tactics by adopting advanced detection and defense mechanisms.\nTogether, these four reports paint a picture of the cybersecurity landscape over two years. The DBIR reports offer broad insights into data breaches across industries, while the M-Trends reports provide a deeper dive into the strategies and techniques employed by most attackers. Both sets of reports underscore the importance of understanding and adapting to the ever-changing tactics used by cybercriminals, as well as the need for organizations to continuously evolve their defenses to keep pace with these threats.\n\n\n\n### Top 10 Techniques\nIn both the 2023 and 2024 M-Trends reports, metrics are provided around the most observed techniques used by adversaries. However, the DBIR reports do not include a similar summary of frequently used TTPs. As a result, our focus in this chapter is on the insights provided by the M-Trends reports, highlighting the most prevalent techniques and sub-techniques utilized by adversaries as identified by Mandiant's analysis.\n![Table3](https://github.com/XiLan-ashley/threat_hunting/raw/main/table3.PNG)\n![Table4](https://github.com/XiLan-ashley/threat_hunting/raw/main/table4.PNG)\nTable 3 and Table 4 show that adversaries frequently leveraged a command or scripting interpreter (T1059) in 50.9% of cases, with one-third of those intrusions involving the use of PowerShell (T1059.001). Mandiant's analysis also reveals the continued frequent use of web protocols (T1071.001) and Remote Desktop (T1021.001) across intrusions, suggesting that adversaries heavily rely on the organization's existing technologies to carry out their operations. These sub-techniques have consistently ranked in the top five over the past three years. This trend could indicate that detection capabilities for these techniques have improved, leading organizations to prioritize other evidence sources to capture additional techniques.\n\n![Table5](https://github.com/XiLan-ashley/threat_hunting/raw/main/table5.PNG)\n![Table6](https://github.com/XiLan-ashley/threat_hunting/raw/main/table6.PNG)\n\nIn these tables, the techniques used by attackers in 2023, as detailed in the M-Trends 2024 report, remain consistent with those observed in 2022, as shown in the M-Trends 2023 report. Tables 3 and 4 demonstrate that the top 10 most frequently seen techniques have shown little variance over the past several years. In more than half of the investigations, Mandiant noted the use of a command or scripting interpreter (T1059) by attackers. A difference in the 2023 dataset is the inclusion of System Owner or User Discovery (T1033) and the exploitation of public-facing applications (T1190) among the top 10 observed techniques. These additions correlate with the rise in ransomware-related intrusions and the increase in mass exploitation campaigns observed in 2023.  \nIt's unsurprising that the top five observed sub-techniques are PowerShell (T1059.001), Web Protocols (T1071.001), Remote Desktop Protocol (T1021.001), Service Execution (T1569.002), and File Deletion (T1070.004).  Attackers likely favor these sub-techniques because they exploit readily available tools within a system, making them easy to abuse. Their proven success in compromising systems, coupled with their ability to sometimes evade security measures, makes them a highly effective part of an attacker’s toolkit. This persistent trend highlights the standard tactics employed by attackers to achieve their objectives. As such, organizations must prioritize detecting these sub-techniques if they have not already done so.\n\n\n### TTP Category\nMandiant provides techniques related to Mandiant’s Targeted Attack Lifecycle, which outlines the predictable sequence of events that cyber attackers use to carry out their attacks. To highlight the most impactful tactics, we have selected the top two techniques from each phase of the lifecycle, as shown in Table 5. This selection provides a detailed view of the most observed methods used by adversaries, thereby helping to understand into their operational patterns.\n![Table7](https://github.com/XiLan-ashley/threat_hunting/raw/main/table7.PNG)\n\nIn both the DBIR 2023 and 2024 reports, Verizon provided relevant ATT&CK techniques based on three types of attacks, as defined in DBIR,  which remained consistent across both years. These are:\n   - **Basic Web Application Attack**s,   where threat actors continue to exploit assets with default, simplistic, and easily guessable credentials by brute forcing them, purchasing them, or reusing credentials from previous breaches. \n   - **Social Engineering**, where pretexting remains the leading cause of cybersecurity incidents, with actors targeting users through existing email chains and context. The prevalence of extortion also saw a dramatic increase, largely due to the large-scale MOVEit incident. \n  - **System Intrusion**, where, despite shifts in tactics leveraged by attackers, the overall impact of these actors continues to affect a majority of industries and organizations of all sizes. \n\nTable 6 shows the specific ATT&CK techniques related to these attack types as outlined in the DBIR 2024 report.\n\n\n![Table8](https://github.com/XiLan-ashley/threat_hunting/raw/main/table8-1.PNG)\n![Table8](https://github.com/XiLan-ashley/threat_hunting/raw/main/table8-2.PNG)\n![Table8](https://github.com/XiLan-ashley/threat_hunting/raw/main/table8-3.PNG)\n\n---\n\n## References\n\n1. [MITRE ATT&CK Framework for TTP Hunting](https://www.mitre.org/sites/default/files/2021-11/prs-19-3892-ttp-based-hunting.pdf)\n2. [Sqrrl Threat Hunting Framework](https://www.threathunting.net/files/framework-for-threat-hunting-whitepaper.pdf)\n3. [B. Nour, M. Pourzandi, and M. Debbabi](“A Survey on Threat Hunting in Enterprise Networks,” IEEE Commun. Surv. Tutor., vol. 25, no. 4, pp. 2299–2324, 2023, doi: 10.1109/COMST.2023.3299519.)\n4. [PEAK Framework](“The PEAK Threat Hunting Framework,” Splunk Inc. Accessed: Nov. 06, 2024. [Online]. Available: https://www.splunk.com/en_us/blog/security/peak-threat-hunting-framework.htm)\n5. [TaHiTI Threat Hunting Methodology](https://www.betaalvereniging.nl/wp-content/uploads/TaHiTI-Threat-Hunting-Methodology-whitepaper.pdf)\n6. [MITRE](MITRE, “CAR Data Model.” [Online]. Available: https://car.mitre.org/data_model/)\n\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-10-16T15:00:02.176Z","dateModified":"2024-10-16T15:02:05.601Z","id":"paragraph_0405f33f-4ff2-4e24-9212-3be92e14991a","input":{"inputText":"%md\nThis Notebook describes the SHOW process","inputType":"MARKDOWN"},"output":[{"execution_time":"0.041 ms","outputType":"MARKDOWN","result":"This Notebook describes the SHOW process"}]}],"path":"Resilmesh-SHOW-Opensearch Threat Hunting"}},"id":"36aa4620-8bcd-11ef-8c3d-754a026f5d54","references":[],"type":"observability-notebook","updated_at":"2024-12-17T09:58:42.480Z","version":"WzE0MTEsNV0="}
{"attributes":{"savedNotebook":{"backend":".kibana_1.0","dateCreated":"2024-11-15T15:51:32.898Z","dateModified":"2024-12-16T17:29:59.871Z","name":"Resilmesh-Threat hunting visualization examples","paragraphs":[{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-15T16:05:10.183Z","dateModified":"2024-11-18T11:10:00.569Z","id":"paragraph_50306433-3396-4c1d-8437-9438ab5c6c5c","input":{"inputText":"%md\nVisualization is a powerful tool in threat hunting since it transforms complex datasets into easily understood insights. By mapping network connections, user behaviors, MITRE ATT&CK TTPs and so on, hunters can quickly identify unusal patterns and relationships that might be indicative of a threat.","inputType":"MARKDOWN"},"output":[{"execution_time":"0.069 ms","outputType":"MARKDOWN","result":"Visualization is a powerful tool in threat hunting since it transforms complex datasets into easily understood insights. By mapping network connections, user behaviors, MITRE ATT&CK TTPs and so on, hunters can quickly identify unusal patterns and relationships that might be indicative of a threat."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T11:10:03.581Z","dateModified":"2024-11-25T16:14:53.433Z","id":"paragraph_e8b99cd9-0a54-4ea7-9838-dd90aee71a7e","input":{"inputText":"%md\nWe incorporate two figures from the MITRE paper titled [TTP-Based Hunting](https://www.mitre.org/sites/default/files/2021-11/prs-19-3892-ttp-based-hunting.pdf) to as our reference example for create our own visulizations.\nFirst picture showing below is provides a visulization of three dimensions (time, terrian and behavior) with example values for behavior and terrain types. Cyber terrain can refer to the broad range of hosts, network segments, or other areas where the adversary may be operating.\n![Analysis Space](https://github.com/XiLan-ashley/threat_hunting/raw/main/anaysis.png)","inputType":"MARKDOWN"},"output":[{"execution_time":"0.012 ms","outputType":"MARKDOWN","result":"We incorporate two figures from the MITRE paper titled [TTP-Based Hunting](https://www.mitre.org/sites/default/files/2021-11/prs-19-3892-ttp-based-hunting.pdf) to as our reference example for create our own visulizations.\nFirst picture showing below is provides a visulization of three dimensions (time, terrian and behavior) with example values for behavior and terrain types. Cyber terrain can refer to the broad range of hosts, network segments, or other areas where the adversary may be operating.\n![Analysis Space](https://github.com/XiLan-ashley/threat_hunting/raw/main/anaysis.png)"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T11:33:30.732Z","dateModified":"2024-11-25T16:44:20.611Z","id":"paragraph_5eeb4278-97fd-45dc-8eb4-c45fbe8d09e5","input":{"inputText":"%md\nTo represent the analysis space in three dimensions, as described above, MITRE used a heatmap where the X and Y axes represent time and terrain, respectively. The color of each square corresponds to the count of behaviors for that terrain within the specified timeframe. Additionally, the axes of the heatmap can be adjusted, allowing flexibility in representing different data dimensions.\nBuilding upon this concept, OpenSearch provides capabilities for creating various types of visualizations. Using the MITRE heatmap as a reference, we designed our own version tailored to our dataset. In our heatmap below, the X axis represents the timestamp, showing data from the last month, which can be adjusted as needed. The Y axis displays the list of agent IPs from our dataset. The color indicates the count of behaviors, which corresponds to the number of MITRE IDs triggered in the data.\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.024 ms","outputType":"MARKDOWN","result":"To represent the analysis space in three dimensions, as described above, MITRE used a heatmap where the X and Y axes represent time and terrain, respectively. The color of each square corresponds to the count of behaviors for that terrain within the specified timeframe. Additionally, the axes of the heatmap can be adjusted, allowing flexibility in representing different data dimensions.\nBuilding upon this concept, OpenSearch provides capabilities for creating various types of visualizations. Using the MITRE heatmap as a reference, we designed our own version tailored to our dataset. In our heatmap below, the X axis represents the timestamp, showing data from the last month, which can be adjusted as needed. The Y axis displays the list of agent IPs from our dataset. The color indicates the count of behaviors, which corresponds to the number of MITRE IDs triggered in the data.\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T12:09:23.627Z","dateModified":"2024-11-18T12:09:37.186Z","id":"paragraph_374738c3-29ea-4e60-921d-2b83a8df5e89","input":{"inputText":"{\"viewMode\":\"view\",\"panels\":{\"1\":{\"gridData\":{\"x\":0,\"y\":0,\"w\":50,\"h\":20,\"i\":\"1\"},\"type\":\"visualization\",\"explicitInput\":{\"id\":\"1\",\"savedObjectId\":\"15578e00-a352-11ef-8c3d-754a026f5d54\"}}},\"isFullScreenMode\":false,\"filters\":[],\"useMargins\":false,\"id\":\"ifb126b91-a5a5-11ef-8b36-77365a2ee424\",\"visSavedObjId\":\"15578e00-a352-11ef-8c3d-754a026f5d54\",\"timeRange\":{\"to\":\"2024-11-18T12:09:24.533Z\",\"from\":\"2024-10-19T11:09:24.533Z\"},\"title\":\"embed_viz_ifb126b91-a5a5-11ef-8b36-77365a2ee424\",\"query\":{\"query\":\"\",\"language\":\"lucene\"},\"refreshConfig\":{\"pause\":true,\"value\":15}}","inputType":"VISUALIZATION"},"output":[{"execution_time":"0.056 ms","outputType":"VISUALIZATION","result":""}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T12:15:01.570Z","dateModified":"2024-11-18T14:47:11.902Z","id":"paragraph_bec39372-8a6f-43ac-8ad1-4cbc4e729ee2","input":{"inputText":"%md\nWe also created another heatmap, switching the cyber terrain dimension. The period remains the last month, but it can be adjusted as needed. The Y axis represents the list of MITRE techniques. The color indicates the count of IPs that triggered the corresponding TTP.","inputType":"MARKDOWN"},"output":[{"execution_time":"0.015 ms","outputType":"MARKDOWN","result":"We also created another heatmap, switching the cyber terrain dimension. The period remains the last month, but it can be adjusted as needed. The Y axis represents the list of MITRE techniques. The color indicates the count of IPs that triggered the corresponding TTP."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T12:22:54.804Z","dateModified":"2024-11-18T12:23:06.802Z","id":"paragraph_d6752347-4978-489f-b942-fa3727f58366","input":{"inputText":"{\"viewMode\":\"view\",\"panels\":{\"1\":{\"gridData\":{\"x\":0,\"y\":0,\"w\":50,\"h\":20,\"i\":\"1\"},\"type\":\"visualization\",\"explicitInput\":{\"id\":\"1\",\"savedObjectId\":\"c0711160-a363-11ef-8c3d-754a026f5d54\"}}},\"isFullScreenMode\":false,\"filters\":[],\"useMargins\":false,\"id\":\"idda40491-a5a7-11ef-8b36-77365a2ee424\",\"visSavedObjId\":\"c0711160-a363-11ef-8c3d-754a026f5d54\",\"timeRange\":{\"to\":\"2024-11-18T12:22:55.443Z\",\"from\":\"2024-10-19T11:22:55.443Z\"},\"title\":\"embed_viz_idda40491-a5a7-11ef-8b36-77365a2ee424\",\"query\":{\"query\":\"\",\"language\":\"lucene\"},\"refreshConfig\":{\"pause\":true,\"value\":15}}","inputType":"VISUALIZATION"},"output":[{"execution_time":"0.025 ms","outputType":"VISUALIZATION","result":""}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T13:34:51.450Z","dateModified":"2024-11-18T15:11:07.481Z","id":"paragraph_efa7e41b-69ce-4686-8952-f2fa8afcd276","input":{"inputText":"%md\n\nAccording to two papers, [TaHiTi - Treat Hunting-Methodology](https://www.betaalvereniging.nl/wp-content/uploads/DEF-TaHiTI-Threat-Hunting-Methodology.pdf) and the Splunk PEAK Threat Hunting Framework, both mention an idea called 'stack counting,' which involves counting the occurrences of each unique value and sorting them in ascending order. Based on this concept, we designed two vertical bar graphs: one showing the number of processes for agents and the other showing the number of events for agents over a specific time period.","inputType":"MARKDOWN"},"output":[{"execution_time":"0.011 ms","outputType":"MARKDOWN","result":"\nAccording to two papers, [TaHiTi - Treat Hunting-Methodology](https://www.betaalvereniging.nl/wp-content/uploads/DEF-TaHiTI-Threat-Hunting-Methodology.pdf) and the Splunk PEAK Threat Hunting Framework, both mention an idea called 'stack counting,' which involves counting the occurrences of each unique value and sorting them in ascending order. Based on this concept, we designed two vertical bar graphs: one showing the number of processes for agents and the other showing the number of events for agents over a specific time period."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T13:44:51.983Z","dateModified":"2024-11-18T13:45:02.307Z","id":"paragraph_73f72c34-4d52-4848-bfda-777dfbcbed4b","input":{"inputText":"{\"viewMode\":\"view\",\"panels\":{\"1\":{\"gridData\":{\"x\":0,\"y\":0,\"w\":50,\"h\":20,\"i\":\"1\"},\"type\":\"visualization\",\"explicitInput\":{\"id\":\"1\",\"savedObjectId\":\"110eaca0-a345-11ef-8c3d-754a026f5d54\"}}},\"isFullScreenMode\":false,\"filters\":[],\"useMargins\":false,\"id\":\"i4f81cb51-a5b3-11ef-9f85-cdcc97e1a8a9\",\"visSavedObjId\":\"110eaca0-a345-11ef-8c3d-754a026f5d54\",\"timeRange\":{\"to\":\"2024-11-18T13:44:52.128Z\",\"from\":\"2024-10-19T12:44:52.128Z\"},\"title\":\"embed_viz_i4f81cb51-a5b3-11ef-9f85-cdcc97e1a8a9\",\"query\":{\"query\":\"\",\"language\":\"lucene\"},\"refreshConfig\":{\"pause\":true,\"value\":15}}","inputType":"VISUALIZATION"},"output":[{"execution_time":"0.025 ms","outputType":"VISUALIZATION","result":""}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T13:45:59.774Z","dateModified":"2024-11-18T13:46:08.828Z","id":"paragraph_cab6c810-25ef-4658-aa9e-17a41843c0c6","input":{"inputText":"{\"viewMode\":\"view\",\"panels\":{\"1\":{\"gridData\":{\"x\":0,\"y\":0,\"w\":50,\"h\":20,\"i\":\"1\"},\"type\":\"visualization\",\"explicitInput\":{\"id\":\"1\",\"savedObjectId\":\"acd57310-a347-11ef-8c3d-754a026f5d54\"}}},\"isFullScreenMode\":false,\"filters\":[],\"useMargins\":false,\"id\":\"i77292951-a5b3-11ef-9f85-cdcc97e1a8a9\",\"visSavedObjId\":\"acd57310-a347-11ef-8c3d-754a026f5d54\",\"timeRange\":{\"to\":\"2024-11-18T13:46:00.206Z\",\"from\":\"2024-10-19T12:46:00.206Z\"},\"title\":\"embed_viz_i77292951-a5b3-11ef-9f85-cdcc97e1a8a9\",\"query\":{\"query\":\"\",\"language\":\"lucene\"},\"refreshConfig\":{\"pause\":true,\"value\":15}}","inputType":"VISUALIZATION"},"output":[{"execution_time":"0.029 ms","outputType":"VISUALIZATION","result":""}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T13:53:00.821Z","dateModified":"2024-11-18T14:50:36.722Z","id":"paragraph_fe032cdc-a30f-4214-900b-d847de778670","input":{"inputText":"%md\nAs mentioned at the beginning, network connections are also crucial for threat hunting. Visualization can provide a clear overview of the status of each network connection. In OpenSearch, there is no existing tool for visualizing connections directly; however, OpenSearch supports Vega, a visualization grammar that allows users to create custom graphs. Here, we provide a visualization example showing the network connections. To display the graph for the first time, click on any node, which will reveal all the links between nodes. Hovering over a node will display basic information, such as node ID, node IP, domain name, and the number of connections for that node.","inputType":"MARKDOWN"},"output":[{"execution_time":"0.009 ms","outputType":"MARKDOWN","result":"As mentioned at the beginning, network connections are also crucial for threat hunting. Visualization can provide a clear overview of the status of each network connection. In OpenSearch, there is no existing tool for visualizing connections directly; however, OpenSearch supports Vega, a visualization grammar that allows users to create custom graphs. Here, we provide a visualization example showing the network connections. To display the graph for the first time, click on any node, which will reveal all the links between nodes. Hovering over a node will display basic information, such as node ID, node IP, domain name, and the number of connections for that node."}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T13:59:50.047Z","dateModified":"2024-11-18T13:59:59.752Z","id":"paragraph_2bbfa8f1-6b9e-4bee-8e17-e025780ed9cc","input":{"inputText":"{\"viewMode\":\"view\",\"panels\":{\"1\":{\"gridData\":{\"x\":0,\"y\":0,\"w\":50,\"h\":20,\"i\":\"1\"},\"type\":\"visualization\",\"explicitInput\":{\"id\":\"1\",\"savedObjectId\":\"971363a0-8a03-11ef-8c3d-754a026f5d54\"}}},\"isFullScreenMode\":false,\"filters\":[],\"useMargins\":false,\"id\":\"i666da4e1-a5b5-11ef-9f85-cdcc97e1a8a9\",\"visSavedObjId\":\"971363a0-8a03-11ef-8c3d-754a026f5d54\",\"timeRange\":{\"to\":\"2024-11-18T13:59:50.227Z\",\"from\":\"2024-10-19T12:59:50.227Z\"},\"title\":\"embed_viz_i666da4e1-a5b5-11ef-9f85-cdcc97e1a8a9\",\"query\":{\"query\":\"\",\"language\":\"lucene\"},\"refreshConfig\":{\"pause\":true,\"value\":15}}","inputType":"VISUALIZATION"},"output":[{"execution_time":"0.025 ms","outputType":"VISUALIZATION","result":""}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T14:03:43.524Z","dateModified":"2024-11-18T14:06:32.169Z","id":"paragraph_595244b3-685c-4127-9144-49a63a212501","input":{"inputText":"%md\nWazuh provided the dashboard for analyse the data based on MITRE ATT&CK.\nHere we based on Wazuh MITRE ATT&CK dashboard to created seveal visualiaztions.\n","inputType":"MARKDOWN"},"output":[{"execution_time":"0.028 ms","outputType":"MARKDOWN","result":"Wazuh provided the dashboard for analyse the data based on MITRE ATT&CK.\nHere we based on Wazuh MITRE ATT&CK dashboard to created seveal visualiaztions.\n"}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T14:06:37.086Z","dateModified":"2024-11-18T14:07:42.578Z","id":"paragraph_fdecfc2f-4ceb-4f04-a94d-f0b6dfdabd36","input":{"inputText":"{\"viewMode\":\"view\",\"panels\":{\"1\":{\"gridData\":{\"x\":0,\"y\":0,\"w\":50,\"h\":20,\"i\":\"1\"},\"type\":\"visualization\",\"explicitInput\":{\"id\":\"1\",\"savedObjectId\":\"b3f4e450-a365-11ef-8c3d-754a026f5d54\"}}},\"isFullScreenMode\":false,\"filters\":[],\"useMargins\":false,\"id\":\"i7a4afb61-a5b6-11ef-9f85-cdcc97e1a8a9\",\"visSavedObjId\":\"b3f4e450-a365-11ef-8c3d-754a026f5d54\",\"timeRange\":{\"to\":\"2024-11-18T14:06:37.799Z\",\"from\":\"2024-10-19T13:06:37.799Z\"},\"title\":\"embed_viz_i7a4afb61-a5b6-11ef-9f85-cdcc97e1a8a9\",\"query\":{\"query\":\"\",\"language\":\"lucene\"},\"refreshConfig\":{\"pause\":true,\"value\":15}}","inputType":"VISUALIZATION"},"output":[{"execution_time":"0.025 ms","outputType":"VISUALIZATION","result":""}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T14:29:05.278Z","dateModified":"2024-11-18T14:29:19.543Z","id":"paragraph_0f28f541-da16-47b3-82f5-2c20b9b681d4","input":{"inputText":"{\"viewMode\":\"view\",\"panels\":{\"1\":{\"gridData\":{\"x\":0,\"y\":0,\"w\":50,\"h\":20,\"i\":\"1\"},\"type\":\"visualization\",\"explicitInput\":{\"id\":\"1\",\"savedObjectId\":\"63cff720-a366-11ef-8c3d-754a026f5d54\"}}},\"isFullScreenMode\":false,\"filters\":[],\"useMargins\":false,\"id\":\"i7f5849c1-a5b9-11ef-9f85-cdcc97e1a8a9\",\"visSavedObjId\":\"63cff720-a366-11ef-8c3d-754a026f5d54\",\"timeRange\":{\"to\":\"2024-11-18T14:29:05.824Z\",\"from\":\"2024-10-19T13:29:05.824Z\"},\"title\":\"embed_viz_i7f5849c1-a5b9-11ef-9f85-cdcc97e1a8a9\",\"query\":{\"query\":\"\",\"language\":\"lucene\"},\"refreshConfig\":{\"pause\":true,\"value\":15}}","inputType":"VISUALIZATION"},"output":[{"execution_time":"0.047 ms","outputType":"VISUALIZATION","result":""}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T14:29:29.373Z","dateModified":"2024-11-18T14:29:38.422Z","id":"paragraph_c32b83e3-a652-450e-ac1e-022e0c4bf07a","input":{"inputText":"{\"viewMode\":\"view\",\"panels\":{\"1\":{\"gridData\":{\"x\":0,\"y\":0,\"w\":50,\"h\":20,\"i\":\"1\"},\"type\":\"visualization\",\"explicitInput\":{\"id\":\"1\",\"savedObjectId\":\"643e9010-a369-11ef-8c3d-754a026f5d54\"}}},\"isFullScreenMode\":false,\"filters\":[],\"useMargins\":false,\"id\":\"i8a9925c1-a5b9-11ef-9f85-cdcc97e1a8a9\",\"visSavedObjId\":\"643e9010-a369-11ef-8c3d-754a026f5d54\",\"timeRange\":{\"to\":\"2024-11-18T14:29:29.869Z\",\"from\":\"2024-10-19T13:29:29.869Z\"},\"title\":\"embed_viz_i8a9925c1-a5b9-11ef-9f85-cdcc97e1a8a9\",\"query\":{\"query\":\"\",\"language\":\"lucene\"},\"refreshConfig\":{\"pause\":true,\"value\":15}}","inputType":"VISUALIZATION"},"output":[{"execution_time":"0.031 ms","outputType":"VISUALIZATION","result":""}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T14:29:42.272Z","dateModified":"2024-11-18T14:29:55.616Z","id":"paragraph_b0ae9ac8-6f37-433d-ac59-3a45d2453662","input":{"inputText":"{\"viewMode\":\"view\",\"panels\":{\"1\":{\"gridData\":{\"x\":0,\"y\":0,\"w\":50,\"h\":20,\"i\":\"1\"},\"type\":\"visualization\",\"explicitInput\":{\"id\":\"1\",\"savedObjectId\":\"2c303da0-a368-11ef-8c3d-754a026f5d54\"}}},\"isFullScreenMode\":false,\"filters\":[],\"useMargins\":false,\"id\":\"i94d8be61-a5b9-11ef-9f85-cdcc97e1a8a9\",\"visSavedObjId\":\"2c303da0-a368-11ef-8c3d-754a026f5d54\",\"timeRange\":{\"to\":\"2024-11-18T14:29:42.909Z\",\"from\":\"2024-10-19T13:29:42.909Z\"},\"title\":\"embed_viz_i94d8be61-a5b9-11ef-9f85-cdcc97e1a8a9\",\"query\":{\"query\":\"\",\"language\":\"lucene\"},\"refreshConfig\":{\"pause\":true,\"value\":15}}","inputType":"VISUALIZATION"},"output":[{"execution_time":"0.038 ms","outputType":"VISUALIZATION","result":""}]},{"dataSourceMDSId":"","dataSourceMDSLabel":"","dateCreated":"2024-11-18T14:29:59.786Z","dateModified":"2024-11-18T14:30:10.747Z","id":"paragraph_c8ac11bc-9767-480f-b175-d2719a1156bf","input":{"inputText":"{\"viewMode\":\"view\",\"panels\":{\"1\":{\"gridData\":{\"x\":0,\"y\":0,\"w\":50,\"h\":20,\"i\":\"1\"},\"type\":\"visualization\",\"explicitInput\":{\"id\":\"1\",\"savedObjectId\":\"001a1e60-a369-11ef-8c3d-754a026f5d54\"}}},\"isFullScreenMode\":false,\"filters\":[],\"useMargins\":false,\"id\":\"i9dde2951-a5b9-11ef-9f85-cdcc97e1a8a9\",\"visSavedObjId\":\"001a1e60-a369-11ef-8c3d-754a026f5d54\",\"timeRange\":{\"to\":\"2024-11-18T14:29:59.950Z\",\"from\":\"2024-10-19T13:29:59.949Z\"},\"title\":\"embed_viz_i9dde2951-a5b9-11ef-9f85-cdcc97e1a8a9\",\"query\":{\"query\":\"\",\"language\":\"lucene\"},\"refreshConfig\":{\"pause\":true,\"value\":15}}","inputType":"VISUALIZATION"},"output":[{"execution_time":"0.025 ms","outputType":"VISUALIZATION","result":""}]}],"path":"Resilmesh-Threat hunting visualization examples"}},"id":"7c981550-a369-11ef-8c3d-754a026f5d54","references":[],"type":"observability-notebook","updated_at":"2024-12-16T17:29:59.871Z","version":"WzE0MDIsNV0="}
{"exportedCount":6,"missingRefCount":0,"missingReferences":[]}